/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
  warnings.warn(f"Warning: The {path} owner does not match the current owner.")
/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
  warnings.warn(f"Warning: The {path} owner does not match the current owner.")
/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
  warnings.warn(f"Warning: The {path} owner does not match the current owner.")
/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
  warnings.warn(f"Warning: The {path} owner does not match the current owner.")
/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
[Rank 0 | Local Rank 0] 2026-01-02 17:03:35,856 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/ray/_private/node.py:1125: ResourceWarning: unclosed file <_io.TextIOWrapper name='/dev/null' mode='w' encoding='UTF-8'>
  process_info = ray._private.services.start_gcs_server(
/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/ray/_private/node.py:1086: ResourceWarning: unclosed file <_io.TextIOWrapper name='/dev/null' mode='w' encoding='UTF-8'>
  self._webui_url, process_info = ray._private.services.start_api_server(
2026-01-02 17:03:46,906	WARNING utils.py:460 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.
2026-01-02 17:03:48,189	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(pid=357514)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=357514)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=357514)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=357514)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=357514)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=357514)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=357514)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=357514)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=357514)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
[36m(pid=357514)[0m     *************************************************************************************************************
[36m(pid=357514)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(pid=357514)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(pid=357514)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(pid=357514)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(pid=357514)[0m     The device parameters have been replaced with npu in the function below:
[36m(pid=357514)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(pid=357514)[0m     *************************************************************************************************************
[36m(pid=357514)[0m     
[36m(pid=357514)[0m   warnings.warn(msg, ImportWarning)
[36m(pid=357514)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(pid=357514)[0m   warnings.warn(msg, RuntimeWarning)
[36m(pid=357514)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(pid=357514)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(pid=357514)[0m   import pkg_resources
ray init kwargs: {'num_cpus': None, 'runtime_env': {'env_vars': {'TOKENIZERS_PARALLELISM': 'true', 'NCCL_DEBUG': 'WARN', 'VLLM_LOGGING_LEVEL': 'WARN', 'VLLM_ALLOW_RUNTIME_LORA_UPDATING': 'true', 'VLLM_ALLREDUCE_USE_SYMM_MEM': '0', 'CUDA_DEVICE_MAX_CONNECTIONS': '1', 'NCCL_CUMEM_ENABLE': '0'}, 'working_dir': None}}
[36m(pid=357514)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:04:06,432 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(FullyAsyncTaskRunner pid=357514)[0m [ASYNC MAIN] Starting fully async PPO training...
[36m(FullyAsyncTaskRunner pid=357514)[0m [ASYNC MAIN] TaskRunner hostname: notebook-7f74bd20-3c19-4e51-b968-a157f487844c, PID: 357514
[36m(FullyAsyncTaskRunner pid=357514)[0m {'actor_rollout_ref': {'actor': {'_target_': 'verl.workers.config.McoreActorConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'calculate_entropy': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'checkpoint': {'_target_': 'verl.trainer.config.CheckpointConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                 'async_save': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                 'load_contents': ['model',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                   'optimizer',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                   'extra'],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                 'save_contents': ['model',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                   'optimizer',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                   'extra']},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'clip_ratio': 0.2,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'clip_ratio_c': 10.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'clip_ratio_high': 0.28,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'clip_ratio_low': 0.2,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'data_loader_seed': 42,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'entropy_coeff': 0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'freeze_vision_tower': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'kl_loss_coef': 0.001,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'load_weight': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'loss_agg_mode': 'token-mean',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'loss_scale_factor': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'megatron': {'_target_': 'verl.workers.config.McoreEngineConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'context_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'dist_checkpointing_path': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'dist_checkpointing_prefix': '',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'dtype': 'bfloat16',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'expert_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'expert_tensor_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'forward_only': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'grad_offload': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'optimizer_offload': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'override_ddp_config': {},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'override_mcore_model_config': {},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'override_transformer_config': {'apply_rope_fusion': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                               'attention_backend': 'flash',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                               'bias_activation_fusion': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                               'bias_dropout_fusion': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                               'deallocate_pipeline_outputs': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                               'gradient_accumulation_fusion': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                               'masked_softmax_fusion': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                               'persist_layer_norm': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                               'recompute_granularity': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                               'recompute_method': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                               'recompute_modules': ['core_attn'],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                               'recompute_num_layers': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                               'use_flash_attn': True},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'param_offload': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'pipeline_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'seed': 42,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'sequence_parallel': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'tensor_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'use_dist_checkpointing': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'use_distributed_optimizer': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'use_mbridge': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'use_remove_padding': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'vanilla_mbridge': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'virtual_pipeline_model_parallel_size': None},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'optim': {'_target_': 'verl.workers.config.McoreOptimizerConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                            'betas': [0.9, 0.999],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                            'clip_grad': 1.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                            'lr': 1e-06,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                            'lr_decay_steps': 51200,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                            'lr_decay_style': 'constant',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                            'lr_warmup_init': 0.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                            'lr_warmup_steps': 10,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                            'lr_wsd_decay_steps': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                            'lr_wsd_decay_style': 'exponential',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                            'min_lr': 0.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                            'optimizer': 'adam',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                            'override_optimizer_config': {'optimizer_cpu_offload': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                          'optimizer_offload_fraction': 0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                          'overlap_cpu_optimizer_d2h_h2d': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                          'use_precision_aware_optimizer': True},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                            'total_training_steps': -1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                            'use_checkpoint_opt_param_scheduler': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                            'weight_decay': 0.1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                            'weight_decay_incr_style': 'constant'},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'policy_loss': {'_target_': 'verl.workers.config.PolicyLossConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                  'clip_cov_lb': 1.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                  'clip_cov_ratio': 0.0002,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                  'clip_cov_ub': 5.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                  'kl_cov_ratio': 0.0002,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                  'loss_mode': 'vanilla',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                  'ppo_kl_coef': 0.1},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'ppo_epochs': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'ppo_max_token_len_per_gpu': 5120,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'ppo_micro_batch_size': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'ppo_mini_batch_size': 64,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'all_ranks': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'enable': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'ranks': [],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'save_path': 'outputs/profile',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'tool': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                               'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                       'analysis': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                       'contents': [],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                       'discrete': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                       'level': 'level0'},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                               'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                        'discrete': False},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                               'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                         'step_end': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                         'step_start': 0},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                               'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                                'stack_depth': 32,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                                'trace_alloc_max_entries': 100000}}},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'rollout_n': 8,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'router_replay': {'_target_': 'verl.workers.config.RouterReplayConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                    'mode': 'disabled',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                    'record_file': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                    'replay_file': None},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'shuffle': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'strategy': 'megatron',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'use_dynamic_bsz': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'use_fused_kernels': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'use_kl_loss': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'use_rollout_log_probs': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'use_torch_compile': True},
[36m(FullyAsyncTaskRunner pid=357514)[0m                        'checkpoint_engine': {'device_buffer_size_M': 4096,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                              'enable': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                              'overlap_broadcast_and_consume': False},
[36m(FullyAsyncTaskRunner pid=357514)[0m                        'hybrid_engine': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                        'model': {'_target_': 'verl.workers.config.HFModelConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'custom_chat_template': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'enable_activation_offload': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'enable_gradient_checkpointing': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'exclude_modules': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'external_lib': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'fused_kernel_options': {'impl_backend': 'torch'},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'hf_config_path': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'lora': {'a2a_experimental': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                           'adapter_path': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                           'alpha': 32,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                           'dropout': 0.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                           'dropout_position': 'pre',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                           'dtype': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                           'exclude_modules': [],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                           'freeze_language_model': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                           'freeze_vision_model': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                           'freeze_vision_projection': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                           'lora_A_init_method': 'xavier',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                           'lora_B_init_method': 'zero',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                           'rank': 0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                           'target_modules': ['linear_qkv',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                              'linear_proj',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                              'linear_fc1',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                              'linear_fc2'],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                           'type': 'lora'},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'lora_adapter_path': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'lora_alpha': 16,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'lora_rank': 0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'override_config': {'model_config': {'max_position_embeddings': 5120},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                      'moe_config': {'freeze_moe_router': False}},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'path': '/home/ma-user/work/models/Qwen2.5-0.5B-Instruct',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'target_modules': 'all-linear',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'tokenizer_path': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'trust_remote_code': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'use_fused_kernels': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'use_liger': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'use_remove_padding': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                  'use_shm': False},
[36m(FullyAsyncTaskRunner pid=357514)[0m                        'nccl_timeout': 600,
[36m(FullyAsyncTaskRunner pid=357514)[0m                        'ref': {'_target_': 'verl.workers.config.McoreActorConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'load_weight': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'log_prob_max_token_len_per_gpu': 5120,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'log_prob_micro_batch_size': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'log_prob_micro_batch_size_per_gpu': 64,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'log_prob_use_dynamic_bsz': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'megatron': {'_target_': 'verl.workers.config.McoreEngineConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'context_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'dist_checkpointing_path': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'dist_checkpointing_prefix': '',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'dtype': 'bfloat16',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'expert_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'expert_tensor_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'forward_only': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'grad_offload': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'optimizer_offload': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'override_ddp_config': {},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'override_mcore_model_config': {},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'override_transformer_config': {'apply_rope_fusion': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                             'attention_backend': 'flash',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                             'bias_activation_fusion': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                             'bias_dropout_fusion': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                             'deallocate_pipeline_outputs': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                             'gradient_accumulation_fusion': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                             'masked_softmax_fusion': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                             'persist_layer_norm': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                             'recompute_granularity': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                             'recompute_method': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                             'recompute_modules': ['core_attn'],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                             'recompute_num_layers': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                             'use_flash_attn': True},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'param_offload': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'pipeline_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'seed': 42,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'sequence_parallel': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'tensor_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'use_dist_checkpointing': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'use_distributed_optimizer': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'use_mbridge': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'use_remove_padding': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'vanilla_mbridge': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'virtual_pipeline_model_parallel_size': None},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'all_ranks': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'enable': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'ranks': [],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'save_path': 'outputs/profile',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'tool': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                     'analysis': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                     'contents': [],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                     'discrete': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                     'level': 'level0'},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                             'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                      'discrete': False},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                             'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                       'step_end': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                       'step_start': 0},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                             'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                              'stack_depth': 32,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                              'trace_alloc_max_entries': 100000}}},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'rollout_n': 8,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'router_replay': {'_target_': 'verl.workers.config.RouterReplayConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                  'mode': 'disabled',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                  'record_file': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                  'replay_file': None},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'strategy': 'megatron',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'use_torch_compile': True},
[36m(FullyAsyncTaskRunner pid=357514)[0m                        'rollout': {'_target_': 'verl.workers.config.RolloutConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'agent': {'_target_': 'verl.workers.config.AgentLoopConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                              'agent_loop_config_path': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                              'custom_async_server': {'_target_': 'verl.workers.config.CustomAsyncServerConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                      'name': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                      'path': None},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                              'default_agent_loop': 'single_turn_agent',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                              'num_workers': 8},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'calculate_log_probs': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'cudagraph_capture_sizes': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'data_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'disable_log_stats': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'do_sample': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'dtype': 'bfloat16',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'enable_chunked_prefill': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'enable_prefix_caching': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'enable_rollout_routing_replay': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'enforce_eager': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'engine_kwargs': {'sglang': {}, 'vllm': {}},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'expert_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'free_cache_engine': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'gpu_memory_utilization': 0.8,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'ignore_eos': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'layer_name_map': {'gate_proj_layer_name': 'gate_up',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                       'qkv_layer_name': 'qkv'},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'load_format': 'dummy',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'log_prob_max_token_len_per_gpu': 5120,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'log_prob_micro_batch_size': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'log_prob_micro_batch_size_per_gpu': 64,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'log_prob_use_dynamic_bsz': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'max_model_len': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'max_num_batched_tokens': 5120,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'max_num_seqs': 1024,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'mode': 'async',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'multi_stage_wake_up': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'multi_turn': {'_target_': 'verl.workers.config.MultiTurnConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'enable': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'format': 'hermes',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'interaction_config_path': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'max_assistant_turns': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'max_parallel_calls': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'max_tool_response_length': 256,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'max_user_turns': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'num_repeat_rollouts': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'tokenization_sanity_check_mode': 'strict',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'tool_config_path': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'tool_response_truncate_side': 'middle',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'use_inference_chat_template': False},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'n': 8,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'name': 'vllm',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'over_sample_rate': 0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'pipeline_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                 'all_ranks': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                 'enable': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                 'ranks': [],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                 'save_path': 'outputs/profile',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                 'tool': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                 'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                         'analysis': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                         'contents': [],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                         'discrete': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                         'level': 'level0'},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                 'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                          'discrete': False},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                 'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                           'step_end': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                           'step_start': 0},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                 'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                                  'stack_depth': 32,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                                  'trace_alloc_max_entries': 100000}}},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'prometheus': {'_target_': 'verl.workers.config.PrometheusConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'enable': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'file': '/tmp/ray/session_latest/metrics/prometheus/prometheus.yml',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'port': 9090,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'served_model_name': '/home/ma-user/work/models/Qwen2.5-0.5B-Instruct'},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'prompt_length': 2048,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'quantization': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'quantization_config_file': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'response_length': 3072,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'skip_dump_dir': '/tmp/rollout_dump',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'skip_rollout': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'skip_tokenizer_init': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'temperature': 1.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'tensor_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'top_k': -1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'top_p': 1.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'trace': {'_target_': 'verl.workers.config.TraceConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                              'backend': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                              'max_samples_per_step_per_worker': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                              'token2text': False},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'update_weights_bucket_megabytes': 512,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                    'val_kwargs': {'_target_': 'verl.workers.config.SamplingConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'do_sample': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'n': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'temperature': 1.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'top_k': -1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'top_p': 0.7}}},
[36m(FullyAsyncTaskRunner pid=357514)[0m  'algorithm': {'_target_': 'verl.trainer.config.AlgoConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                'adv_estimator': 'grpo',
[36m(FullyAsyncTaskRunner pid=357514)[0m                'gamma': 1.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                'kl_ctrl': {'_target_': 'verl.trainer.config.KLControlConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                            'horizon': 10000,
[36m(FullyAsyncTaskRunner pid=357514)[0m                            'kl_coef': 0.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                            'target_kl': 0.1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                            'type': 'fixed'},
[36m(FullyAsyncTaskRunner pid=357514)[0m                'kl_penalty': 'kl',
[36m(FullyAsyncTaskRunner pid=357514)[0m                'lam': 1.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                'norm_adv_by_std_in_grpo': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                'pf_ppo': {'reweight_method': 'pow', 'weight_pow': 2.0},
[36m(FullyAsyncTaskRunner pid=357514)[0m                'rollout_correction': {'bypass_mode': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                       'loss_type': 'ppo_clip',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                       'rollout_is': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                       'rollout_is_batch_normalize': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                       'rollout_is_threshold': 2.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                       'rollout_rs': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                       'rollout_rs_threshold': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                       'rollout_rs_threshold_lower': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                       'rollout_token_veto_threshold': None},
[36m(FullyAsyncTaskRunner pid=357514)[0m                'use_kl_in_reward': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                'use_pf_ppo': False},
[36m(FullyAsyncTaskRunner pid=357514)[0m  'async_training': {'checkpoint_engine': {'device_buffer_size_M': 4096,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                           'enable': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                           'overlap_broadcast_and_consume': False},
[36m(FullyAsyncTaskRunner pid=357514)[0m                     'compute_prox_log_prob': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                     'partial_rollout': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                     'require_batches': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                     'staleness_threshold': 0.2,
[36m(FullyAsyncTaskRunner pid=357514)[0m                     'trigger_parameter_sync_step': 4,
[36m(FullyAsyncTaskRunner pid=357514)[0m                     'use_rollout_log_probs': True},
[36m(FullyAsyncTaskRunner pid=357514)[0m  'critic': {'_target_': 'verl.workers.config.McoreCriticConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m             'checkpoint': {'_target_': 'verl.trainer.config.CheckpointConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                            'async_save': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                            'load_contents': ['model', 'optimizer', 'extra'],
[36m(FullyAsyncTaskRunner pid=357514)[0m                            'save_contents': ['model', 'optimizer', 'extra']},
[36m(FullyAsyncTaskRunner pid=357514)[0m             'cliprange_value': 0.5,
[36m(FullyAsyncTaskRunner pid=357514)[0m             'data_loader_seed': 42,
[36m(FullyAsyncTaskRunner pid=357514)[0m             'enable': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(FullyAsyncTaskRunner pid=357514)[0m             'load_weight': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m             'loss_agg_mode': 'token-mean',
[36m(FullyAsyncTaskRunner pid=357514)[0m             'megatron': {'_target_': 'verl.workers.config.McoreEngineConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'context_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'dist_checkpointing_path': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'dist_checkpointing_prefix': '',
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'dtype': 'bfloat16',
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'expert_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'expert_tensor_parallel_size': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'forward_only': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'grad_offload': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'optimizer_offload': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'override_ddp_config': {},
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'override_mcore_model_config': {},
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'override_transformer_config': {'attention_backend': 'flash',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                          'recompute_granularity': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                          'recompute_method': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                          'recompute_modules': ['core_attn'],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                          'recompute_num_layers': None},
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'param_offload': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'pipeline_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'seed': 42,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'sequence_parallel': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'tensor_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'use_dist_checkpointing': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'use_distributed_optimizer': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'use_mbridge': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'use_remove_padding': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'vanilla_mbridge': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'virtual_pipeline_model_parallel_size': None},
[36m(FullyAsyncTaskRunner pid=357514)[0m             'model': {'_target_': 'verl.trainer.config.BaseModelConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'external_lib': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'lora': {'a2a_experimental': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'adapter_path': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'alpha': 32,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'dropout': 0.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'dropout_position': 'pre',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'dtype': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'exclude_modules': [],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'freeze_language_model': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'freeze_vision_model': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'freeze_vision_projection': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'lora_A_init_method': 'xavier',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'lora_B_init_method': 'zero',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'rank': 0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'target_modules': ['linear_qkv',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'linear_proj',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'linear_fc1',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'linear_fc2'],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'type': 'lora'},
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'override_config': {'model_config': {},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                           'moe_config': {'freeze_moe_router': False}},
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'path': '~/models/deepseek-llm-7b-chat',
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'tokenizer_path': '/home/ma-user/work/models/Qwen2.5-0.5B-Instruct',
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'trust_remote_code': False},
[36m(FullyAsyncTaskRunner pid=357514)[0m             'nccl_timeout': 600,
[36m(FullyAsyncTaskRunner pid=357514)[0m             'optim': {'_target_': 'verl.workers.config.McoreOptimizerConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'betas': [0.9, 0.999],
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'clip_grad': 1.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'lr': 1e-05,
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'lr_decay_steps': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'lr_decay_style': 'constant',
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'lr_warmup_init': 0.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'lr_warmup_steps': -1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'lr_wsd_decay_steps': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'lr_wsd_decay_style': 'exponential',
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'min_lr': 0.0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'optimizer': 'adam',
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'override_optimizer_config': {},
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'total_training_steps': -1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'use_checkpoint_opt_param_scheduler': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'weight_decay': 0.01,
[36m(FullyAsyncTaskRunner pid=357514)[0m                       'weight_decay_incr_style': 'constant'},
[36m(FullyAsyncTaskRunner pid=357514)[0m             'ppo_epochs': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(FullyAsyncTaskRunner pid=357514)[0m             'ppo_micro_batch_size': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m             'ppo_micro_batch_size_per_gpu': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m             'ppo_mini_batch_size': 64,
[36m(FullyAsyncTaskRunner pid=357514)[0m             'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'all_ranks': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'enable': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'ranks': [],
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'save_path': 'outputs/profile',
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'tool': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                          'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                  'analysis': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                  'contents': [],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                  'discrete': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                  'level': 'level0'},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                          'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                   'discrete': False},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                          'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                    'step_end': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                    'step_start': 0},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                          'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                           'stack_depth': 32,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                           'trace_alloc_max_entries': 100000}}},
[36m(FullyAsyncTaskRunner pid=357514)[0m             'rollout_n': 8,
[36m(FullyAsyncTaskRunner pid=357514)[0m             'shuffle': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m             'strategy': 'megatron',
[36m(FullyAsyncTaskRunner pid=357514)[0m             'use_dynamic_bsz': True},
[36m(FullyAsyncTaskRunner pid=357514)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(FullyAsyncTaskRunner pid=357514)[0m  'data': {'apply_chat_template_kwargs': {},
[36m(FullyAsyncTaskRunner pid=357514)[0m           'custom_cls': {'name': None, 'path': None},
[36m(FullyAsyncTaskRunner pid=357514)[0m           'datagen': {'name': None, 'path': None},
[36m(FullyAsyncTaskRunner pid=357514)[0m           'dataloader_num_workers': 8,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'filter_overlong_prompts': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'filter_overlong_prompts_workers': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'gen_batch_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'image_key': 'images',
[36m(FullyAsyncTaskRunner pid=357514)[0m           'image_patch_size': 14,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'max_prompt_length': 2048,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'max_response_length': 3072,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'prompt_key': 'prompt',
[36m(FullyAsyncTaskRunner pid=357514)[0m           'return_full_prompt': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'return_multi_modal_inputs': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'return_raw_chat': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'return_raw_input_ids': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'reward_fn_key': 'data_source',
[36m(FullyAsyncTaskRunner pid=357514)[0m           'sampler': {'class_name': None, 'class_path': None},
[36m(FullyAsyncTaskRunner pid=357514)[0m           'seed': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'shuffle': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'tokenizer': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'tool_config_path': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'train_batch_size': 0,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'train_files': '/home/ma-user/work/data/gsm8k/train.parquet',
[36m(FullyAsyncTaskRunner pid=357514)[0m           'train_max_samples': -1,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'truncation': 'left',
[36m(FullyAsyncTaskRunner pid=357514)[0m           'trust_remote_code': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'use_shm': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'val_batch_size': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'val_files': '/home/ma-user/work/data/gsm8k/test.parquet',
[36m(FullyAsyncTaskRunner pid=357514)[0m           'val_max_samples': -1,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'validation_shuffle': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m           'video_key': 'videos'},
[36m(FullyAsyncTaskRunner pid=357514)[0m  'global_profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                      'global_tool_config': {'nsys': {'controller_nsight_options': {'cuda-graph-trace': 'graph',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                                    'cuda-memory-usage': 'true',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                                    'trace': 'cuda,nvtx,cublas,ucx'},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                      'discrete': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                      'worker_nsight_options': {'capture-range': 'cudaProfilerApi',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                                'capture-range-end': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                                'cuda-graph-trace': 'graph',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                                'cuda-memory-usage': 'true',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                                'kill': 'none',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                                'trace': 'cuda,nvtx,cublas,ucx'}},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                             'torch_memory': {'context': 'all',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                              'kw_args': {},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                              'stack_depth': 32,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                              'stacks': 'all',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                              'trace_alloc_max_entries': 100000}},
[36m(FullyAsyncTaskRunner pid=357514)[0m                      'profile_continuous_steps': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                      'save_path': 'outputs/profile',
[36m(FullyAsyncTaskRunner pid=357514)[0m                      'steps': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                      'tool': None},
[36m(FullyAsyncTaskRunner pid=357514)[0m  'ray_kwargs': {'ray_init': {'num_cpus': None}, 'timeline_json_file': None},
[36m(FullyAsyncTaskRunner pid=357514)[0m  'reward_manager': {'_target_': 'verl.trainer.config.config.RewardManagerConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                     'module': {'_target_': 'verl.trainer.config.config.ModuleConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'name': 'custom_reward_manager',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'path': None},
[36m(FullyAsyncTaskRunner pid=357514)[0m                     'name': 'dapo',
[36m(FullyAsyncTaskRunner pid=357514)[0m                     'source': 'register'},
[36m(FullyAsyncTaskRunner pid=357514)[0m  'reward_model': {'enable': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'enable_resource_pool': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'launch_reward_fn_async': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'load_weight': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'max_length': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'megatron': {'_target_': 'verl.workers.config.MegatronEngineConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'context_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'dist_checkpointing_path': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'dist_checkpointing_prefix': '',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'dtype': 'bfloat16',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'expert_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'expert_tensor_parallel_size': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'override_transformer_config': {'apply_rope_fusion': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                'attention_backend': 'flash',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                'bias_activation_fusion': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                'bias_dropout_fusion': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                'deallocate_pipeline_outputs': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                'gradient_accumulation_fusion': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                'masked_softmax_fusion': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                'persist_layer_norm': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                'recompute_granularity': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                'recompute_method': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                'recompute_modules': ['core_attn'],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                'recompute_num_layers': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                'use_flash_attn': True},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'param_offload': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'pipeline_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'seed': 42,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'sequence_parallel': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'tensor_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'use_dist_checkpointing': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'use_distributed_optimizer': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'use_mbridge': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'use_remove_padding': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'vanilla_mbridge': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'virtual_pipeline_model_parallel_size': None},
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'micro_batch_size': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'micro_batch_size_per_gpu': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'model': {'external_lib': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                             'input_tokenizer': '/home/ma-user/work/models/Qwen2.5-0.5B-Instruct',
[36m(FullyAsyncTaskRunner pid=357514)[0m                             'override_config': {},
[36m(FullyAsyncTaskRunner pid=357514)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(FullyAsyncTaskRunner pid=357514)[0m                             'trust_remote_code': False},
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'n_gpus_per_node': 8,
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'nccl_timeout': 600,
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'nnodes': 0,
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'num_workers': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'all_ranks': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'enable': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'ranks': [],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'save_path': 'outputs/profile',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'tool': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                        'analysis': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                        'contents': [],
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                        'discrete': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                        'level': 'level0'},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                         'discrete': False},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                          'step_end': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                          'step_start': 0},
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                 'stack_depth': 32,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                                 'trace_alloc_max_entries': 100000}}},
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'reward_kwargs': {'max_resp_len': 3072,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                     'overlong_buffer_cfg': {'enable': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                             'len': 512,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                             'log': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                                             'penalty_factor': 1.0}},
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'reward_loop_class_name': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'reward_loop_module_path': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'reward_loop_source': 'register',
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'reward_manager': 'dapo',
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'rollout': {'_target_': 'verl.workers.config.RolloutConfig',
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'cudagraph_capture_sizes': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'data_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'disable_log_stats': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'dtype': 'bfloat16',
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'enable_chunked_prefill': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'enable_prefix_caching': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'enforce_eager': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'engine_kwargs': {},
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'expert_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'free_cache_engine': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'gpu_memory_utilization': 0.5,
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'limit_images': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'load_format': 'auto',
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'max_model_len': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'max_num_batched_tokens': 8192,
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'max_num_seqs': 1024,
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'name': '???',
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'prompt_length': 2048,
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'response_length': 2048,
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'skip_tokenizer_init': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m                               'tensor_model_parallel_size': 2},
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'sandbox_fusion': {'max_concurrent': 64,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                      'memory_limit_mb': 1024,
[36m(FullyAsyncTaskRunner pid=357514)[0m                                      'url': None},
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'strategy': 'megatron',
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'use_dynamic_bsz': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m                   'use_reward_loop': True},
[36m(FullyAsyncTaskRunner pid=357514)[0m  'rollout': {'n': 4,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'n_gpus_per_node': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'nnodes': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'test_freq': 20,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'total_epochs': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'total_rollout_steps': 51200},
[36m(FullyAsyncTaskRunner pid=357514)[0m  'trainer': {'balance_batch': True,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'critic_warmup': 0,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'default_hdfs_dir': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m /home/ma-user/work/verl/verl/workers/megatron_workers.py:54: UserWarning: NPU not support router replay for now.
[36m(FullyAsyncTaskRunner pid=357514)[0m   from verl.utils.megatron.router_replay_patch import RouterReplay, RouterReplayAction, apply_router_replay_patch
[36m(FullyAsyncTaskRunner pid=357514)[0m /home/ma-user/work/verl/verl/workers/actor/megatron_actor.py:44: UserWarning: NPU not support router replay for now.
[36m(FullyAsyncTaskRunner pid=357514)[0m   from verl.utils.megatron.router_replay_utils import (
[36m(pid=360588)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=360588)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=360588)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=360588)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=360588)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=360588)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=360588)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=360588)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=360588)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
[36m(pid=360588)[0m     *************************************************************************************************************
[36m(pid=360588)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(pid=360588)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(pid=360588)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(pid=360588)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(pid=360588)[0m     The device parameters have been replaced with npu in the function below:
[36m(pid=360588)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(pid=360588)[0m     *************************************************************************************************************
[36m(pid=360588)[0m     
[36m(pid=360588)[0m   warnings.warn(msg, ImportWarning)
[36m(pid=360588)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(pid=360588)[0m   warnings.warn(msg, RuntimeWarning)
[36m(pid=360588)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(pid=360588)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(pid=360588)[0m   import pkg_resources
[36m(FullyAsyncRollouter pid=360588)[0m /home/ma-user/work/verl/verl/workers/megatron_workers.py:54: UserWarning: NPU not support router replay for now.
[36m(FullyAsyncRollouter pid=360588)[0m   from verl.utils.megatron.router_replay_patch import RouterReplay, RouterReplayAction, apply_router_replay_patch
[36m(FullyAsyncRollouter pid=360588)[0m /home/ma-user/work/verl/verl/workers/actor/megatron_actor.py:44: UserWarning: NPU not support router replay for now.
[36m(FullyAsyncRollouter pid=360588)[0m   from verl.utils.megatron.router_replay_utils import (
[36m(FullyAsyncRollouter pid=360588)[0m Using blocking ray.get inside async actor. This blocks the event loop. Please use `await` on object ref with asyncio.gather if you want to yield execution to the event loop instead.
[36m(pid=361271)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=361271)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=361271)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=361271)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=361271)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=361271)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=361271)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=361271)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=361271)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:345: ImportWarning: 
[36m(pid=361271)[0m     *************************************************************************************************************
[36m(pid=361271)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(pid=361271)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(pid=361271)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(pid=361271)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(pid=361271)[0m     The device parameters have been replaced with npu in the function below:
[36m(pid=361271)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(pid=361271)[0m     *************************************************************************************************************
[36m(pid=361271)[0m     
[36m(pid=361271)[0m   warnings.warn(msg, ImportWarning)
[36m(pid=361271)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(pid=361271)[0m   warnings.warn(msg, RuntimeWarning)
[36m(pid=361271)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(pid=361271)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(pid=361271)[0m   import pkg_resources
[36m(pid=361271)[0m /home/ma-user/work/verl/verl/workers/megatron_workers.py:54: UserWarning: NPU not support router replay for now.
[36m(pid=361271)[0m   from verl.utils.megatron.router_replay_patch import RouterReplay, RouterReplayAction, apply_router_replay_patch
[36m(pid=361271)[0m /home/ma-user/work/verl/verl/workers/actor/megatron_actor.py:44: UserWarning: NPU not support router replay for now.
[36m(pid=361271)[0m   from verl.utils.megatron.router_replay_utils import (
[36m(pid=361271)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/ray/util/state/util.py:55: DeprecationWarning: Ray state API is no longer experimental. Please import from `ray.util.state`. instead. Importing from `ray.experimental` will be deprecated in future releases. 
[36m(pid=361271)[0m   warnings.warn(
[36m(WorkerDict pid=361271)[0m [W102 17:04:54.463023904 compiler_depend.ts:1060] Warning: The watchdog timeout 600000ms(which is set by init_process_group) is less than or equal to HCCL execution timeout 1836000ms! The plog may not be recorded. (function ProcessGroupHCCL)
[36m(WorkerDict pid=361271)[0m /home/ma-user/work/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.
[36m(WorkerDict pid=361271)[0m   warnings.warn("Torch profiler tool config is not fully supported now.", stacklevel=1)
[36m(WorkerDict pid=361271)[0m <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute
[36m(WorkerDict pid=361271)[0m <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute
[36m(FullyAsyncRollouter pid=360588)[0m /home/ma-user/work/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.
[36m(FullyAsyncRollouter pid=360588)[0m   warnings.warn("Torch profiler tool config is not fully supported now.", stacklevel=1)
[36m(pid=362100)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=362100)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=362100)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=362100)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(FullyAsyncRollouter pid=360588)[0m <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute
[36m(FullyAsyncRollouter pid=360588)[0m <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute
[36m(pid=362100)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=362100)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=362100)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=362100)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=362100)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(pid=362100)[0m   import pkg_resources
[36m(pid=362100)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
[36m(pid=362100)[0m     *************************************************************************************************************
[36m(pid=362100)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(pid=362100)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(pid=362100)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(pid=362100)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(pid=362100)[0m     The device parameters have been replaced with npu in the function below:
[36m(pid=362100)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(pid=362100)[0m     *************************************************************************************************************
[36m(pid=362100)[0m     
[36m(pid=362100)[0m   warnings.warn(msg, ImportWarning)
[36m(pid=362100)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(pid=362100)[0m   warnings.warn(msg, RuntimeWarning)
[36m(pid=362100)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(vLLMHttpServerForPartial pid=362100)[0m /home/ma-user/work/verl/verl/workers/megatron_workers.py:54: UserWarning: NPU not support router replay for now.
[36m(vLLMHttpServerForPartial pid=362100)[0m   from verl.utils.megatron.router_replay_patch import RouterReplay, RouterReplayAction, apply_router_replay_patch
[36m(vLLMHttpServerForPartial pid=362100)[0m /home/ma-user/work/verl/verl/workers/actor/megatron_actor.py:44: UserWarning: NPU not support router replay for now.
[36m(vLLMHttpServerForPartial pid=362100)[0m   from verl.utils.megatron.router_replay_utils import (
[36m(FullyAsyncTaskRunner pid=357514)[0m              'default_local_dir': 'checkpoints/GRPO-Qwen2.5-0.5b-Base-MATH/GRPO-Qwen2.5-0.5b-Base-MATH-2gpu-async',
[36m(FullyAsyncTaskRunner pid=357514)[0m              'del_local_ckpt_after_load': False,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'device': 'npu',
[36m(FullyAsyncTaskRunner pid=357514)[0m              'esi_redundant_time': 0,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'experiment_name': 'GRPO-Qwen2.5-0.5b-Base-MATH-2gpu-async',
[36m(FullyAsyncTaskRunner pid=357514)[0m              'log_val_generations': 10,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'logger': ['console', 'tensorboard'],
[36m(FullyAsyncTaskRunner pid=357514)[0m              'max_actor_ckpt_to_keep': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'max_critic_ckpt_to_keep': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'n_gpus_per_node': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'nnodes': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'project_name': 'GRPO-Qwen2.5-0.5b-Base-MATH',
[36m(FullyAsyncTaskRunner pid=357514)[0m              'ray_wait_register_center_timeout': 300,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'resume_from_path': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'resume_mode': 'auto',
[36m(FullyAsyncTaskRunner pid=357514)[0m              'rollout_data_dir': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'save_freq': -1,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'test_freq': -1,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'total_epochs': 1,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'total_training_steps': None,
[36m(FullyAsyncTaskRunner pid=357514)[0m              'use_legacy_worker_impl': 'auto',
[36m(FullyAsyncTaskRunner pid=357514)[0m              'val_before_train': False},
[36m(FullyAsyncTaskRunner pid=357514)[0m  'transfer_queue': {'enable': False}}
[36m(FullyAsyncTaskRunner pid=357514)[0m [ASYNC MAIN] Initializing model and tokenizer...
[36m(FullyAsyncTaskRunner pid=357514)[0m [ASYNC MAIN] Creating worker mapping and resource pools...
[36m(FullyAsyncTaskRunner pid=357514)[0m [ASYNC MAIN] Creating FullyAsyncRollouter...
[36m(pid=360588)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:04:26,704 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter] Creating datasets...
[36m(FullyAsyncRollouter pid=360588)[0m Using dataset class: RLHFDataset
[36m(FullyAsyncRollouter pid=360588)[0m dataset len: 7473
[36m(FullyAsyncRollouter pid=360588)[0m Using dataset class: RLHFDataset
[36m(FullyAsyncRollouter pid=360588)[0m dataset len: 1319
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter] Rollouter _create_dataloader...
[36m(FullyAsyncRollouter pid=360588)[0m <verl.utils.dataset.rl_dataset.RLHFDataset object at 0xffe155f813c0>
[36m(FullyAsyncRollouter pid=360588)[0m <verl.utils.dataset.rl_dataset.RLHFDataset object at 0xffe155b1f280>
[36m(FullyAsyncRollouter pid=360588)[0m Size of train dataloader: 7473, Size of val dataloader: 1
[36m(FullyAsyncRollouter pid=360588)[0m Total training steps: 7473
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter] Total rollout steps: 7473
[36m(FullyAsyncRollouter pid=360588)[0m colocated worker base class <class 'verl.workers.megatron_workers.MegatronWorker'>
[36m(FullyAsyncRollouter pid=360588)[0m bind role rollout method chat_completion to class <class 'verl.single_controller.ray.base.create_colocated_worker_cls.<locals>.WorkerDict'>
[36m(FullyAsyncRollouter pid=360588)[0m bind role rollout method generate to class <class 'verl.single_controller.ray.base.create_colocated_worker_cls.<locals>.WorkerDict'>
[36m(FullyAsyncRollouter pid=360588)[0m bind role rollout method get_zeromq_address to class <class 'verl.single_controller.ray.base.create_colocated_worker_cls.<locals>.WorkerDict'>
[36m(FullyAsyncRollouter pid=360588)[0m bind role rollout method sleep to class <class 'verl.single_controller.ray.base.create_colocated_worker_cls.<locals>.WorkerDict'>
[36m(FullyAsyncRollouter pid=360588)[0m bind role rollout method wake_up to class <class 'verl.single_controller.ray.base.create_colocated_worker_cls.<locals>.WorkerDict'>
[36m(pid=361271)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:04:48,017 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(WorkerDict pid=361271)[0m [DetachAsyncRolloutWorker] (<class 'recipe.fully_async_policy.megatron_worker.DetachAsyncRolloutWorker'>, <class 'recipe.fully_async_policy.megatron_worker.DetachNcclSync'>, <class 'verl.workers.megatron_workers.AsyncActorRolloutRefWorker'>, <class 'verl.workers.megatron_workers.ActorRolloutRefWorker'>, <class 'verl.workers.megatron_workers.MegatronWorker'>, <class 'verl.single_controller.base.worker.Worker'>, <class 'verl.single_controller.base.worker.WorkerHelper'>, <class 'verl.utils.profiler.profile.DistProfilerExtension'>, <class 'object'>)
[36m(WorkerDict pid=361271)[0m WARNING 01-02 17:05:00 [_custom_ops.py:20] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
[36m(FullyAsyncRollouter pid=360588)[0m WARNING 01-02 17:05:05 [api_server.py:1213] LoRA dynamic loading & unloading is enabled in the API server. This should ONLY be used for local development!
[36m(pid=362100)[0m WARNING 01-02 17:05:25 [_custom_ops.py:20] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=362100)[0m WARNING 01-02 17:05:26 [api_server.py:1213] LoRA dynamic loading & unloading is enabled in the API server. This should ONLY be used for local development!
[36m(pid=362100)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:05:27,101 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(vLLMHttpServerForPartial pid=362100)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:05:30,199 INFO [/home/ma-user/work/verl/verl/workers/rollout/vllm_rollout/vllm_async_server.py:217] => vLLMHttpServer, replica_rank: 0, master address: 172.16.0.99, master port: 37619, data parallel master port: 34535
[36m(vLLMHttpServerForPartial pid=362100)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:05:30,208 INFO [/home/ma-user/work/verl/verl/workers/rollout/vllm_rollout/vllm_async_server.py:257] => override_generation_config: {'temperature': 1.0, 'top_k': -1, 'top_p': 1.0, 'repetition_penalty': 1.0, 'max_new_tokens': 3072}
[36m(vLLMHttpServerForPartial pid=362100)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:05:30,209 INFO [/home/ma-user/work/verl/verl/workers/rollout/vllm_rollout/vllm_async_server.py:259] => enable_sleep_mode: True
[36m(vLLMHttpServerForPartial pid=362100)[0m ['serve',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '/home/ma-user/work/models/Qwen2.5-0.5B-Instruct',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '--dtype',
[36m(vLLMHttpServerForPartial pid=362100)[0m  'bfloat16',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '--load_format',
[36m(vLLMHttpServerForPartial pid=362100)[0m  'dummy',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '--max_model_len',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '5120',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '--max_num_seqs',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '1024',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '--enable_chunked_prefill',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '--max_num_batched_tokens',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '5120',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '--enable_prefix_caching',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '--enable_sleep_mode',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '--disable_custom_all_reduce',
[36m(vLLMHttpServerForPartial pid=362100)[0m Using blocking ray.get inside async actor. This blocks the event loop. Please use `await` on object ref with asyncio.gather if you want to yield execution to the event loop instead.
[36m(vLLMHttpServerForPartial pid=362100)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(vLLMHttpServerForPartial pid=362100)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(vLLMHttpServerForPartial pid=362100)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(vLLMHttpServerForPartial pid=362100)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(vLLMHttpServerForPartial pid=362100)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(vLLMHttpServerForPartial pid=362100)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(vLLMHttpServerForPartial pid=362100)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(vLLMHttpServerForPartial pid=362100)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(vLLMHttpServerForPartial pid=362100)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(vLLMHttpServerForPartial pid=362100)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(vLLMHttpServerForPartial pid=362100)[0m   import pkg_resources
[36m(vLLMHttpServerForPartial pid=362100)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
[36m(vLLMHttpServerForPartial pid=362100)[0m     *************************************************************************************************************
[36m(vLLMHttpServerForPartial pid=362100)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(vLLMHttpServerForPartial pid=362100)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(vLLMHttpServerForPartial pid=362100)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(vLLMHttpServerForPartial pid=362100)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(vLLMHttpServerForPartial pid=362100)[0m     The device parameters have been replaced with npu in the function below:
[36m(vLLMHttpServerForPartial pid=362100)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(vLLMHttpServerForPartial pid=362100)[0m     *************************************************************************************************************
[36m(vLLMHttpServerForPartial pid=362100)[0m     
[36m(vLLMHttpServerForPartial pid=362100)[0m   warnings.warn(msg, ImportWarning)
[36m(vLLMHttpServerForPartial pid=362100)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(vLLMHttpServerForPartial pid=362100)[0m   warnings.warn(msg, RuntimeWarning)
[36m(vLLMHttpServerForPartial pid=362100)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(vLLMHttpServerForPartial pid=362100)[0m [1;36m(EngineCore_DP0 pid=362792)[0;0m /home/ma-user/.conda/envs/test01/lib/python3.10/contextlib.py:142: ResourceWarning: Unclosed context <zmq.Context() at 0xffff7d55dda0>
[36m(vLLMHttpServerForPartial pid=362100)[0m [1;36m(EngineCore_DP0 pid=362792)[0;0m   next(self.gen)
[36m(vLLMHttpServerForPartial pid=362100)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/websockets/legacy/__init__.py:6: DeprecationWarning: websockets.legacy is deprecated; see https://websockets.readthedocs.io/en/stable/howto/upgrade.html for upgrade instructions
[36m(vLLMHttpServerForPartial pid=362100)[0m   warnings.warn(  # deprecated in 14.0 - 2024-11-09
[36m(vLLMHttpServerForPartial pid=362100)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/uvicorn/protocols/websockets/websockets_impl.py:17: DeprecationWarning: websockets.server.WebSocketServerProtocol is deprecated
[36m(vLLMHttpServerForPartial pid=362100)[0m   from websockets.server import WebSocketServerProtocol
[36m(vLLMHttpServerForPartial pid=362100)[0m  '--enforce_eager',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '--gpu_memory_utilization',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '0.8',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '--disable_log_stats',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '--tensor_parallel_size',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '1',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '--seed',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '0',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '--override_generation_config',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '{"temperature": 1.0, "top_k": -1, "top_p": 1.0, "repetition_penalty": 1.0, '
[36m(vLLMHttpServerForPartial pid=362100)[0m  '"max_new_tokens": 3072}',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '--hf_overrides',
[36m(vLLMHttpServerForPartial pid=362100)[0m  '{}']
[36m(vLLMHttpServerForPartial pid=362100)[0m WARNING 01-02 17:05:30 [registry.py:582] Model architecture Qwen2VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_vl:AscendQwen2VLForConditionalGeneration.
[36m(vLLMHttpServerForPartial pid=362100)[0m WARNING 01-02 17:05:30 [registry.py:582] Model architecture Qwen3VLMoeForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_5_vl_without_padding:AscendQwen3VLMoeForConditionalGeneration.
[36m(vLLMHttpServerForPartial pid=362100)[0m WARNING 01-02 17:05:30 [registry.py:582] Model architecture Qwen3VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_5_vl_without_padding:AscendQwen3VLForConditionalGeneration.
[36m(vLLMHttpServerForPartial pid=362100)[0m WARNING 01-02 17:05:30 [registry.py:582] Model architecture Qwen2_5_VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_5_vl:AscendQwen2_5_VLForConditionalGeneration.
[36m(vLLMHttpServerForPartial pid=362100)[0m WARNING 01-02 17:05:30 [registry.py:582] Model architecture Qwen2_5OmniModel is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_5_omni_thinker:AscendQwen2_5OmniThinkerForConditionalGeneration.
[36m(vLLMHttpServerForPartial pid=362100)[0m WARNING 01-02 17:05:30 [registry.py:582] Model architecture DeepseekV32ForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.deepseek_v3_2:CustomDeepseekV3ForCausalLM.
[36m(vLLMHttpServerForPartial pid=362100)[0m WARNING 01-02 17:05:30 [registry.py:582] Model architecture Qwen3NextForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen3_next:CustomQwen3NextForCausalLM.
[36m(vLLMHttpServerForPartial pid=362100)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:05:30,356 INFO [/home/ma-user/work/verl/verl/workers/rollout/vllm_rollout/vllm_async_server.py:389] => replica_rank=0, node_rank=0, nnodes=1, get worker zmq addresses: ['ipc:///tmp/verl_vllm_zmq_361271_ma-user.ipc']
[36m(vLLMHttpServerForPartial pid=362100)[0m WARNING 01-02 17:05:30 [platform.py:270] If chunked prefill or prefix caching is enabled, block size must be set to 128.
[36m(vLLMHttpServerForPartial pid=362100)[0m WARNING 01-02 17:05:31 [__init__.py:3036] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: In a Ray actor and can only be spawned
[36m(vLLMHttpServerForPartial pid=362100)[0m WARNING 01-02 17:05:47 [_custom_ops.py:20] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
[36m(vLLMHttpServerForPartial pid=362100)[0m WARNING 01-02 17:05:48 [api_server.py:1213] LoRA dynamic loading & unloading is enabled in the API server. This should ONLY be used for local development!
[36m(vLLMHttpServerForPartial pid=362100)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:05:49,519 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(vLLMHttpServerForPartial pid=362100)[0m [1;36m(EngineCore_DP0 pid=362792)[0;0m WARNING 01-02 17:05:51 [registry.py:582] Model architecture Qwen2VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_vl:AscendQwen2VLForConditionalGeneration.
[36m(vLLMHttpServerForPartial pid=362100)[0m [1;36m(EngineCore_DP0 pid=362792)[0;0m WARNING 01-02 17:05:51 [registry.py:582] Model architecture Qwen3VLMoeForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_5_vl_without_padding:AscendQwen3VLMoeForConditionalGeneration.
[36m(vLLMHttpServerForPartial pid=362100)[0m [1;36m(EngineCore_DP0 pid=362792)[0;0m WARNING 01-02 17:05:51 [registry.py:582] Model architecture Qwen3VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_5_vl_without_padding:AscendQwen3VLForConditionalGeneration.
[36m(vLLMHttpServerForPartial pid=362100)[0m [1;36m(EngineCore_DP0 pid=362792)[0;0m WARNING 01-02 17:05:51 [registry.py:582] Model architecture Qwen2_5_VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_5_vl:AscendQwen2_5_VLForConditionalGeneration.
[36m(vLLMHttpServerForPartial pid=362100)[0m [1;36m(EngineCore_DP0 pid=362792)[0;0m WARNING 01-02 17:05:51 [registry.py:582] Model architecture Qwen2_5OmniModel is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_5_omni_thinker:AscendQwen2_5OmniThinkerForConditionalGeneration.
[36m(vLLMHttpServerForPartial pid=362100)[0m [1;36m(EngineCore_DP0 pid=362792)[0;0m WARNING 01-02 17:05:51 [registry.py:582] Model architecture DeepseekV32ForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.deepseek_v3_2:CustomDeepseekV3ForCausalLM.
[36m(vLLMHttpServerForPartial pid=362100)[0m [1;36m(EngineCore_DP0 pid=362792)[0;0m WARNING 01-02 17:05:51 [registry.py:582] Model architecture Qwen3NextForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen3_next:CustomQwen3NextForCausalLM.
[36m(WorkerDict pid=361271)[0m WARNING 01-02 17:05:56 [cudagraph_dispatcher.py:106] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[36m(WorkerDict pid=361271)[0m WARNING 01-02 17:05:51 [api_server.py:1213] LoRA dynamic loading & unloading is enabled in the API server. This should ONLY be used for local development!
[36m(vLLMHttpServerForPartial pid=362100)[0m [1;36m(EngineCore_DP0 pid=362792)[0;0m WARNING 01-02 17:05:59 [platform.py:270] If chunked prefill or prefix caching is enabled, block size must be set to 128.
[36m(WorkerDict pid=361271)[0m WARNING 01-02 17:05:51 [registry.py:582] Model architecture Qwen3NextForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen3_next:CustomQwen3NextForCausalLM.[32m [repeated 7x across cluster][0m
[36m(vLLMHttpServerForPartial pid=362100)[0m WARNING 01-02 17:05:59 [model.py:1389] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
[36m(vLLMHttpServerForPartial pid=362100)[0m /home/ma-user/work/verl/verl/workers/rollout/vllm_rollout/vllm_async_server.py:428: ResourceWarning: unclosed <socket.socket fd=76, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('172.16.0.99', 39399)>
[36m(vLLMHttpServerForPartial pid=362100)[0m   self._server_port, self._server_task = await run_unvicorn(app, args, self._server_address)
[36m(pid=363348)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=363348)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=363348)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=363348)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=363347)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
[36m(pid=363347)[0m     *************************************************************************************************************
[36m(pid=363347)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(pid=363347)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(pid=363347)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(pid=363347)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(pid=363347)[0m     The device parameters have been replaced with npu in the function below:
[36m(pid=363347)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(pid=363347)[0m     *************************************************************************************************************
[36m(pid=363347)[0m     
[36m(pid=363347)[0m   warnings.warn(msg, ImportWarning)
[36m(pid=363347)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(pid=363347)[0m   warnings.warn(msg, RuntimeWarning)
[36m(pid=363373)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.[32m [repeated 17x across cluster][0m
[36m(pid=363373)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")[32m [repeated 34x across cluster][0m
[36m(pid=363373)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.[32m [repeated 17x across cluster][0m
[36m(pid=363349)[0m     
[36m(pid=363362)[0m     
[36m(pid=363347)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(pid=363347)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(pid=363347)[0m   import pkg_resources
[36m(pid=363364)[0m     
[36m(pid=363348)[0m     
[36m(pid=363363)[0m     
[36m(pid=363366)[0m     
[36m(pid=363373)[0m     
[36m(pid=363365)[0m     
[36m(FullyAsyncTrainer pid=363373)[0m /home/ma-user/work/verl/verl/workers/megatron_workers.py:54: UserWarning: NPU not support router replay for now.
[36m(FullyAsyncTrainer pid=363373)[0m   from verl.utils.megatron.router_replay_patch import RouterReplay, RouterReplayAction, apply_router_replay_patch
[36m(FullyAsyncTrainer pid=363373)[0m /home/ma-user/work/verl/verl/workers/actor/megatron_actor.py:44: UserWarning: NPU not support router replay for now.
[36m(FullyAsyncTrainer pid=363373)[0m   from verl.utils.megatron.router_replay_utils import (
[36m(FullyAsyncTrainer pid=363373)[0m /home/ma-user/work/verl/recipe/fully_async_policy/fully_async_trainer.py:78: UserWarning: Disabled critic as algorithm.adv_estimator != gae. If it is not intended, please set critic.enable=True
[36m(FullyAsyncTrainer pid=363373)[0m   self.use_critic = need_critic(self.config)
[36m(pid=363362)[0m <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute
[36m(pid=363362)[0m <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute
[36m(pid=363365)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: [32m [repeated 8x across cluster][0m
[36m(pid=363365)[0m     *************************************************************************************************************[32m [repeated 16x across cluster][0m
[36m(pid=363365)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..[32m [repeated 8x across cluster][0m
[36m(pid=363365)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..[32m [repeated 8x across cluster][0m
[36m(pid=363365)[0m     The backend in torch.distributed.init_process_group set to hccl now..[32m [repeated 8x across cluster][0m
[36m(pid=363365)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..[32m [repeated 8x across cluster][0m
[36m(pid=363365)[0m     The device parameters have been replaced with npu in the function below:[32m [repeated 8x across cluster][0m
[36m(pid=363365)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty[32m [repeated 8x across cluster][0m
[36m(pid=363365)[0m   warnings.warn(msg, ImportWarning)[32m [repeated 8x across cluster][0m
[36m(pid=363365)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.[32m [repeated 8x across cluster][0m
[36m(pid=363365)[0m   warnings.warn(msg, RuntimeWarning)[32m [repeated 8x across cluster][0m
[36m(pid=363365)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...[32m [repeated 8x across cluster][0m
[36m(pid=363365)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.[32m [repeated 8x across cluster][0m
[36m(pid=363365)[0m   import pkg_resources[32m [repeated 8x across cluster][0m
[36m(pid=365376)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=365376)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=365376)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=365376)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=363366)[0m <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute[32m [repeated 7x across cluster][0m
[36m(pid=363366)[0m <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute[32m [repeated 7x across cluster][0m
[36m(pid=365376)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=365376)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=365376)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=365376)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=365497)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.[32m [repeated 9x across cluster][0m
[36m(pid=365497)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")[32m [repeated 18x across cluster][0m
[36m(pid=365497)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.[32m [repeated 9x across cluster][0m
[36m(pid=365376)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:345: ImportWarning: 
[36m(pid=365376)[0m     *************************************************************************************************************
[36m(pid=365376)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(pid=365376)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(pid=365376)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(pid=365376)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(pid=365376)[0m     The device parameters have been replaced with npu in the function below:
[36m(pid=365376)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(pid=365376)[0m     *************************************************************************************************************
[36m(pid=365376)[0m     
[36m(pid=365376)[0m   warnings.warn(msg, ImportWarning)
[36m(pid=365376)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(pid=365376)[0m   warnings.warn(msg, RuntimeWarning)
[36m(pid=365376)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(pid=365376)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(pid=365376)[0m   import pkg_resources
[36m(pid=365376)[0m /home/ma-user/work/verl/verl/workers/megatron_workers.py:54: UserWarning: NPU not support router replay for now.
[36m(pid=365376)[0m   from verl.utils.megatron.router_replay_patch import RouterReplay, RouterReplayAction, apply_router_replay_patch
[36m(pid=365376)[0m /home/ma-user/work/verl/verl/workers/actor/megatron_actor.py:44: UserWarning: NPU not support router replay for now.
[36m(pid=365376)[0m   from verl.utils.megatron.router_replay_utils import (
[36m(pid=365529)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.[32m [repeated 7x across cluster][0m
[36m(pid=365529)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")[32m [repeated 14x across cluster][0m
[36m(pid=365529)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.[32m [repeated 7x across cluster][0m
[36m(pid=365497)[0m     
[36m(pid=365376)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/ray/util/state/util.py:55: DeprecationWarning: Ray state API is no longer experimental. Please import from `ray.util.state`. instead. Importing from `ray.experimental` will be deprecated in future releases. 
[36m(pid=365376)[0m   warnings.warn(
[36m(pid=365501)[0m     
[36m(pid=365506)[0m     
[36m(pid=365506)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: [32m [repeated 3x across cluster][0m
[36m(pid=365506)[0m     *************************************************************************************************************[32m [repeated 6x across cluster][0m
[36m(pid=365506)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..[32m [repeated 3x across cluster][0m
[36m(pid=365506)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..[32m [repeated 3x across cluster][0m
[36m(pid=365506)[0m     The backend in torch.distributed.init_process_group set to hccl now..[32m [repeated 3x across cluster][0m
[36m(pid=365506)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..[32m [repeated 3x across cluster][0m
[36m(pid=365506)[0m     The device parameters have been replaced with npu in the function below:[32m [repeated 3x across cluster][0m
[36m(pid=365506)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty[32m [repeated 3x across cluster][0m
[36m(pid=365506)[0m   warnings.warn(msg, ImportWarning)[32m [repeated 3x across cluster][0m
[36m(pid=365501)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.[32m [repeated 2x across cluster][0m
[36m(pid=365501)[0m   warnings.warn(msg, RuntimeWarning)[32m [repeated 2x across cluster][0m
[36m(pid=365510)[0m     
[36m(pid=365526)[0m     
[36m(pid=365499)[0m     
[36m(pid=365527)[0m     
[36m(pid=365529)[0m     
[36m(pid=365529)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...[32m [repeated 8x across cluster][0m
[36m(pid=365529)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.[32m [repeated 8x across cluster][0m
[36m(pid=365529)[0m   import pkg_resources[32m [repeated 8x across cluster][0m
[36m(WorkerDict pid=365376)[0m [W102 17:06:44.789104495 compiler_depend.ts:1060] Warning: The watchdog timeout 600000ms(which is set by init_process_group) is less than or equal to HCCL execution timeout 1836000ms! The plog may not be recorded. (function ProcessGroupHCCL)
[36m(WorkerDict pid=365376)[0m /home/ma-user/work/verl/verl/models/mcore/config_converter.py:182: UserWarning: The following keys are not supported in the current Megatron version and will be removed: ['use_flash_attn']
[36m(WorkerDict pid=365376)[0m   return check_and_construct_configs(args, TransformerConfig)
[36m(pid=365529)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: [32m [repeated 5x across cluster][0m
[36m(pid=365529)[0m     *************************************************************************************************************[32m [repeated 10x across cluster][0m
[36m(pid=365529)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..[32m [repeated 5x across cluster][0m
[36m(pid=365529)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..[32m [repeated 5x across cluster][0m
[36m(pid=365529)[0m     The backend in torch.distributed.init_process_group set to hccl now..[32m [repeated 5x across cluster][0m
[36m(pid=365529)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..[32m [repeated 5x across cluster][0m
[36m(pid=365529)[0m     The device parameters have been replaced with npu in the function below:[32m [repeated 5x across cluster][0m
[36m(pid=365529)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty[32m [repeated 5x across cluster][0m
[36m(pid=365529)[0m   warnings.warn(msg, ImportWarning)[32m [repeated 5x across cluster][0m
[36m(pid=365529)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.[32m [repeated 6x across cluster][0m
[36m(pid=365529)[0m   warnings.warn(msg, RuntimeWarning)[32m [repeated 6x across cluster][0m
[36m(vLLMHttpServerForPartial pid=362100)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:05:59,780 INFO [/home/ma-user/work/verl/verl/workers/rollout/vllm_rollout/vllm_async_server.py:425] => Initializing a V1 LLM engine with config: model='/home/ma-user/work/models/Qwen2.5-0.5B-Instruct', speculative_config=None, tokenizer='/home/ma-user/work/models/Qwen2.5-0.5B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=5120, download_dir=None, load_format=dummy, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=npu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/home/ma-user/work/models/Qwen2.5-0.5B-Instruct, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":["all"],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[36m(FullyAsyncRollouter pid=360588)[0m AgentLoopManager: ['172.16.0.99:39399']
[36m(vLLMHttpServerForPartial pid=362100)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:06:00,425 INFO [/home/ma-user/work/verl/verl/workers/rollout/utils.py:67] => HTTP server started on port 39399
[36m(FullyAsyncTaskRunner pid=357514)[0m [ASYNC MAIN] Rollouter created and initialized successfully
[36m(FullyAsyncTaskRunner pid=357514)[0m [ASYNC MAIN] Creating FullyAsyncTrainer...
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter] required_samples : 64 max_required_samples: 307 max_queue_size: 307 total_train_steps: 29 total_rollout_steps: 7473 max_concurrent_samples: 128 
[36m(pid=363347)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:06:16,802 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(FullyAsyncTrainer pid=363373)[0m colocated worker base class <class 'verl.workers.megatron_workers.MegatronWorker'>
[36m(pid=363362)[0m WARNING 01-02 17:06:22 [_custom_ops.py:20] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
[36m(pid=363365)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:06:17,813 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.[32m [repeated 8x across cluster][0m
[36m(pid=363362)[0m WARNING 01-02 17:06:23 [api_server.py:1213] LoRA dynamic loading & unloading is enabled in the API server. This should ONLY be used for local development!
[36m(pid=363365)[0m WARNING 01-02 17:06:23 [_custom_ops.py:20] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")[32m [repeated 7x across cluster][0m
[36m(pid=365376)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:06:36,500 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(pid=363366)[0m WARNING 01-02 17:06:24 [api_server.py:1213] LoRA dynamic loading & unloading is enabled in the API server. This should ONLY be used for local development![32m [repeated 7x across cluster][0m
[36m(pid=365497)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:06:39,666 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(WorkerDict pid=365376)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=365376)[0m   "architectures": [
[36m(WorkerDict pid=365376)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=365376)[0m   ],
[36m(WorkerDict pid=365376)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=365376)[0m   "dtype": "bfloat16",
[36m(WorkerDict pid=365376)[0m   "eos_token_id": 151645,
[36m(WorkerDict pid=365376)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=365376)[0m   "hidden_size": 896,
[36m(WorkerDict pid=365376)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=365376)[0m   "intermediate_size": 4864,
[36m(WorkerDict pid=365376)[0m   "layer_types": [
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention"
[36m(WorkerDict pid=365376)[0m   ],
[36m(WorkerDict pid=365376)[0m   "max_position_embeddings": 5120,
[36m(WorkerDict pid=365376)[0m   "max_window_layers": 21,
[36m(WorkerDict pid=365376)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=365376)[0m   "num_attention_heads": 14,
[36m(WorkerDict pid=365376)[0m   "num_hidden_layers": 24,
[36m(WorkerDict pid=365376)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=365376)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=365376)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=365376)[0m   "rope_scaling": null,
[36m(WorkerDict pid=365376)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=365376)[0m   "sliding_window": null,
[36m(WorkerDict pid=365376)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=365376)[0m   "transformers_version": "4.57.3",
[36m(WorkerDict pid=365376)[0m   "use_cache": true,
[36m(WorkerDict pid=365376)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=365376)[0m   "vocab_size": 151936
[36m(WorkerDict pid=365376)[0m }
[36m(WorkerDict pid=365376)[0m 
[36m(WorkerDict pid=365376)[0m Overridden TransformerConfig init config: {'num_layers': 24, 'hidden_size': 896, 'num_attention_heads': 14, 'num_query_groups': 2, 'ffn_hidden_size': 4864, 'attention_dropout': 0.0, 'hidden_dropout': 0.0, 'kv_channels': None, 'layernorm_epsilon': 1e-06, 'add_bias_linear': False, 'activation_func': <function silu at 0xffff0c215090>, 'normalization': 'RMSNorm', 'gated_linear_unit': True, 'pipeline_dtype': torch.bfloat16, 'params_dtype': torch.bfloat16, 'bf16': True, 'tensor_model_parallel_size': 1, 'pipeline_model_parallel_size': 1, 'expert_model_parallel_size': 1, 'expert_tensor_parallel_size': 1, 'virtual_pipeline_model_parallel_size': None, 'context_parallel_size': 1, 'overlap_p2p_comm': False, 'batch_p2p_comm': False, 'sequence_parallel': False, 'variable_seq_lengths': True, 'masked_softmax_fusion': True, 'moe_token_dispatcher_type': 'alltoall', 'use_cpu_initialization': False, 'add_qkv_bias': True, 'qk_layernorm': False, 'recompute_granularity': None, 'recompute_modules': ['core_attn'], 'recompute_method': None, 'recompute_num_layers': None, 'attention_backend': <AttnBackend.flash: 1>, 'apply_rope_fusion': True, 'bias_activation_fusion': True, 'bias_dropout_fusion': True, 'gradient_accumulation_fusion': True, 'deallocate_pipeline_outputs': True, 'persist_layer_norm': True}
[36m(pid=365529)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:06:41,529 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=365376)[0m TF config: TransformerConfig(tensor_model_parallel_size=1, pipeline_model_parallel_comm_backend=None, pipeline_model_parallel_size=1, virtual_pipeline_model_parallel_size=None, sequence_parallel=False, context_parallel_size=1, hierarchical_context_parallel_sizes=None, expert_model_parallel_size=1, expert_tensor_parallel_size=1, moe_extended_tp=False, perform_initialization=True, use_cpu_initialization=False, fp16=False, bf16=True, params_dtype=torch.bfloat16, timers=None, finalize_model_grads_func=None, grad_scale_func=None, no_sync_func=None, grad_sync_func=None, param_sync_func=None, deterministic_mode=False, enable_autocast=False, autocast_dtype=torch.bfloat16, num_microbatches_with_partial_activation_checkpoints=None, gradient_accumulation_fusion=True, async_tensor_model_parallel_allreduce=False, use_te_rng_tracker=False, tp_comm_overlap=False, tp_comm_bulk_wgrad=True, tp_comm_bulk_dgrad=True, tp_comm_overlap_ag=True, tp_comm_overlap_rs=True, tp_comm_overlap_rs_dgrad=False, tp_comm_split_ag=True, tp_comm_atomic_ag=False, tp_comm_split_rs=True, tp_comm_atomic_rs=False, cross_entropy_loss_fusion=False, cross_entropy_fusion_impl='native', tp_comm_overlap_disable_qkv=False, tp_comm_overlap_disable_fc1=False, tp_comm_bootstrap_backend='nccl', pipeline_dtype=torch.bfloat16, variable_seq_lengths=True, overlap_p2p_comm=False, batch_p2p_comm=False, batch_p2p_sync=True, use_ring_exchange_p2p=False, deallocate_pipeline_outputs=True, defer_embedding_wgrad_compute=False, wgrad_deferral_limit=0, pipeline_model_parallel_split_rank=None, overlap_p2p_comm_warmup_flush=False, microbatch_group_size_per_vp_stage=1, cpu_offloading=False, cpu_offloading_num_layers=0, _cpu_offloading_context=None, cpu_offloading_activations=True, cpu_offloading_weights=True, barrier_with_L1_time=True, num_layers=24, mtp_num_layers=None, mtp_loss_scaling_factor=None, num_layers_in_first_pipeline_stage=None, num_layers_in_last_pipeline_stage=None, account_for_embedding_in_pipeline_split=False, account_for_loss_in_pipeline_split=False, hidden_size=896, num_attention_heads=14, attention_backend=<AttnBackend.flash: 1>, softmax_scale=None, num_query_groups=2, ffn_hidden_size=4864, kv_channels=64, hidden_dropout=0.0, attention_dropout=0.0, fp32_residual_connection=False, apply_residual_connection_post_layernorm=False, layernorm_epsilon=1e-06, layernorm_zero_centered_gamma=False, add_bias_linear=False, add_qkv_bias=True, gated_linear_unit=True, activation_func=<function silu at 0xffff0c215090>, activation_func_fp8_input_store=False, num_moe_experts=None, rotary_interleaved=False, window_size=None, normalization='RMSNorm', qk_layernorm=False, test_mode=False, calculate_per_token_loss=False, multi_latent_attention=False, init_method=functools.partial(<function normal_ at 0xffff0c29dcf0>, mean=0.0, std=0.02), output_layer_init_method=functools.partial(<function normal_ at 0xffff0c29dcf0>, mean=0.0, std=0.002886751345948129), init_method_std=0.02, init_model_with_meta_device=False, apply_query_key_layer_scaling=False, attention_softmax_in_fp32=True, disable_bf16_reduced_precision_matmul=False, bias_activation_fusion=True, masked_softmax_fusion=True, persist_layer_norm=True, memory_efficient_layer_norm=False, bias_dropout_fusion=True, apply_rope_fusion=True, recompute_granularity=None, recompute_method=None, recompute_num_layers=None, distribute_saved_activations=None, recompute_modules=['core_attn'], fp8=None, fp8_recipe='delayed', fp8_param=False, fp8_margin=0, fp8_interval=1, fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', fp8_wgrad=True, fp8_dot_product_attention=False, fp8_multi_head_attention=False, tp_only_amax_red=False, first_last_layers_bf16=False, num_layers_at_start_in_bf16=1, num_layers_at_end_in_bf16=1, moe_shared_expert_intermediate_size=None, moe_shared_expert_overlap=False, moe_layer_freq=1, moe_ffn_hidden_size=4864, moe_router_load_balancing_type='aux_loss', moe_router_topk=2, moe_router_topk_limited_devices=None, moe_router_num_groups=None, moe_router_group_topk=None, moe_router_pre_softmax=False, moe_router_topk_scaling_factor=None, moe_router_score_function='softmax', moe_router_dtype=None, moe_router_enable_expert_bias=False, moe_router_bias_update_rate=0.001, moe_grouped_gemm=False, moe_use_legacy_grouped_gemm=False, moe_aux_loss_coeff=0, moe_z_loss_coeff=None, moe_input_jitter_eps=None, moe_token_dropping=False, moe_token_dispatcher_type='alltoall', moe_enable_deepep=False, moe_per_layer_logging=False, moe_expert_capacity_factor=None, moe_pad_expert_input_to_capacity=False, moe_token_drop_policy='probs', moe_layer_recompute=False, moe_permute_fusion=False, moe_apply_probs_on_input=False, cp_comm_type=None, enable_cuda_graph=False, cuda_graph_use_single_mempool=False, cuda_graph_retain_backward_graph=False, cuda_graph_warmup_steps=3, external_cuda_graph=False, cuda_graph_scope='full', clone_scatter_output_in_embedding=True, disable_parameter_transpose_cache=False, config_logger_dir='', flash_decode=False, inference_rng_tracker=False, mrope_section=None, is_hybrid_model=False, mamba_state_dim=128, mamba_head_dim=64, mamba_num_groups=8, heterogeneous_block_specs=False, optimizer_selection='fused_adamw', optimization_level=2, use_fused_rmsnorm=False, use_fused_swiglu=False, use_gmm_fp8=True, te_comparison_with_cpu=False, te_comparison_with_bf16=False, context_parallel_algo='megatron_cp_algo', cp_window_size=1, attention_mask_type='causal', use_cp_send_recv_overlap=False, use_fused_ring_attention_update=False, megatron_cp_in_bnsd=False, ulysses_degree_in_cp=None, context_parallel_kv_cache_policy=None, context_parallel_cache_interval=0, use_ulysses_allgather_kv=False, attention_mask_on_cpu=False, adaptive_cp_without_coarse=False, adaptive_cp_dynamic_attn_mask=False, adaptive_cp_only_reschedule=False, adaptive_cp_manually_set_mask_list=False, async_log_allreduce=False, use_fused_rotary_pos_emb=False, use_fused_moe_token_permute_and_unpermute=False, npu_deterministic=False, op_cal_tflops=False, profile_level='level0', profile_with_cpu=False, profile_with_stack=False, profile_with_memory=False, profile_record_shapes=False, profile_save_path='./profile_dir', recompute_activation_function=False, recompute_activation_function_num_layers=None, recompute_norm=False, recompute_norm_num_layers=None, enable_recompute_layers_per_pp_rank=False, unaligned_linear=False, use_ascend_mc2=False, use_ascend_coc=False, coc_mode=-1, coc_parallel_num=1, coc_fused_kernel=False, tp_2d=False, tp_x=1, tp_y=1, enable_overlap_ag_with_matmul=False, enable_overlap_matmul_with_rs=False, enable_backward_overlap_ag_with_matmul=False, recompute_in_bubble=False, recompute_in_advance=False, noop_layers=None, use_multiparameter_pipeline_model_parallel=False, optimize_send_recv_comm=False, pipeline_num_transformer_layers=None, schedules_method=None, dualpipev_dw_detach=False, gemm_gradient_accumulation_fusion=False, moe_tp_extend_ep=False, moe_permutation_async_comm=False, n_shared_experts=None, moe_allgather_overlap_comm=False, moe_alltoall_overlap_comm=False, moe_zero_memory='disable', moe_zero_memory_num_layers=None, moe_fb_overlap=False, moe_unperm2_mem_optim_swap=False, balanced_moe_experts=False, balanced_moe_hot_expert_num=3, trans_hot_expert_group_num=4, enable_expert_placement=False, expert_placement_freq=50, enable_fine_grained_expert_placement=False, print_expert_load=False, fine_grained_expert_placement_thre=0.08, hccl_group_buffer=None, hccl_group_buffer_adaptive=False, hccl_ep_group_buffer_adaptive_factor=-1.0, ema_decay=0.9999, virtual_optimizer=None, quant_states=None, quant_grads=False, dist_train=False, tokenizer_name_or_path=None, tokenizer_not_use_fast=True, param_and_grad_buffer_pad=None, layerzero=False, layerzero_config=None, fsdp2_config_path=None, reset_bucket_group_order=False, reuse_fp32_param=False, smart_swap=False, swap_attention=False, swap_modules='input_norm,self_attention,post_attention_norm', compress_dense='disable', disable_gloo_group=False, hccl_slice_size=10485760, swap_optimizer=False, swap_optimizer_times=16, pre_tockens=65536, next_tockens=0, sparse_mode=0, use_fusion_attn_v2=False, square_alibi_mask=False, fill_neg_inf=False, alibi_fusion_attn_type=None, alibi_diagonal_opposite=False, multi_head_latent_attention=False, qk_rope_head_dim=None, qk_nope_head_dim=None, ai_framework='pytorch', auto_settings=False, auto_settings_work_dir='/home/ma-user/work/verl', auto_settings_ranks=8, auto_settings_log_level='info', target_nnodes=1, nnodes=1, nproc_per_node=1, node_rank=0, auto_settings_type='white', prof_file=None, master_addr='127.0.0.1', master_port=29500, automated_pipeline=False, automated_pipeline_perf=False, recompute_module_list=None, jit_compile=False, node_ip_address='172.16.0.99', node_manager_port='45639', object_store_name='/tmp/ray/session_2026-01-02_17-03-40_712406_352544/sockets/plasma_store', raylet_name='/tmp/ray/session_2026-01-02_17-03-40_712406_352544/sockets/raylet', redis_address='None', metrics_agent_port='61289', logging_rotate_bytes='536870912', logging_rotate_backup_count='5', runtime_env_agent_port='64055', gcs_address='172.16.0.99:65454', session_name='session_2026-01-02_17-03-40_712406_352544', temp_dir='/tmp/ray', webui='127.0.0.1:8265', cluster_id='9add5208ab0ee3dfa31e107829a831629531b24f8ae6e4a93d7b02cf', startup_token='62', worker_launch_time_ms='1767344781356', node_id='d965e5f3387a710fe18fc46d53e06f1834513854357cb26e7b7140db', runtime_env_hash='-602549344', quant_states_enabled=False, quant_grads_dtype=None, use_quant_optimizer=False, use_flash_attn=True)[36m(WorkerDict pid=365376)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=365376)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=365376)[0m   warnings.warn(  # warn only once

[36m(WorkerDict pid=365376)[0m  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 494032768
[36m(WorkerDict pid=365376)[0m load ref weight start
[36m(WorkerDict pid=365376)[0m load from local dir /home/ma-user/work/models/Qwen2.5-0.5B-Instruct
[36m(WorkerDict pid=365376)[0m loading embeddings...
[36m(WorkerDict pid=365376)[0m loading layer #0, with layer_name model.layers.0...
[36m(WorkerDict pid=365376)[0m loading layer #1, with layer_name model.layers.1...
[36m(WorkerDict pid=365376)[0m loading layer #2, with layer_name model.layers.2...
[36m(WorkerDict pid=365376)[0m loading layer #3, with layer_name model.layers.3...
[36m(WorkerDict pid=365376)[0m loading layer #4, with layer_name model.layers.4...
[36m(WorkerDict pid=365376)[0m loading layer #5, with layer_name model.layers.5...
[36m(WorkerDict pid=365376)[0m loading layer #6, with layer_name model.layers.6...
[36m(WorkerDict pid=365376)[0m loading layer #7, with layer_name model.layers.7...
[36m(WorkerDict pid=365376)[0m loading layer #8, with layer_name model.layers.8...
[36m(WorkerDict pid=365376)[0m loading layer #9, with layer_name model.layers.9...
[36m(WorkerDict pid=365376)[0m loading layer #10, with layer_name model.layers.10...
[36m(WorkerDict pid=365376)[0m loading layer #11, with layer_name model.layers.11...
[36m(WorkerDict pid=365376)[0m loading layer #12, with layer_name model.layers.12...
[36m(WorkerDict pid=365376)[0m loading layer #13, with layer_name model.layers.13...
[36m(WorkerDict pid=365376)[0m loading layer #14, with layer_name model.layers.14...
[36m(WorkerDict pid=365376)[0m loading layer #15, with layer_name model.layers.15...
[36m(WorkerDict pid=365376)[0m loading layer #16, with layer_name model.layers.16...
[36m(WorkerDict pid=365376)[0m loading layer #17, with layer_name model.layers.17...
[36m(WorkerDict pid=365376)[0m loading layer #18, with layer_name model.layers.18...
[36m(WorkerDict pid=365376)[0m loading layer #19, with layer_name model.layers.19...
[36m(WorkerDict pid=365376)[0m loading layer #20, with layer_name model.layers.20...
[36m(WorkerDict pid=365376)[0m loading layer #21, with layer_name model.layers.21...
[36m(WorkerDict pid=365376)[0m loading layer #22, with layer_name model.layers.22...
[36m(WorkerDict pid=365376)[0m loading layer #23, with layer_name model.layers.23...
[36m(WorkerDict pid=365376)[0m loading final layernorm...
[36m(WorkerDict pid=365376)[0m loading lm_head...
[36m(WorkerDict pid=365376)[0m loading megatron ckpt done, time elapsed 2.584099054336548s
[36m(WorkerDict pid=365376)[0m [Warining] Because actor tp size == 1, set sp to False
[36m(WorkerDict pid=365376)[0m TransformerConfig(tensor_model_parallel_size=1, pipeline_model_parallel_comm_backend=None, pipeline_model_parallel_size=1, virtual_pipeline_model_parallel_size=None, sequence_parallel=False, context_parallel_size=1, hierarchical_context_parallel_sizes=None, expert_model_parallel_size=1, expert_tensor_parallel_size=1, moe_extended_tp=False, perform_initialization=True, use_cpu_initialization=False, fp16=False, bf16=True, params_dtype=torch.bfloat16, timers=None, finalize_model_grads_func=None, grad_scale_func=None, no_sync_func=None, grad_sync_func=None, param_sync_func=None, deterministic_mode=False, enable_autocast=False, autocast_dtype=torch.bfloat16, num_microbatches_with_partial_activation_checkpoints=None, gradient_accumulation_fusion=True, async_tensor_model_parallel_allreduce=False, use_te_rng_tracker=False, tp_comm_overlap=False, tp_comm_bulk_wgrad=True, tp_comm_bulk_dgrad=True, tp_comm_overlap_ag=True, tp_comm_overlap_rs=True, tp_comm_overlap_rs_dgrad=False, tp_comm_split_ag=True, tp_comm_atomic_ag=False, tp_comm_split_rs=True, tp_comm_atomic_rs=False, cross_entropy_loss_fusion=False, cross_entropy_fusion_impl='native', tp_comm_overlap_disable_qkv=False, tp_comm_overlap_disable_fc1=False, tp_comm_bootstrap_backend='nccl', pipeline_dtype=torch.bfloat16, variable_seq_lengths=True, overlap_p2p_comm=False, batch_p2p_comm=False, batch_p2p_sync=True, use_ring_exchange_p2p=False, deallocate_pipeline_outputs=True, defer_embedding_wgrad_compute=False, wgrad_deferral_limit=0, pipeline_model_parallel_split_rank=None, overlap_p2p_comm_warmup_flush=False, microbatch_group_size_per_vp_stage=1, cpu_offloading=False, cpu_offloading_num_layers=0, _cpu_offloading_context=None, cpu_offloading_activations=True, cpu_offloading_weights=True, barrier_with_L1_time=True, num_layers=24, mtp_num_layers=None, mtp_loss_scaling_factor=None, num_layers_in_first_pipeline_stage=None, num_layers_in_last_pipeline_stage=None, account_for_embedding_in_pipeline_split=False, account_for_loss_in_pipeline_split=False, hidden_size=896, num_attention_heads=14, attention_backend=<AttnBackend.flash: 1>, softmax_scale=None, num_query_groups=2, ffn_hidden_size=4864, kv_channels=64, hidden_dropout=0.0, attention_dropout=0.0, fp32_residual_connection=False, apply_residual_connection_post_layernorm=False, layernorm_epsilon=1e-06, layernorm_zero_centered_gamma=False, add_bias_linear=False, add_qkv_bias=True, gated_linear_unit=True, activation_func=<function silu at 0xffff0c215090>, activation_func_fp8_input_store=False, num_moe_experts=None, rotary_interleaved=False, window_size=None, normalization='RMSNorm', qk_layernorm=False, test_mode=False, calculate_per_token_loss=False, multi_latent_attention=False, init_method=functools.partial(<function normal_ at 0xffff0c29dcf0>, mean=0.0, std=0.02), output_layer_init_method=functools.partial(<function normal_ at 0xffff0c29dcf0>, mean=0.0, std=0.002886751345948129), init_method_std=0.02, init_model_with_meta_device=False, apply_query_key_layer_scaling=False, attention_softmax_in_fp32=True, disable_bf16_reduced_precision_matmul=False, bias_activation_fusion=True, masked_softmax_fusion=True, persist_layer_norm=True, memory_efficient_layer_norm=False, bias_dropout_fusion=True, apply_rope_fusion=True, recompute_granularity=None, recompute_method=None, recompute_num_layers=None, distribute_saved_activations=None, recompute_modules=['core_attn'], fp8=None, fp8_recipe='delayed', fp8_param=False, fp8_margin=0, fp8_interval=1, fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', fp8_wgrad=True, fp8_dot_product_attention=False, fp8_multi_head_attention=False, tp_only_amax_red=False, first_last_layers_bf16=False, num_layers_at_start_in_bf16=1, num_layers_at_end_in_bf16=1, moe_shared_expert_intermediate_size=None, moe_shared_expert_overlap=False, moe_layer_freq=1, moe_ffn_hidden_size=4864, moe_router_load_balancing_type='aux_loss', moe_router_topk=2, moe_router_topk_limited_devices=None, moe_router_num_groups=None, moe_router_group_topk=None, moe_router_pre_softmax=False, moe_router_topk_scaling_factor=None, moe_router_score_function='softmax', moe_router_dtype=None, moe_router_enable_expert_bias=False, moe_router_bias_update_rate=0.001, moe_grouped_gemm=False, moe_use_legacy_grouped_gemm=False, moe_aux_loss_coeff=0, moe_z_loss_coeff=None, moe_input_jitter_eps=None, moe_token_dropping=False, moe_token_dispatcher_type='alltoall', moe_enable_deepep=False, moe_per_layer_logging=False, moe_expert_capacity_factor=None, moe_pad_expert_input_to_capacity=False, moe_token_drop_policy='probs', moe_layer_recompute=False, moe_permute_fusion=False, moe_apply_probs_on_input=False, cp_comm_type=None, enable_cuda_graph=False, cuda_graph_use_single_mempool=False, cuda_graph_retain_backward_graph=False, cuda_graph_warmup_steps=3, external_cuda_graph=False, cuda_graph_scope='full', clone_scatter_output_in_embedding=True, disable_parameter_transpose_cache=False, config_logger_dir='', flash_decode=False, inference_rng_tracker=False, mrope_section=None, is_hybrid_model=False, mamba_state_dim=128, mamba_head_dim=64, mamba_num_groups=8, heterogeneous_block_specs=False, optimizer_selection='fused_adamw', optimization_level=2, use_fused_rmsnorm=True, use_fused_swiglu=False, use_gmm_fp8=True, te_comparison_with_cpu=False, te_comparison_with_bf16=False, context_parallel_algo='megatron_cp_algo', cp_window_size=1, attention_mask_type='causal', use_cp_send_recv_overlap=False, use_fused_ring_attention_update=False, megatron_cp_in_bnsd=False, ulysses_degree_in_cp=None, context_parallel_kv_cache_policy=None, context_parallel_cache_interval=0, use_ulysses_allgather_kv=False, attention_mask_on_cpu=False, adaptive_cp_without_coarse=False, adaptive_cp_dynamic_attn_mask=False, adaptive_cp_only_reschedule=False, adaptive_cp_manually_set_mask_list=False, async_log_allreduce=False, use_fused_rotary_pos_emb=False, use_fused_moe_token_permute_and_unpermute=False, npu_deterministic=False, op_cal_tflops=False, profile_level='level0', profile_with_cpu=False, profile_with_stack=False, profile_with_memory=False, profile_record_shapes=False, profile_save_path='./profile_dir', recompute_activation_function=False, recompute_activation_function_num_layers=None, recompute_norm=False, recompute_norm_num_layers=None, enable_recompute_layers_per_pp_rank=False, unaligned_linear=False, use_ascend_mc2=False, use_ascend_coc=False, coc_mode=-1, coc_parallel_num=1, coc_fused_kernel=False, tp_2d=False, tp_x=1, tp_y=1, enable_overlap_ag_with_matmul=False, enable_overlap_matmul_with_rs=False, enable_backward_overlap_ag_with_matmul=False, recompute_in_bubble=False, recompute_in_advance=False, noop_layers=None, use_multiparameter_pipeline_model_parallel=False, optimize_send_recv_comm=False, pipeline_num_transformer_layers=None, schedules_method=None, dualpipev_dw_detach=False, gemm_gradient_accumulation_fusion=False, moe_tp_extend_ep=False, moe_permutation_async_comm=False, n_shared_experts=None, moe_allgather_overlap_comm=False, moe_alltoall_overlap_comm=False, moe_zero_memory='disable', moe_zero_memory_num_layers=None, moe_fb_overlap=False, moe_unperm2_mem_optim_swap=False, balanced_moe_experts=False, balanced_moe_hot_expert_num=3, trans_hot_expert_group_num=4, enable_expert_placement=False, expert_placement_freq=50, enable_fine_grained_expert_placement=False, print_expert_load=False, fine_grained_expert_placement_thre=0.08, hccl_group_buffer=None, hccl_group_buffer_adaptive=False, hccl_ep_group_buffer_adaptive_factor=-1.0, ema_decay=0.9999, virtual_optimizer=None, quant_states=None, quant_grads=False, dist_train=False, tokenizer_name_or_path=None, tokenizer_not_use_fast=True, param_and_grad_buffer_pad=None, layerzero=False, layerzero_config=None, fsdp2_config_path=None, reset_bucket_group_order=False, reuse_fp32_param=False, smart_swap=False, swap_attention=False, swap_modules='input_norm,self_attention,post_attention_norm', compress_dense='disable', disable_gloo_group=False, hccl_slice_size=10485760, swap_optimizer=False, swap_optimizer_times=16, pre_tockens=65536, next_tockens=0, sparse_mode=0, use_fusion_attn_v2=False, square_alibi_mask=False, fill_neg_inf=False, alibi_fusion_attn_type=None, alibi_diagonal_opposite=False, multi_head_latent_attention=False, qk_rope_head_dim=None, qk_nope_head_dim=None, ai_framework='pytorch', auto_settings=False, auto_settings_work_dir='/home/ma-user/work/verl', auto_settings_ranks=8, auto_settings_log_level='info', target_nnodes=1, nnodes=1, nproc_per_node=1, node_rank=0, auto_settings_type='white', prof_file=None, master_addr='127.0.0.1', master_port=29500, automated_pipeline=False, automated_pipeline_perf=False, recompute_module_list=None, jit_compile=False, node_ip_address='172.16.0.99', node_manager_port='45639', object_store_name='/tmp/ray/session_2026-01-02_17-03-40_712406_352544/sockets/plasma_store', raylet_name='/tmp/ray/session_2026-01-02_17-03-40_712406_352544/sockets/raylet', redis_address='None', metrics_agent_port='61289', logging_rotate_bytes='536870912', logging_rotate_backup_count='5', runtime_env_agent_port='64055', gcs_address='172.16.0.99:65454', session_name='session_2026-01-02_17-03-40_712406_352544', temp_dir='/tmp/ray', webui='127.0.0.1:8265', cluster_id='9add5208ab0ee3dfa31e107829a831629531b24f8ae6e4a93d7b02cf', startup_token='62', worker_launch_time_ms='1767344781356', node_id='d965e5f3387a710fe18fc46d53e06f1834513854357cb26e7b7140db', runtime_env_hash='-602549344', quant_states_enabled=False, quant_grads_dtype=None, use_quant_optimizer=False, use_flash_attn=True)[36m(WorkerDict pid=365376)[0m /home/ma-user/work/verl/verl/models/mcore/config_converter.py:182: UserWarning: The following keys are not supported in the current Megatron version and will be removed: ['use_flash_attn']
[36m(WorkerDict pid=365376)[0m   return check_and_construct_configs(args, TransformerConfig)

[36m(WorkerDict pid=365376)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=365376)[0m   "architectures": [
[36m(WorkerDict pid=365376)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=365376)[0m   ],
[36m(WorkerDict pid=365376)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=365376)[0m   "dtype": "bfloat16",
[36m(WorkerDict pid=365376)[0m   "eos_token_id": 151645,
[36m(WorkerDict pid=365376)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=365376)[0m   "hidden_size": 896,
[36m(WorkerDict pid=365376)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=365376)[0m   "intermediate_size": 4864,
[36m(WorkerDict pid=365376)[0m   "layer_types": [
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention",
[36m(WorkerDict pid=365376)[0m     "full_attention"
[36m(WorkerDict pid=365376)[0m   ],
[36m(WorkerDict pid=365376)[0m   "max_position_embeddings": 5120,
[36m(WorkerDict pid=365376)[0m   "max_window_layers": 21,
[36m(WorkerDict pid=365376)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=365376)[0m   "num_attention_heads": 14,
[36m(WorkerDict pid=365376)[0m   "num_hidden_layers": 24,
[36m(WorkerDict pid=365376)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=365376)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=365376)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=365376)[0m   "rope_scaling": null,
[36m(WorkerDict pid=365376)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=365376)[0m   "sliding_window": null,
[36m(WorkerDict pid=365376)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=365376)[0m   "transformers_version": "4.57.3",
[36m(WorkerDict pid=365376)[0m   "use_cache": true,
[36m(WorkerDict pid=365376)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=365376)[0m   "vocab_size": 151936
[36m(WorkerDict pid=365376)[0m }
[36m(WorkerDict pid=365376)[0m 
[36m(WorkerDict pid=365376)[0m Overridden TransformerConfig init config: {'num_layers': 24, 'hidden_size': 896, 'num_attention_heads': 14, 'num_query_groups': 2, 'ffn_hidden_size': 4864, 'attention_dropout': 0.0, 'hidden_dropout': 0.0, 'kv_channels': None, 'layernorm_epsilon': 1e-06, 'add_bias_linear': False, 'activation_func': <function silu at 0xffff0c215090>, 'normalization': 'RMSNorm', 'gated_linear_unit': True, 'pipeline_dtype': torch.bfloat16, 'params_dtype': torch.bfloat16, 'bf16': True, 'tensor_model_parallel_size': 1, 'pipeline_model_parallel_size': 1, 'expert_model_parallel_size': 1, 'expert_tensor_parallel_size': 1, 'virtual_pipeline_model_parallel_size': None, 'context_parallel_size': 1, 'overlap_p2p_comm': False, 'batch_p2p_comm': False, 'sequence_parallel': False, 'variable_seq_lengths': True, 'masked_softmax_fusion': True, 'moe_token_dispatcher_type': 'alltoall', 'use_cpu_initialization': False, 'add_qkv_bias': True, 'qk_layernorm': False, 'recompute_granularity': None, 'recompute_modules': ['core_attn'], 'recompute_method': None, 'recompute_num_layers': None, 'attention_backend': <AttnBackend.flash: 1>, 'apply_rope_fusion': True, 'bias_activation_fusion': True, 'bias_dropout_fusion': True, 'gradient_accumulation_fusion': True, 'deallocate_pipeline_outputs': True, 'persist_layer_norm': True}
[36m(WorkerDict pid=365376)[0m TF config: TransformerConfig(tensor_model_parallel_size=1, pipeline_model_parallel_comm_backend=None, pipeline_model_parallel_size=1, virtual_pipeline_model_parallel_size=None, sequence_parallel=False, context_parallel_size=1, hierarchical_context_parallel_sizes=None, expert_model_parallel_size=1, expert_tensor_parallel_size=1, moe_extended_tp=False, perform_initialization=True, use_cpu_initialization=False, fp16=False, bf16=True, params_dtype=torch.bfloat16, timers=None, finalize_model_grads_func=None, grad_scale_func=None, no_sync_func=None, grad_sync_func=None, param_sync_func=None, deterministic_mode=False, enable_autocast=False, autocast_dtype=torch.bfloat16, num_microbatches_with_partial_activation_checkpoints=None, gradient_accumulation_fusion=True, async_tensor_model_parallel_allreduce=False, use_te_rng_tracker=False, tp_comm_overlap=False, tp_comm_bulk_wgrad=True, tp_comm_bulk_dgrad=True, tp_comm_overlap_ag=True, tp_comm_overlap_rs=True, tp_comm_overlap_rs_dgrad=False, tp_comm_split_ag=True, tp_comm_atomic_ag=False, tp_comm_split_rs=True, tp_comm_atomic_rs=False, cross_entropy_loss_fusion=False, cross_entropy_fusion_impl='native', tp_comm_overlap_disable_qkv=False, tp_comm_overlap_disable_fc1=False, tp_comm_bootstrap_backend='nccl', pipeline_dtype=torch.bfloat16, variable_seq_lengths=True, overlap_p2p_comm=False, batch_p2p_comm=False, batch_p2p_sync=True, use_ring_exchange_p2p=False, deallocate_pipeline_outputs=True, defer_embedding_wgrad_compute=False, wgrad_deferral_limit=0, pipeline_model_parallel_split_rank=None, overlap_p2p_comm_warmup_flush=False, microbatch_group_size_per_vp_stage=1, cpu_offloading=False, cpu_offloading_num_layers=0, _cpu_offloading_context=None, cpu_offloading_activations=True, cpu_offloading_weights=True, barrier_with_L1_time=True, num_layers=24, mtp_num_layers=None, mtp_loss_scaling_factor=None, num_layers_in_first_pipeline_stage=None, num_layers_in_last_pipeline_stage=None, account_for_embedding_in_pipeline_split=False, account_for_loss_in_pipeline_split=False, hidden_size=896, num_attention_heads=14, attention_backend=<AttnBackend.flash: 1>, softmax_scale=None, num_query_groups=2, ffn_hidden_size=4864, kv_channels=64, hidden_dropout=0.0, attention_dropout=0.0, fp32_residual_connection=False, apply_residual_connection_post_layernorm=False, layernorm_epsilon=1e-06, layernorm_zero_centered_gamma=False, add_bias_linear=False, add_qkv_bias=True, gated_linear_unit=True, activation_func=<function silu at 0xffff0c215090>, activation_func_fp8_input_store=False, num_moe_experts=None, rotary_interleaved=False, window_size=None, normalization='RMSNorm', qk_layernorm=False, test_mode=False, calculate_per_token_loss=False, multi_latent_attention=False, init_method=functools.partial(<function normal_ at 0xffff0c29dcf0>, mean=0.0, std=0.02), output_layer_init_method=functools.partial(<function normal_ at 0xffff0c29dcf0>, mean=0.0, std=0.002886751345948129), init_method_std=0.02, init_model_with_meta_device=False, apply_query_key_layer_scaling=False, attention_softmax_in_fp32=True, disable_bf16_reduced_precision_matmul=False, bias_activation_fusion=True, masked_softmax_fusion=True, persist_layer_norm=True, memory_efficient_layer_norm=False, bias_dropout_fusion=True, apply_rope_fusion=True, recompute_granularity=None, recompute_method=None, recompute_num_layers=None, distribute_saved_activations=None, recompute_modules=['core_attn'], fp8=None, fp8_recipe='delayed', fp8_param=False, fp8_margin=0, fp8_interval=1, fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', fp8_wgrad=True, fp8_dot_product_attention=False, fp8_multi_head_attention=False, tp_only_amax_red=False, first_last_layers_bf16=False, num_layers_at_start_in_bf16=1, num_layers_at_end_in_bf16=1, moe_shared_expert_intermediate_size=None, moe_shared_expert_overlap=False, moe_layer_freq=1, moe_ffn_hidden_size=4864, moe_router_load_balancing_type='aux_loss', moe_router_topk=2, moe_router_topk_limited_devices=None, moe_router_num_groups=None, moe_router_group_topk=None, moe_router_pre_softmax=False, moe_router_topk_scaling_factor=None, moe_router_score_function='softmax', moe_router_dtype=None, moe_router_enable_expert_bias=False, moe_router_bias_update_rate=0.001, moe_grouped_gemm=False, moe_use_legacy_grouped_gemm=False, moe_aux_loss_coeff=0, moe_z_loss_coeff=None, moe_input_jitter_eps=None, moe_token_dropping=False, moe_token_dispatcher_type='alltoall', moe_enable_deepep=False, moe_per_layer_logging=False, moe_expert_capacity_factor=None, moe_pad_expert_input_to_capacity=False, moe_token_drop_policy='probs', moe_layer_recompute=False, moe_permute_fusion=False, moe_apply_probs_on_input=False, cp_comm_type=None, enable_cuda_graph=False, cuda_graph_use_single_mempool=False, cuda_graph_retain_backward_graph=False, cuda_graph_warmup_steps=3, external_cuda_graph=False, cuda_graph_scope='full', clone_scatter_output_in_embedding=True, disable_parameter_transpose_cache=False, config_logger_dir='', flash_decode=False, inference_rng_tracker=False, mrope_section=None, is_hybrid_model=False, mamba_state_dim=128, mamba_head_dim=64, mamba_num_groups=8, heterogeneous_block_specs=False, optimizer_selection='fused_adamw', optimization_level=2, use_fused_rmsnorm=False, use_fused_swiglu=False, use_gmm_fp8=True, te_comparison_with_cpu=False, te_comparison_with_bf16=False, context_parallel_algo='megatron_cp_algo', cp_window_size=1, attention_mask_type='causal', use_cp_send_recv_overlap=False, use_fused_ring_attention_update=False, megatron_cp_in_bnsd=False, ulysses_degree_in_cp=None, context_parallel_kv_cache_policy=None, context_parallel_cache_interval=0, use_ulysses_allgather_kv=False, attention_mask_on_cpu=False, adaptive_cp_without_coarse=False, adaptive_cp_dynamic_attn_mask=False, adaptive_cp_only_reschedule=False, adaptive_cp_manually_set_mask_list=False, async_log_allreduce=False, use_fused_rotary_pos_emb=False, use_fused_moe_token_permute_and_unpermute=False, npu_deterministic=False, op_cal_tflops=False, profile_level='level0', profile_with_cpu=False, profile_with_stack=False, profile_with_memory=False, profile_record_shapes=False, profile_save_path='./profile_dir', recompute_activation_function=False, recompute_activation_function_num_layers=None, recompute_norm=False, recompute_norm_num_layers=None, enable_recompute_layers_per_pp_rank=False, unaligned_linear=False, use_ascend_mc2=False, use_ascend_coc=False, coc_mode=-1, coc_parallel_num=1, coc_fused_kernel=False, tp_2d=False, tp_x=1, tp_y=1, enable_overlap_ag_with_matmul=False, enable_overlap_matmul_with_rs=False, enable_backward_overlap_ag_with_matmul=False, recompute_in_bubble=False, recompute_in_advance=False, noop_layers=None, use_multiparameter_pipeline_model_parallel=False, optimize_send_recv_comm=False, pipeline_num_transformer_layers=None, schedules_method=None, dualpipev_dw_detach=False, gemm_gradient_accumulation_fusion=False, moe_tp_extend_ep=False, moe_permutation_async_comm=False, n_shared_experts=None, moe_allgather_overlap_comm=False, moe_alltoall_overlap_comm=False, moe_zero_memory='disable', moe_zero_memory_num_layers=None, moe_fb_overlap=False, moe_unperm2_mem_optim_swap=False, balanced_moe_experts=False, balanced_moe_hot_expert_num=3, trans_hot_expert_group_num=4, enable_expert_placement=False, expert_placement_freq=50, enable_fine_grained_expert_placement=False, print_expert_load=False, fine_grained_expert_placement_thre=0.08, hccl_group_buffer=None, hccl_group_buffer_adaptive=False, hccl_ep_group_buffer_adaptive_factor=-1.0, ema_decay=0.9999, virtual_optimizer=None, quant_states=None, quant_grads=False, dist_train=False, tokenizer_name_or_path=None, tokenizer_not_use_fast=True, param_and_grad_buffer_pad=None, layerzero=False, layerzero_config=None, fsdp2_config_path=None, reset_bucket_group_order=False, reuse_fp32_param=False, smart_swap=False, swap_attention=False, swap_modules='input_norm,self_attention,post_attention_norm', compress_dense='disable', disable_gloo_group=False, hccl_slice_size=10485760, swap_optimizer=False, swap_optimizer_times=16, pre_tockens=65536, next_tockens=0, sparse_mode=0, use_fusion_attn_v2=False, square_alibi_mask=False, fill_neg_inf=False, alibi_fusion_attn_type=None, alibi_diagonal_opposite=False, multi_head_latent_attention=False, qk_rope_head_dim=None, qk_nope_head_dim=None, ai_framework='pytorch', auto_settings=False, auto_settings_work_dir='/home/ma-user/work/verl', auto_settings_ranks=8, auto_settings_log_level='info', target_nnodes=1, nnodes=1, nproc_per_node=1, node_rank=0, auto_settings_type='white', prof_file=None, master_addr='127.0.0.1', master_port=29500, automated_pipeline=False, automated_pipeline_perf=False, recompute_module_list=None, jit_compile=False, node_ip_address='172.16.0.99', node_manager_port='45639', object_store_name='/tmp/ray/session_2026-01-02_17-03-40_712406_352544/sockets/plasma_store', raylet_name='/tmp/ray/session_2026-01-02_17-03-40_712406_352544/sockets/raylet', redis_address='None', metrics_agent_port='61289', logging_rotate_bytes='536870912', logging_rotate_backup_count='5', runtime_env_agent_port='64055', gcs_address='172.16.0.99:65454', session_name='session_2026-01-02_17-03-40_712406_352544', temp_dir='/tmp/ray', webui='127.0.0.1:8265', cluster_id='9add5208ab0ee3dfa31e107829a831629531b24f8ae6e4a93d7b02cf', startup_token='62', worker_launch_time_ms='1767344781356', node_id='d965e5f3387a710fe18fc46d53e06f1834513854357cb26e7b7140db', runtime_env_hash='-602549344', quant_states_enabled=False, quant_grads_dtype=None, use_quant_optimizer=False, use_flash_attn=True)
[36m(WorkerDict pid=365376)[0m  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 494032768
[36m(WorkerDict pid=365376)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:06:56,382 INFO [megatron.core.distributed.distributed_data_parallel:532] => Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=True, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=False, check_for_large_grads=False, bucket_size=None, pad_buckets_for_high_nccl_busbw=False, average_in_collective=False, fp8_param_gather=False, use_custom_fsdp=False, data_parallel_sharding_strategy='no_shard', gradient_reduce_div_fusion=True, suggested_communication_unit_size=None, preserve_fp32_weights=True, keep_fp8_transpose_cache_when_using_custom_fsdp=False)
[36m(WorkerDict pid=365376)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:06:56,416 INFO [megatron.core.distributed.param_and_grad_buffer:553] => Number of buckets for gradient all-reduce / reduce-scatter: 1
[36m(WorkerDict pid=365376)[0m Params for bucket 1 (494032768 elements, 494032768 padded size):
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.21.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.18.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.12.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.4.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.22.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.19.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.23.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.18.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.11.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.9.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.5.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.5.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.5.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.19.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.15.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.11.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.10.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.1.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.20.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.17.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.9.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.9.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.5.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.1.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.18.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.12.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.10.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.22.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.19.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.16.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.16.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.13.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.21.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.11.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.7.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.6.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.22.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.15.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.14.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.12.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.10.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.8.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.3.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.1.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.0.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.23.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.20.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.9.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.5.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.3.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.21.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.7.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.13.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.22.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.17.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.16.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.14.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.4.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.2.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.1.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.final_layernorm.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.18.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.6.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.embedding.word_embeddings.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.19.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.16.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.15.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.14.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.12.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.0.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.23.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.18.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.14.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.13.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.7.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.4.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.2.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.1.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.21.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.19.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.5.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.2.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.20.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.17.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.15.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.6.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.21.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.18.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.11.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.8.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.22.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.19.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.16.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.14.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.12.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.8.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.20.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.17.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.12.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.21.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.11.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.11.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.10.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.6.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.2.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.23.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.13.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.8.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.7.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.3.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.7.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.22.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.16.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.14.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.8.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.3.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.2.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.23.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.20.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.17.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.2.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.0.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.15.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.12.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.11.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.8.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.20.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.17.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.15.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.13.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.10.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.6.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.21.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.18.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.19.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.16.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.14.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.13.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.1.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.23.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.20.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.9.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.9.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.7.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.4.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.4.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.3.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.0.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.22.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.10.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.6.mlp.linear_fc2.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.4.self_attention.linear_qkv.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.3.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.0.self_attention.linear_proj.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.23.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.15.mlp.linear_fc1.weight
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.13.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=365376)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=365376)[0m <string>:35: UserWarning: set sequence parallel to false as TP size is 1
[36m(WorkerDict pid=365376)[0m /home/ma-user/work/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.
[36m(WorkerDict pid=365376)[0m   warnings.warn("Torch profiler tool config is not fully supported now.", stacklevel=1)
[36m(WorkerDict pid=365376)[0m 	module.decoder.layers.0.self_attention.linear_qkv.bias
[36m(WorkerDict pid=365376)[0m actor_module: 1
[36m(WorkerDict pid=365376)[0m load from local dir /home/ma-user/work/models/Qwen2.5-0.5B-Instruct
[36m(WorkerDict pid=365376)[0m loading embeddings...
[36m(WorkerDict pid=365376)[0m loading layer #0, with layer_name model.layers.0...
[36m(WorkerDict pid=365376)[0m loading layer #1, with layer_name model.layers.1...
[36m(WorkerDict pid=365376)[0m loading layer #2, with layer_name model.layers.2...
[36m(WorkerDict pid=365376)[0m loading layer #3, with layer_name model.layers.3...
[36m(WorkerDict pid=365376)[0m loading layer #4, with layer_name model.layers.4...
[36m(WorkerDict pid=365376)[0m loading layer #5, with layer_name model.layers.5...
[36m(WorkerDict pid=365376)[0m loading layer #6, with layer_name model.layers.6...
[36m(WorkerDict pid=365376)[0m loading layer #7, with layer_name model.layers.7...
[36m(WorkerDict pid=365376)[0m loading layer #8, with layer_name model.layers.8...
[36m(WorkerDict pid=365376)[0m loading layer #9, with layer_name model.layers.9...
[36m(WorkerDict pid=365376)[0m loading layer #10, with layer_name model.layers.10...
[36m(WorkerDict pid=365376)[0m loading layer #11, with layer_name model.layers.11...
[36m(WorkerDict pid=365376)[0m loading layer #12, with layer_name model.layers.12...
[36m(WorkerDict pid=365376)[0m loading layer #13, with layer_name model.layers.13...
[36m(WorkerDict pid=365376)[0m loading layer #14, with layer_name model.layers.14...
[36m(WorkerDict pid=365376)[0m loading layer #15, with layer_name model.layers.15...
[36m(WorkerDict pid=365376)[0m loading layer #16, with layer_name model.layers.16...
[36m(WorkerDict pid=365376)[0m loading layer #17, with layer_name model.layers.17...
[36m(WorkerDict pid=365376)[0m loading layer #18, with layer_name model.layers.18...
[36m(WorkerDict pid=365376)[0m loading layer #19, with layer_name model.layers.19...
[36m(WorkerDict pid=365376)[0m loading layer #20, with layer_name model.layers.20...
[36m(WorkerDict pid=365376)[0m loading layer #21, with layer_name model.layers.21...
[36m(WorkerDict pid=365376)[0m loading layer #22, with layer_name model.layers.22...
[36m(WorkerDict pid=365376)[0m loading layer #23, with layer_name model.layers.23...
[36m(WorkerDict pid=365376)[0m loading final layernorm...
[36m(WorkerDict pid=365376)[0m loading lm_head...
[36m(WorkerDict pid=365376)[0m loading megatron ckpt done, time elapsed 0.5905234813690186s
[36m(WorkerDict pid=365376)[0m DistributedDataParallel contains 494.03M parameters
[36m(WorkerDict pid=365376)[0m optimizer config after override: {'optimizer': 'adam', 'lr': 1e-06, 'min_lr': 0.0, 'clip_grad': 1.0, 'weight_decay': 0.1, 'use_distributed_optimizer': True, 'bf16': True, 'params_dtype': torch.bfloat16, 'optimizer_offload_fraction': 0, 'overlap_cpu_optimizer_d2h_h2d': True, 'use_precision_aware_optimizer': True, 'optimizer_cpu_offload': True}
[36m(WorkerDict pid=365376)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:06:57,379 INFO [megatron.core.optimizer:532] => Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=1e-06, min_lr=0.0, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp16=False, bf16=True, params_dtype=torch.bfloat16, use_precision_aware_optimizer=True, main_grads_dtype=torch.float32, main_params_dtype=torch.float32, exp_avg_dtype=torch.float32, exp_avg_sq_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, optimizer_cpu_offload=True, optimizer_offload_fraction=0, use_torch_optimizer_for_cpu_offload=False, overlap_cpu_optimizer_d2h_h2d=True, pin_cpu_grads=True, pin_cpu_params=True, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')
[36m(WorkerDict pid=365376)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:06:57,438 INFO [megatron.core.optimizer_param_scheduler:532] => > learning rate decay style: constant
[36m(WorkerDict pid=365376)[0m [Warining] Because actor tp size == 1, set sp to False
[36m(WorkerDict pid=365376)[0m TransformerConfig(tensor_model_parallel_size=1, pipeline_model_parallel_comm_backend=None, pipeline_model_parallel_size=1, virtual_pipeline_model_parallel_size=None, sequence_parallel=False, context_parallel_size=1, hierarchical_context_parallel_sizes=None, expert_model_parallel_size=1, expert_tensor_parallel_size=1, moe_extended_tp=False, perform_initialization=True, use_cpu_initialization=False, fp16=False, bf16=True, params_dtype=torch.bfloat16, timers=None, finalize_model_grads_func=<function finalize_model_grads at 0xffe173984280>, grad_scale_func=<bound method MegatronOptimizer.scale_loss of <megatron.core.optimizer.optimizer.ChainedOptimizer object at 0xffe1580eb070>>, no_sync_func=None, grad_sync_func=None, param_sync_func=None, deterministic_mode=False, enable_autocast=False, autocast_dtype=torch.bfloat16, num_microbatches_with_partial_activation_checkpoints=None, gradient_accumulation_fusion=True, async_tensor_model_parallel_allreduce=False, use_te_rng_tracker=False, tp_comm_overlap=False, tp_comm_bulk_wgrad=True, tp_comm_bulk_dgrad=True, tp_comm_overlap_ag=True, tp_comm_overlap_rs=True, tp_comm_overlap_rs_dgrad=False, tp_comm_split_ag=True, tp_comm_atomic_ag=False, tp_comm_split_rs=True, tp_comm_atomic_rs=False, cross_entropy_loss_fusion=False, cross_entropy_fusion_impl='native', tp_comm_overlap_disable_qkv=False, tp_comm_overlap_disable_fc1=False, tp_comm_bootstrap_backend='nccl', pipeline_dtype=torch.bfloat16, variable_seq_lengths=True, overlap_p2p_comm=False, batch_p2p_comm=False, batch_p2p_sync=True, use_ring_exchange_p2p=False, deallocate_pipeline_outputs=True, defer_embedding_wgrad_compute=False, wgrad_deferral_limit=0, pipeline_model_parallel_split_rank=None, overlap_p2p_comm_warmup_flush=False, microbatch_group_size_per_vp_stage=1, cpu_offloading=False, cpu_offloading_num_layers=0, _cpu_offloading_context=None, cpu_offloading_activations=True, cpu_offloading_weights=True, barrier_with_L1_time=True, num_layers=24, mtp_num_layers=None, mtp_loss_scaling_factor=None, num_layers_in_first_pipeline_stage=None, num_layers_in_last_pipeline_stage=None, account_for_embedding_in_pipeline_split=False, account_for_loss_in_pipeline_split=False, hidden_size=896, num_attention_heads=14, attention_backend=<AttnBackend.flash: 1>, softmax_scale=None, num_query_groups=2, ffn_hidden_size=4864, kv_channels=64, hidden_dropout=0.0, attention_dropout=0.0, fp32_residual_connection=False, apply_residual_connection_post_layernorm=False, layernorm_epsilon=1e-06, layernorm_zero_centered_gamma=False, add_bias_linear=False, add_qkv_bias=True, gated_linear_unit=True, activation_func=<function silu at 0xffff0c215090>, activation_func_fp8_input_store=False, num_moe_experts=None, rotary_interleaved=False, window_size=None, normalization='RMSNorm', qk_layernorm=False, test_mode=False, calculate_per_token_loss=False, multi_latent_attention=False, init_method=functools.partial(<function normal_ at 0xffff0c29dcf0>, mean=0.0, std=0.02), output_layer_init_method=functools.partial(<function normal_ at 0xffff0c29dcf0>, mean=0.0, std=0.002886751345948129), init_method_std=0.02, init_model_with_meta_device=False, apply_query_key_layer_scaling=False, attention_softmax_in_fp32=True, disable_bf16_reduced_precision_matmul=False, bias_activation_fusion=True, masked_softmax_fusion=True, persist_layer_norm=True, memory_efficient_layer_norm=False, bias_dropout_fusion=True, apply_rope_fusion=True, recompute_granularity=None, recompute_method=None, recompute_num_layers=None, distribute_saved_activations=None, recompute_modules=['core_attn'], fp8=None, fp8_recipe='delayed', fp8_param=False, fp8_margin=0, fp8_interval=1, fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', fp8_wgrad=True, fp8_dot_product_attention=False, fp8_multi_head_attention=False, tp_only_amax_red=False, first_last_layers_bf16=False, num_layers_at_start_in_bf16=1, num_layers_at_end_in_bf16=1, moe_shared_expert_intermediate_size=None, moe_shared_expert_overlap=False, moe_layer_freq=1, moe_ffn_hidden_size=4864, moe_router_load_balancing_type='aux_loss', moe_router_topk=2, moe_router_topk_limited_devices=None, moe_router_num_groups=None, moe_router_group_topk=None, moe_router_pre_softmax=False, moe_router_topk_scaling_factor=None, moe_router_score_function='softmax', moe_router_dtype=None, moe_router_enable_expert_bias=False, moe_router_bias_update_rate=0.001, moe_grouped_gemm=False, moe_use_legacy_grouped_gemm=False, moe_aux_loss_coeff=0, moe_z_loss_coeff=None, moe_input_jitter_eps=None, moe_token_dropping=False, moe_token_dispatcher_type='alltoall', moe_enable_deepep=False, moe_per_layer_logging=False, moe_expert_capacity_factor=None, moe_pad_expert_input_to_capacity=False, moe_token_drop_policy='probs', moe_layer_recompute=False, moe_permute_fusion=False, moe_apply_probs_on_input=False, cp_comm_type=None, enable_cuda_graph=False, cuda_graph_use_single_mempool=False, cuda_graph_retain_backward_graph=False, cuda_graph_warmup_steps=3, external_cuda_graph=False, cuda_graph_scope='full', clone_scatter_output_in_embedding=True, disable_parameter_transpose_cache=False, config_logger_dir='', flash_decode=False, inference_rng_tracker=False, mrope_section=None, is_hybrid_model=False, mamba_state_dim=128, mamba_head_dim=64, mamba_num_groups=8, heterogeneous_block_specs=False, optimizer_selection='fused_adamw', optimization_level=2, use_fused_rmsnorm=True, use_fused_swiglu=False, use_gmm_fp8=True, te_comparison_with_cpu=False, te_comparison_with_bf16=False, context_parallel_algo='megatron_cp_algo', cp_window_size=1, attention_mask_type='causal', use_cp_send_recv_overlap=False, use_fused_ring_attention_update=False, megatron_cp_in_bnsd=False, ulysses_degree_in_cp=None, context_parallel_kv_cache_policy=None, context_parallel_cache_interval=0, use_ulysses_allgather_kv=False, attention_mask_on_cpu=False, adaptive_cp_without_coarse=False, adaptive_cp_dynamic_attn_mask=False, adaptive_cp_only_reschedule=False, adaptive_cp_manually_set_mask_list=False, async_log_allreduce=False, use_fused_rotary_pos_emb=False, use_fused_moe_token_permute_and_unpermute=False, npu_deterministic=False, op_cal_tflops=False, profile_level='level0', profile_with_cpu=False, profile_with_stack=False, profile_with_memory=False, profile_record_shapes=False, profile_save_path='./profile_dir', recompute_activation_function=False, recompute_activation_function_num_layers=None, recompute_norm=False, recompute_norm_num_layers=None, enable_recompute_layers_per_pp_rank=False, unaligned_linear=False, use_ascend_mc2=False, use_ascend_coc=False, coc_mode=-1, coc_parallel_num=1, coc_fused_kernel=False, tp_2d=False, tp_x=1, tp_y=1, enable_overlap_ag_with_matmul=False, enable_overlap_matmul_with_rs=False, enable_backward_overlap_ag_with_matmul=False, recompute_in_bubble=False, recompute_in_advance=False, noop_layers=None, use_multiparameter_pipeline_model_parallel=False, optimize_send_recv_comm=False, pipeline_num_transformer_layers=None, schedules_method=None, dualpipev_dw_detach=False, gemm_gradient_accumulation_fusion=False, moe_tp_extend_ep=False, moe_permutation_async_comm=False, n_shared_experts=None, moe_allgather_overlap_comm=False, moe_alltoall_overlap_comm=False, moe_zero_memory='disable', moe_zero_memory_num_layers=None, moe_fb_overlap=False, moe_unperm2_mem_optim_swap=False, balanced_moe_experts=False, balanced_moe_hot_expert_num=3, trans_hot_expert_group_num=4, enable_expert_placement=False, expert_placement_freq=50, enable_fine_grained_expert_placement=False, print_expert_load=False, fine_grained_expert_placement_thre=0.08, hccl_group_buffer=None, hccl_group_buffer_adaptive=False, hccl_ep_group_buffer_adaptive_factor=-1.0, ema_decay=0.9999, virtual_optimizer=None, quant_states=None, quant_grads=False, dist_train=False, tokenizer_name_or_path=None, tokenizer_not_use_fast=True, param_and_grad_buffer_pad=None, layerzero=False, layerzero_config=None, fsdp2_config_path=None, reset_bucket_group_order=False, reuse_fp32_param=False, smart_swap=False, swap_attention=False, swap_modules='input_norm,self_attention,post_attention_norm', compress_dense='disable', disable_gloo_group=False, hccl_slice_size=10485760, swap_optimizer=False, swap_optimizer_times=16, pre_tockens=65536, next_tockens=0, sparse_mode=0, use_fusion_attn_v2=False, square_alibi_mask=False, fill_neg_inf=False, alibi_fusion_attn_type=None, alibi_diagonal_opposite=False, multi_head_latent_attention=False, qk_rope_head_dim=None, qk_nope_head_dim=None, ai_framework='pytorch', auto_settings=False, auto_settings_work_dir='/home/ma-user/work/verl', auto_settings_ranks=8, auto_settings_log_level='info', target_nnodes=1, nnodes=1, nproc_per_node=1, node_rank=0, auto_settings_type='white', prof_file=None, master_addr='127.0.0.1', master_port=29500, automated_pipeline=False, automated_pipeline_perf=False, recompute_module_list=None, jit_compile=False, node_ip_address='172.16.0.99', node_manager_port='45639', object_store_name='/tmp/ray/session_2026-01-02_17-03-40_712406_352544/sockets/plasma_store', raylet_name='/tmp/ray/session_2026-01-02_17-03-40_712406_352544/sockets/raylet', redis_address='None', metrics_agent_port='61289', logging_rotate_bytes='536870912', logging_rotate_backup_count='5', runtime_env_agent_port='64055', gcs_address='172.16.0.99:65454', session_name='session_2026-01-02_17-03-40_712406_352544', temp_dir='/tmp/ray', webui='127.0.0.1:8265', cluster_id='9add5208ab0ee3dfa31e107829a831629531b24f8ae6e4a93d7b02cf', startup_token='62', worker_launch_time_ms='1767344781356', node_id='d965e5f3387a710fe18fc46d53e06f1834513854357cb26e7b7140db', runtime_env_hash='-602549344', quant_states_enabled=False, quant_grads_dtype=None, use_quant_optimizer=False, use_flash_attn=True)[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:   0%|                                                                                                                                     | 0/29 [00:00<?, ?it/s]
[36m(pid=367621)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=367621)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=367621)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=367621)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=367621)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=367621)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=367621)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=367621)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(ParameterSynchronizer pid=367621)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
[36m(ParameterSynchronizer pid=367621)[0m     *************************************************************************************************************
[36m(ParameterSynchronizer pid=367621)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(ParameterSynchronizer pid=367621)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(ParameterSynchronizer pid=367621)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(ParameterSynchronizer pid=367621)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(ParameterSynchronizer pid=367621)[0m     The device parameters have been replaced with npu in the function below:
[36m(ParameterSynchronizer pid=367621)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(ParameterSynchronizer pid=367621)[0m     *************************************************************************************************************
[36m(ParameterSynchronizer pid=367621)[0m     
[36m(ParameterSynchronizer pid=367621)[0m   warnings.warn(msg, ImportWarning)
[36m(ParameterSynchronizer pid=367621)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(ParameterSynchronizer pid=367621)[0m   warnings.warn(msg, RuntimeWarning)
[36m(ParameterSynchronizer pid=367621)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(ParameterSynchronizer pid=367621)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(ParameterSynchronizer pid=367621)[0m   import pkg_resources
[36m(ParameterSynchronizer pid=367621)[0m /home/ma-user/work/verl/verl/workers/megatron_workers.py:54: UserWarning: NPU not support router replay for now.
[36m(ParameterSynchronizer pid=367621)[0m   from verl.utils.megatron.router_replay_patch import RouterReplay, RouterReplayAction, apply_router_replay_patch
[36m(ParameterSynchronizer pid=367621)[0m /home/ma-user/work/verl/verl/workers/actor/megatron_actor.py:44: UserWarning: NPU not support router replay for now.
[36m(ParameterSynchronizer pid=367621)[0m   from verl.utils.megatron.router_replay_utils import (
[36m(WorkerDict pid=361271)[0m Using blocking ray.get inside async actor. This blocks the event loop. Please use `await` on object ref with asyncio.gather if you want to yield execution to the event loop instead.
[36m(WorkerDict pid=365376)[0m [rank0]:[W102 17:07:22.983742490 compiler_depend.ts:117] Warning: Driver Version: 9 is invalid or not supported yet. (function operator())
[36m(WorkerDict pid=365376)[0m Using blocking ray.get inside async actor. This blocks the event loop. Please use `await` on object ref with asyncio.gather if you want to yield execution to the event loop instead.
[36m(WorkerDict pid=361271)[0m [rank0]:[W102 17:07:29.518708295 compiler_depend.ts:117] Warning: Driver Version: 9 is invalid or not supported yet. (function operator())
[36m(FullyAsyncAgentLoopWorker pid=363365)[0m You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[36m(FullyAsyncAgentLoopWorker pid=363348)[0m You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.[32m [repeated 3x across cluster][0m
[36m(FullyAsyncAgentLoopWorker pid=363366)[0m You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.[32m [repeated 3x across cluster][0m

[36m(WorkerDict pid=365376)[0m routing replay layers: 0
[36m(WorkerDict pid=365376)[0m Overridden TransformerConfig init config: {'num_layers': 24, 'hidden_size': 896, 'num_attention_heads': 14, 'num_query_groups': 2, 'ffn_hidden_size': 4864, 'attention_dropout': 0.0, 'hidden_dropout': 0.0, 'kv_channels': None, 'layernorm_epsilon': 1e-06, 'add_bias_linear': False, 'activation_func': <function silu at 0xffff0c215090>, 'normalization': 'RMSNorm', 'gated_linear_unit': True, 'pipeline_dtype': torch.bfloat16, 'params_dtype': torch.bfloat16, 'bf16': True, 'tensor_model_parallel_size': 1, 'pipeline_model_parallel_size': 1, 'expert_model_parallel_size': 1, 'expert_tensor_parallel_size': 1, 'virtual_pipeline_model_parallel_size': None, 'context_parallel_size': 1, 'overlap_p2p_comm': False, 'batch_p2p_comm': False, 'sequence_parallel': False, 'variable_seq_lengths': True, 'masked_softmax_fusion': True, 'moe_token_dispatcher_type': 'alltoall', 'use_cpu_initialization': False, 'add_qkv_bias': True, 'qk_layernorm': False}
[36m(FullyAsyncTaskRunner pid=357514)[0m [ASYNC MAIN] FullyAsyncTrainer created and initialized successfully
[36m(FullyAsyncTaskRunner pid=357514)[0m total_train_steps 29
[36m(FullyAsyncTaskRunner pid=357514)[0m [ASYNC MAIN] Creating MessageQueue... max_queue_size 307
[36m(FullyAsyncTaskRunner pid=357514)[0m [ASYNC MAIN] Setting up parameter synchronization...
[36m(FullyAsyncRollouter pid=360588)[0m Checkpoint tracker file does not exist: /home/ma-user/work/verl/checkpoints/GRPO-Qwen2.5-0.5b-Base-MATH/GRPO-Qwen2.5-0.5b-Base-MATH-2gpu-async/latest_checkpointed_iteration.txt
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter] Training from scratch (no checkpoint found)
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Training from scratch
[36m(MessageQueue pid=367620)[0m [MessageQueue] initialized with max_queue_size=307,staleness_threshold=0.2
[36m(ParameterSynchronizer pid=367621)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:07:13,033 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(FullyAsyncTrainer pid=363373)[0m Checkpoint tracker file does not exist: /home/ma-user/work/verl/checkpoints/GRPO-Qwen2.5-0.5b-Base-MATH/GRPO-Qwen2.5-0.5b-Base-MATH-2gpu-async/latest_checkpointed_iteration.txt
[33m(raylet)[0m It looks like you're creating a detached actor in an anonymous namespace. In order to access this actor in the future, you will need to explicitly connect to this namespace with ray.init(namespace="33b2ac36-07c5-4c6e-b399-28c3bdca2075", ...)
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Initializing parameter synchronization group...
[36m(WorkerDict pid=365376)[0m 
[36m(WorkerDict pid=365376)[0m [DEBUG_UUID] 开始查找: Container PID=365376, Searching in 4 NPUs...
[36m(WorkerDict pid=365376)[0m [DEBUG_UUID] NPU 0 查询失败: Command '['npu-smi', 'info', '-t', 'proc-mem', '-i', '0']' returned non-zero exit status 215.
[36m(WorkerDict pid=365376)[0m [DEBUG_UUID] NPU 1 查询失败: Command '['npu-smi', 'info', '-t', 'proc-mem', '-i', '1']' returned non-zero exit status 215.
[36m(WorkerDict pid=365376)[0m [DEBUG_UUID] NPU 2 查询失败: Command '['npu-smi', 'info', '-t', 'proc-mem', '-i', '2']' returned non-zero exit status 215.
[36m(WorkerDict pid=361271)[0m 
[36m(WorkerDict pid=365376)[0m [DEBUG_UUID] NPU 3 查询失败: Command '['npu-smi', 'info', '-t', 'proc-mem', '-i', '3']' returned non-zero exit status 215.
[36m(WorkerDict pid=365376)[0m [DEBUG_UUID] 遍历结束，未找到匹配 PID (Docker环境下属正常现象)。
[36m(WorkerDict pid=365376)[0m [DEBUG_UUID] 启用兜底策略 (Fallback)，生成唯一 UUID。
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(MessageQueue pid=367620)[0m Parameter version updated from 0 to 0
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 0.02 seconds
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[33m(raylet)[0m It looks like you're creating a detached actor in an anonymous namespace. In order to access this actor in the future, you will need to explicitly connect to this namespace with ray.init(namespace="33b2ac36-07c5-4c6e-b399-28c3bdca2075", ...)
[36m(FullyAsyncTaskRunner pid=357514)[0m [ASYNC MAIN] All components initialized successfully
[36m(FullyAsyncTaskRunner pid=357514)[0m [ASYNC MAIN] Starting Rollouter and Trainer...
[36m(WorkerDict pid=361271)[0m [DEBUG_UUID] 开始查找: Container PID=361271, Searching in 4 NPUs...
[36m(WorkerDict pid=361271)[0m [DEBUG_UUID] NPU 3 查询失败: Command '['npu-smi', 'info', '-t', 'proc-mem', '-i', '3']' returned non-zero exit status 215.[32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=361271)[0m [DEBUG_UUID] 遍历结束，未找到匹配 PID (Docker环境下属正常现象)。
[36m(WorkerDict pid=361271)[0m [DEBUG_UUID] 启用兜底策略 (Fallback)，生成唯一 UUID。
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 0 to 0 ,reset staleness_samples to: 0,idle_ratio: None
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter] Starting FullyAsyncRollouter...
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter] Start streaming mode, maximum concurrent samples: 128
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:5.223099708557129 seconds, while cache cost 3.0994415283203125e-06 seconds,  register cost 0.003226757049560547 seconds, update cost 0.3077409267425537 seconds
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Starting FullyAsyncTrainer...
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:5.222877502441406 seconds, while cache cost 0.9042868614196777 seconds,  register cost 0.13790392875671387 seconds, update cost 0.30767369270324707 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 5.26 seconds, pause:0.03s, sync:5.23s
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.02 seconds
[36m(FullyAsyncTrainer pid=363373)[0m Saving tensorboard log to tensorboard_log/GRPO-Qwen2.5-0.5b-Base-MATH/GRPO-Qwen2.5-0.5b-Base-MATH-2gpu-async.
[36m(FullyAsyncTrainer pid=363373)[0m step:0
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:07:27,845 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 58.80 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.60s
[36m(WorkerDict pid=365376)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:08:30,890 WARNING [mindspeed.core.fusions.fused_rope:107] => Setting apply_rope_fusion to false because its implementation is not included in Apex. Try upgrading to the latest version
[36m(WorkerDict pid=365376)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(WorkerDict pid=365376)[0m Emitting ninja build file /home/ma-user/.cache/torch_extensions/py310_cpu/npu_matmul_add_fp32/build.ninja...
[36m(WorkerDict pid=365376)[0m Building extension module npu_matmul_add_fp32...
[36m(WorkerDict pid=365376)[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[36m(WorkerDict pid=365376)[0m Loading extension module npu_matmul_add_fp32...
[36m(FullyAsyncAgentLoopWorker pid=363347)[0m You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[36m(WorkerDict pid=365376)[0m [rank0]:[W102 17:08:52.699995390 compiler_depend.ts:67] Warning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (function operator())
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 211,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 82,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 18,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=100, queue_size=36
[36m(WorkerDict pid=365376)[0m ninja: no work to do.
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 1 local_trigger_step: 1 trigger_parameter_sync_step: 4 17:09:24.224
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:09:24,227 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 31
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.38 seconds.mq_len: 31
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.55s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 184,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 123,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 56,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=200, queue_size=72
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 2 local_trigger_step: 2 trigger_parameter_sync_step: 4 17:10:35.737
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:10:35,741 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 107
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.61 seconds.mq_len: 107
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=300, queue_size=108
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.61s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 300,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 7,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 108,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 3 local_trigger_step: 3 trigger_parameter_sync_step: 4 17:11:53.863
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:11:53,866 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 49
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.40 seconds.mq_len: 49
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.61s
[36m(RewardLoopWorker pid=365527)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 306,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 1,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 50,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 4 local_trigger_step: 4 trigger_parameter_sync_step: 4 17:13:14.095
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0007081031799316406
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:   3%|████▏                                                                                                                     | 1/29 [06:16<2:55:39, 376.39s/it]
[36m(FullyAsyncTrainer pid=363373)[0m step:1 - fully_async/count/stale_samples_processed:0.0 - fully_async/count/stale_trajectory_processed:0.0 - fully_async/count/current_param_version:0.0 - fully_async/processing_time/avg:43.00253720775049 - fully_async/processing_time/max:143.64729832997546 - fully_async/processing_time/min:0.9094390529207885 - fully_async/processing_time/tp50:41.33483422111021 - fully_async/processing_time/tp99:87.16638537658261 - fully_async/processing_time/tp95:73.47956188109819 - fully_async/monitor/active_tasks_size:124.75 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:32.0 - fully_async/count/total_generated_samples:192.0 - fully_async/count/staleness_samples:221.5 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:60.19170093536377 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:1.801378852905219 - rollout_corr/training_log_ppl:0.46090079105283105 - rollout_corr/kl:0.0005661222763905262 - rollout_corr/k3_kl:0.0005979219371227656 - rollout_corr/rollout_ppl:1.7965998706428004 - rollout_corr/rollout_log_ppl:0.4602707756755801 - rollout_corr/log_ppl_diff:0.0006300188771181751 - rollout_corr/log_ppl_abs_diff:0.0017420324174924379 - rollout_corr/log_ppl_diff_max:0.07865762710571289 - rollout_corr/log_ppl_diff_min:-0.01639270782470703 - rollout_corr/ppl_ratio:1.0006346771641383 - rollout_corr/chi2_token:0.0012699357584699407 - rollout_corr/chi2_seq:0.7277222199819735 - actor/kl_loss:0.00027100123478510687 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.00010187632151625122 - actor/ppo_kl:0.0005661222763905262 - actor/pg_clipfrac_lower:0.0 - actor/pg_loss:0.0014271585160604656 - actor/grad_norm:0.16780991522668198 - perf/mfu/actor:0.05625363505324189 - perf/max_memory_allocated_gb:20.080695152282715 - perf/max_memory_reserved_gb:49.9609375 - perf/cpu_memory_used_gb:79.87521839141846 - actor/lr:1.5e-07 - training/global_step:4.0 - training/epoch:0.0 - critic/score/mean:0.01123046875 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.01123046875 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-0.0015131240215850994 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-0.5400605201721191 - critic/returns/mean:-0.0015131240215850994 - critic/returns/max:2.4748666286468506 - critic/returns/min:-0.5400605201721191 - response_length/mean:309.2001953125 - response_length/max:1114.0 - response_length/min:2.0 - response_length/clip_ratio:0.0 - response_length_non_aborted/mean:309.2001953125 - response_length_non_aborted/max:1114.0 - response_length_non_aborted/min:2.0 - response_length_non_aborted/clip_ratio:0.0 - response/aborted_ratio:0.0 - prompt_length/mean:104.890625 - prompt_length/max:222.0 - prompt_length/min:73.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:63.552523501217365 - timing_s/reward:0.002226260956376791 - timing_s/old_log_prob:0.0015145777724683285 - timing_s/ref:107.18248222954571 - timing_s/adv:0.33184017194435 - timing_s/update_actor:174.9881256967783 - timing_s/step:346.06609269976616 - timing_per_token_ms/gen:0.006897389265219347 - timing_per_token_ms/update_actor:0.1915857405314864 - timing_per_token_ms/ref:0.12229078801934662 - timing_per_token_ms/adv:0.00030878508410709743 - perf/total_num_tokens:848058.0 - perf/time_per_step:346.06609269976616 - perf/throughput:1225.283288206659 - trainer/idle_ratio:0.1836427342691245
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(RewardLoopWorker pid=365506)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[36m(MessageQueue pid=367620)[0m Parameter version updated from 0 to 1
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 81.82 seconds
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 0 to 1 ,reset staleness_samples to: 51,idle_ratio: 0.0027903644785415294
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.183520793914795 seconds, while cache cost 5.4836273193359375e-06 seconds,  register cost 0.0005464553833007812 seconds, update cost 0.1789391040802002 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:1 - timing_s/wait_last_valid:0.006903376895934343 - timing_s/param_sync:83.01853518141434
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:14:37,141 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1839361190795898 seconds, while cache cost 0.7922654151916504 seconds,  register cost 0.208909273147583 seconds, update cost 0.1788649559020996 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 83.02 seconds, pause:81.83s, sync:1.19s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 1,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 180,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 45.08 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.57s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 1,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 249,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 376,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 57,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=400, queue_size=80
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 5 local_trigger_step: 1 trigger_parameter_sync_step: 4 17:16:46.723
[36m(FullyAsyncTrainer pid=363373)[0m step:1 - rollouter/active_time:428.22144174575806 - rollouter/version_time:429.4196791648865 - rollouter/idle_ratio:0.0027903644785415294
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:16:46,727 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 101
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 101
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.57s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 1,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 495,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 68,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 111,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=500, queue_size=116
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 1,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 555,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 8,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 171,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 6 local_trigger_step: 2 trigger_parameter_sync_step: 4 17:18:02.936
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:18:02,940 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 107
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 107
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.63s
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 7 local_trigger_step: 3 trigger_parameter_sync_step: 4 17:19:24.394
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:19:24,397 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 46
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.37 seconds.mq_len: 46
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 1.19s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 1,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 559,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 4,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 47,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(RewardLoopWorker pid=365526)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 8 local_trigger_step: 4 trigger_parameter_sync_step: 4 17:20:51.474
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006699562072753906
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:   7%|████████▍                                                                                                                 | 2/29 [13:53<3:10:48, 424.03s/it]
[36m(FullyAsyncTrainer pid=363373)[0m step:2 - fully_async/count/stale_samples_processed:51.0 - fully_async/count/stale_trajectory_processed:408.0 - fully_async/count/current_param_version:1.0 - fully_async/processing_time/avg:46.377846276321634 - fully_async/processing_time/max:390.0601897179149 - fully_async/processing_time/min:1.248272759374231 - fully_async/processing_time/tp50:42.04020087962272 - fully_async/processing_time/tp99:107.35361830534642 - fully_async/processing_time/tp95:84.38470980933053 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:80.0 - fully_async/count/total_generated_samples:448.0 - fully_async/count/staleness_samples:265.5 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:46.120622634887695 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:2.146407300884663 - rollout_corr/training_log_ppl:0.56184404262124 - rollout_corr/kl:0.02643305283809289 - rollout_corr/k3_kl:0.020335996772014808 - rollout_corr/rollout_ppl:2.0887489317003185 - rollout_corr/rollout_log_ppl:0.5334718834215431 - rollout_corr/log_ppl_diff:0.02837215709341792 - rollout_corr/log_ppl_abs_diff:0.02876094429770001 - rollout_corr/log_ppl_diff_max:0.5524132251739502 - rollout_corr/log_ppl_diff_min:-0.11689424514770508 - rollout_corr/ppl_ratio:1.029826684492499 - rollout_corr/chi2_token:0.4307666540028741 - rollout_corr/chi2_seq:-0.15887626957285103 - actor/kl_loss:0.0005972750914377779 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.0009966581876918428 - actor/ppo_kl:0.02635141988339043 - actor/pg_clipfrac_lower:0.0 - actor/pg_loss:0.015419175069874547 - actor/grad_norm:0.17121370808952996 - perf/mfu/actor:0.05051181456824652 - perf/max_memory_allocated_gb:20.19743061065674 - perf/max_memory_reserved_gb:59.2734375 - perf/cpu_memory_used_gb:80.08862781524658 - actor/lr:5.5e-07 - training/global_step:8.0 - training/epoch:0.0 - critic/score/mean:0.00830078125 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.00830078125 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.016285625424643513 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.016285625424643513 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:344.33837890625 - response_length/max:3072.0 - response_length/min:6.0 - response_length/clip_ratio:0.0009765625 - response_length_non_aborted/mean:344.33837890625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:6.0 - response_length_non_aborted/clip_ratio:0.0009765625 - response/aborted_ratio:0.0 - prompt_length/mean:104.44921875 - prompt_length/max:179.0 - prompt_length/min:65.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:49.73660949198529 - timing_s/reward:0.001033104956150055 - timing_s/old_log_prob:0.0011082855053246021 - timing_s/ref:116.69883161922917 - timing_s/adv:0.2866923273541033 - timing_s/update_actor:207.4997555189766 - timing_s/step:374.2312308284454 - timing_per_token_ms/gen:0.0062083672215012846 - timing_per_token_ms/update_actor:0.20884925960280507 - timing_per_token_ms/ref:0.11336690072016166 - timing_per_token_ms/adv:0.00026104440952364155 - perf/total_num_tokens:919117.0 - perf/time_per_step:374.2312308284454 - perf/throughput:1228.0068100747856 - trainer/idle_ratio:0.1329034174456313
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(RewardLoopWorker pid=365501)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 1 to 2
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 57.30 seconds
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 1 to 2 ,reset staleness_samples to: 51,idle_ratio: 0.0028737625213469675
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.2233667373657227 seconds, while cache cost 1.3828277587890625e-05 seconds,  register cost 0.0005309581756591797 seconds, update cost 0.18326663970947266 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:2 - timing_s/wait_last_valid:0.0031953672878444195 - timing_s/param_sync:58.539207849185914
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:21:50,036 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.224475383758545 seconds, while cache cost 0.8385379314422607 seconds,  register cost 0.19789743423461914 seconds, update cost 0.18315958976745605 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 58.54 seconds, pause:57.30s, sync:1.23s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 2,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 180,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 563,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(RewardLoopWorker pid=365499)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 48.62 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.55s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=600, queue_size=24
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 2,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 233,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 616,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 40,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=700, queue_size=124
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 2,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 737,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 82,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 161,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 9 local_trigger_step: 1 trigger_parameter_sync_step: 4 17:24:08.503
[36m(FullyAsyncTrainer pid=363373)[0m step:2 - rollouter/active_time:431.64474534988403 - rollouter/version_time:432.88876485824585 - rollouter/idle_ratio:0.0028737625213469675
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:24:08,506 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 102
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 102
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=800, queue_size=160
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 2,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 811,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 8,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 171,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 10 local_trigger_step: 2 trigger_parameter_sync_step: 4 17:25:27.016
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:25:27,019 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 113
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 113
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 2,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 818,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 1,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 114,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 11 local_trigger_step: 3 trigger_parameter_sync_step: 4 17:26:47.150
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:26:47,153 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 50
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.29 seconds.mq_len: 50
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 2,
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  10%|████████████▌                                                                                                             | 3/29 [21:15<3:07:11, 431.98s/it]
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 819,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 51,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 12 local_trigger_step: 4 trigger_parameter_sync_step: 4 17:28:12.915
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006530284881591797
[36m(FullyAsyncTrainer pid=363373)[0m step:3 - fully_async/count/stale_samples_processed:102.0 - fully_async/count/stale_trajectory_processed:816.0 - fully_async/count/current_param_version:2.0 - fully_async/processing_time/avg:46.87032206093613 - fully_async/processing_time/max:386.4441190599464 - fully_async/processing_time/min:2.9356440398842096 - fully_async/processing_time/tp50:42.357551231223624 - fully_async/processing_time/tp99:129.14356975041778 - fully_async/processing_time/tp95:84.67059013184043 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:80.0 - fully_async/count/total_generated_samples:704.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:49.586116552352905 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:2.736789148366531 - rollout_corr/training_log_ppl:0.725494208653576 - rollout_corr/kl:0.0728608128400318 - rollout_corr/k3_kl:0.05452008766330462 - rollout_corr/rollout_ppl:2.5127643122545793 - rollout_corr/rollout_log_ppl:0.6456612090209737 - rollout_corr/log_ppl_diff:0.07983300081981903 - rollout_corr/log_ppl_abs_diff:0.07984962555709887 - rollout_corr/log_ppl_diff_max:0.6667461395263672 - rollout_corr/log_ppl_diff_min:-0.01238250732421875 - rollout_corr/ppl_ratio:1.0870618091737205 - rollout_corr/chi2_token:0.022065802572553448 - rollout_corr/chi2_seq:-0.9788687421099356 - actor/kl_loss:0.0008351033857365731 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.0012203807186750076 - actor/ppo_kl:0.0723965571500879 - actor/pg_clipfrac_lower:1.1118227121187374e-06 - actor/pg_loss:0.03739824521552757 - actor/grad_norm:0.1915555070525814 - perf/mfu/actor:0.05138052645630264 - perf/max_memory_allocated_gb:20.19743061065674 - perf/max_memory_reserved_gb:59.2734375 - perf/cpu_memory_used_gb:80.22676944732666 - actor/lr:9.25e-07 - training/global_step:12.0 - training/epoch:0.0 - critic/score/mean:0.0010385513305664062 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.0010385513305664062 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.03936746169347316 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.03936746169347316 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:358.3935546875 - response_length/max:3072.0 - response_length/min:5.0 - response_length/clip_ratio:0.001953125 - response_length_non_aborted/mean:358.3935546875 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:5.0 - response_length_non_aborted/clip_ratio:0.001953125 - response/aborted_ratio:0.0 - prompt_length/mean:103.6484375 - prompt_length/max:201.0 - prompt_length/min:69.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:52.3008855166845 - timing_s/reward:0.0008563641458749771 - timing_s/old_log_prob:0.001001844648271799 - timing_s/ref:119.196984868031 - timing_s/adv:0.27757224859669805 - timing_s/update_actor:210.99944288562983 - timing_s/step:382.7824893100187 - timing_per_token_ms/gen:0.0054502427601120455 - timing_per_token_ms/update_actor:0.2103751987320238 - timing_per_token_ms/ref:0.11483246584922883 - timing_per_token_ms/adv:0.00026003288511613435 - perf/total_num_tokens:946262.0 - perf/time_per_step:382.7824893100187 - perf/throughput:1236.03093979779 - trainer/idle_ratio:0.13663343276480336
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 2 to 3
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 0.03 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 2 to 3 ,reset staleness_samples to: 51,idle_ratio: 0.18698719810770548
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.1559147834777832 seconds, while cache cost 7.62939453125e-06 seconds,  register cost 0.0005872249603271484 seconds, update cost 0.17977404594421387 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:3 - timing_s/wait_last_valid:0.0033251577988266945 - timing_s/param_sync:1.1992601156234741
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:28:14,138 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1620454788208008 seconds, while cache cost 0.7828302383422852 seconds,  register cost 0.19555115699768066 seconds, update cost 0.17990946769714355 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 1.20 seconds, pause:0.03s, sync:1.17s
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 41.62 seconds.mq_len: 0
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.55s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 3,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 197,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 836,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 4,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=900, queue_size=68
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 3,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 951,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 124,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 119,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=1000, queue_size=168
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 13 local_trigger_step: 1 trigger_parameter_sync_step: 4 17:30:24.198
[36m(FullyAsyncTrainer pid=363373)[0m step:3 - rollouter/active_time:312.27624464035034 - rollouter/version_time:384.09757375717163 - rollouter/idle_ratio:0.18698719810770548
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:30:24,201 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 118
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 118
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 3,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1069,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 6,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 173,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 14 local_trigger_step: 2 trigger_parameter_sync_step: 4 17:31:40.744
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:31:40,748 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 113
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.31 seconds.mq_len: 113
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(RewardLoopWorker pid=365497)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 3,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1075,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 115,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 15 local_trigger_step: 3 trigger_parameter_sync_step: 4 17:33:01.411
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:33:01,414 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 51
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.33 seconds.mq_len: 51
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 3,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1075,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  14%|████████████████▊                                                                                                         | 4/29 [27:21<2:49:11, 406.07s/it]
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 51,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 16 local_trigger_step: 4 trigger_parameter_sync_step: 4 17:34:19.277
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006504058837890625
[36m(FullyAsyncTrainer pid=363373)[0m step:4 - fully_async/count/stale_samples_processed:153.0 - fully_async/count/stale_trajectory_processed:1224.0 - fully_async/count/current_param_version:3.0 - fully_async/processing_time/avg:43.764160489177584 - fully_async/processing_time/max:310.92056550690904 - fully_async/processing_time/min:0.5306954751722515 - fully_async/processing_time/tp50:39.54862891609082 - fully_async/processing_time/tp99:110.28756837484426 - fully_async/processing_time/tp95:82.53708964440156 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:80.0 - fully_async/count/total_generated_samples:960.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:42.57686686515808 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:2.3427607956465764 - rollout_corr/training_log_ppl:0.5897230694543136 - rollout_corr/kl:0.03046020023260661 - rollout_corr/k3_kl:0.02286918476513632 - rollout_corr/rollout_ppl:2.189255826744557 - rollout_corr/rollout_log_ppl:0.5562032746986806 - rollout_corr/log_ppl_diff:0.03351979847359695 - rollout_corr/log_ppl_abs_diff:0.03398015174370762 - rollout_corr/log_ppl_diff_max:0.6141473650932312 - rollout_corr/log_ppl_diff_min:-0.024148941040039062 - rollout_corr/ppl_ratio:1.0361213079033562 - rollout_corr/chi2_token:0.06060889185022004 - rollout_corr/chi2_seq:-0.5008073991154415 - actor/kl_loss:0.0014411051134821608 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.0016334552363905781 - actor/ppo_kl:0.03032878662912774 - actor/pg_clipfrac_lower:0.0 - actor/pg_loss:0.0084561057813862 - actor/grad_norm:0.23385746794531728 - perf/mfu/actor:0.05064816464483553 - perf/max_memory_allocated_gb:20.213000297546387 - perf/max_memory_reserved_gb:59.2734375 - perf/cpu_memory_used_gb:80.35570621490479 - actor/lr:1e-06 - training/global_step:16.0 - training/epoch:0.0 - critic/score/mean:0.0224609375 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.0224609375 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.008952663465606747 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.008952663465606747 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:332.2021484375 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.00048828125 - response_length_non_aborted/mean:332.2021484375 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.00048828125 - response/aborted_ratio:0.0 - prompt_length/mean:103.53125 - prompt_length/max:215.0 - prompt_length/min:68.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:45.27358859870583 - timing_s/reward:0.0008056443184614182 - timing_s/old_log_prob:0.0009818654507398605 - timing_s/ref:117.89047528104857 - timing_s/adv:0.26080511696636677 - timing_s/update_actor:201.6130439019762 - timing_s/step:365.0456138323061 - timing_per_token_ms/gen:0.005905643801023661 - timing_per_token_ms/update_actor:0.2176190501572512 - timing_per_token_ms/ref:0.11646331260762538 - timing_per_token_ms/adv:0.00023489167091009618 - perf/total_num_tokens:892382.0 - perf/time_per_step:365.0456138323061 - perf/throughput:1222.288347244655 - trainer/idle_ratio:0.12402173011590686
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 3 to 4
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 0.03 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 3 to 4 ,reset staleness_samples to: 51,idle_ratio: 0.2434849969878664
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.1505439281463623 seconds, while cache cost 6.9141387939453125e-06 seconds,  register cost 0.0005497932434082031 seconds, update cost 0.1762373447418213 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:4 - timing_s/wait_last_valid:0.002530262805521488 - timing_s/param_sync:1.1874134307727218
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:34:20,485 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1522409915924072 seconds, while cache cost 0.7713479995727539 seconds,  register cost 0.20089197158813477 seconds, update cost 0.17623114585876465 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 1.18 seconds, pause:0.03s, sync:1.16s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 4,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 189,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1084,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 47.06 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.52s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=1100, queue_size=12
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=1200, queue_size=112
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 4,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1205,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 126,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 117,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 17 local_trigger_step: 1 trigger_parameter_sync_step: 4 17:36:36.221
[36m(FullyAsyncTrainer pid=363373)[0m step:4 - rollouter/active_time:277.14303851127625 - rollouter/version_time:366.34176111221313 - rollouter/idle_ratio:0.2434849969878664
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:36:36,225 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 124
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 124
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=1300, queue_size=148
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 4,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1324,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 7,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 172,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 18 local_trigger_step: 2 trigger_parameter_sync_step: 4 17:37:50.744
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:37:50,747 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 112
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.31 seconds.mq_len: 112
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.52s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 4,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1329,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 2,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 113,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 19 local_trigger_step: 3 trigger_parameter_sync_step: 4 17:39:08.494
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:39:08,497 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 49
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 49
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 20 local_trigger_step: 4 trigger_parameter_sync_step: 4 17:40:32.544
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006716251373291016
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  17%|█████████████████████                                                                                                     | 5/29 [33:34<2:37:41, 394.24s/it]
[36m(FullyAsyncTrainer pid=363373)[0m step:5 - fully_async/count/stale_samples_processed:204.0 - fully_async/count/stale_trajectory_processed:1632.0 - fully_async/count/current_param_version:4.0 - fully_async/processing_time/avg:43.80246173329874 - fully_async/processing_time/max:216.59648952633142 - fully_async/processing_time/min:1.2385506369173527 - fully_async/processing_time/tp50:40.0519575253129 - fully_async/processing_time/tp99:111.18155718815979 - fully_async/processing_time/tp95:79.41959106251014 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:80.0 - fully_async/count/total_generated_samples:1216.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:48.02537775039673 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:2.6462520729704533 - rollout_corr/training_log_ppl:0.7325265438366285 - rollout_corr/kl:0.0677699675672858 - rollout_corr/k3_kl:0.050397419521502874 - rollout_corr/rollout_ppl:2.3093788799192696 - rollout_corr/rollout_log_ppl:0.6531306892393114 - rollout_corr/log_ppl_diff:0.07939585801251306 - rollout_corr/log_ppl_abs_diff:0.08004345987586226 - rollout_corr/log_ppl_diff_max:2.867119550704956 - rollout_corr/log_ppl_diff_min:-0.36008501052856445 - rollout_corr/ppl_ratio:1.0998756659874338 - rollout_corr/chi2_token:0.023127309943139832 - rollout_corr/chi2_seq:-0.7677741982769662 - actor/kl_loss:0.004209959542692772 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.007265059964826244 - actor/ppo_kl:0.06753109085091359 - actor/pg_clipfrac_lower:1.1602274111389896e-06 - actor/pg_loss:0.016903618318568008 - actor/grad_norm:0.25136913776775005 - perf/mfu/actor:0.049474173675668066 - perf/max_memory_allocated_gb:20.22773313522339 - perf/max_memory_reserved_gb:59.427734375 - perf/cpu_memory_used_gb:80.46976852416992 - actor/lr:1e-06 - training/global_step:20.0 - training/epoch:0.0 - critic/score/mean:0.03057861328125 - critic/score/max:1.0 - critic/score/min:-0.375 - critic/rewards/mean:0.03057861328125 - critic/rewards/max:1.0 - critic/rewards/min:-0.375 - critic/advantages/mean:-0.01651290594600141 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748551845550537 - critic/returns/mean:-0.01651290594600141 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748551845550537 - response_length/mean:330.4951171875 - response_length/max:2752.0 - response_length/min:4.0 - response_length/clip_ratio:0.0 - response_length_non_aborted/mean:330.4951171875 - response_length_non_aborted/max:2752.0 - response_length_non_aborted/min:4.0 - response_length_non_aborted/clip_ratio:0.0 - response/aborted_ratio:0.0 - prompt_length/mean:104.42578125 - prompt_length/max:190.0 - prompt_length/min:66.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:50.70429937634617 - timing_s/reward:0.0008269445970654488 - timing_s/old_log_prob:0.0010000974871218204 - timing_s/ref:116.4467135318555 - timing_s/adv:0.24438587669283152 - timing_s/update_actor:204.56915227649733 - timing_s/step:371.97227329341695 - timing_per_token_ms/gen:0.00594357197857452 - timing_per_token_ms/update_actor:0.21679354688967722 - timing_per_token_ms/ref:0.12062109460444187 - timing_per_token_ms/adv:0.00021913887041205015 - perf/total_num_tokens:890718.0 - perf/time_per_step:371.97227329341695 - perf/throughput:1197.2908519681373 - trainer/idle_ratio:0.13631203994699334
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(RewardLoopWorker pid=365510)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[36m(MessageQueue pid=367620)[0m Parameter version updated from 4 to 5
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 1.80 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 4 to 5 ,reset staleness_samples to: 51,idle_ratio: 0.003103081312025857
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.145186424255371 seconds, while cache cost 6.198883056640625e-06 seconds,  register cost 0.0005156993865966797 seconds, update cost 0.17873287200927734 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:5 - timing_s/wait_last_valid:0.003319478128105402 - timing_s/param_sync:2.960091015789658
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:40:35,527 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1457631587982178 seconds, while cache cost 0.763861894607544 seconds,  register cost 0.1991710662841797 seconds, update cost 0.17883586883544922 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 2.96 seconds, pause:1.80s, sync:1.15s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 5,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 180,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1331,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 49.34 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 5,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 229,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1380,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 36,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=1400, queue_size=56
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 5,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1474,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 113,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 130,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 21 local_trigger_step: 1 trigger_parameter_sync_step: 4 17:42:55.727
[36m(FullyAsyncTrainer pid=363373)[0m step:5 - rollouter/active_time:373.874267578125 - rollouter/version_time:375.03804111480713 - rollouter/idle_ratio:0.003103081312025857
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:42:55,730 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 67
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.40 seconds.mq_len: 67
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=1500, queue_size=92
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 5,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1556,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 31,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 148,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 22 local_trigger_step: 2 trigger_parameter_sync_step: 4 17:44:14.697
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:44:14,700 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 91
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 91
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 5,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1571,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 16,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 99,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 23 local_trigger_step: 3 trigger_parameter_sync_step: 4 17:45:40.601
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:45:40,604 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 36
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.31 seconds.mq_len: 36
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.57s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 5,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1574,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 13,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 38,
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  21%|█████████████████████████▏                                                                                                | 6/29 [40:20<2:32:33, 397.96s/it]
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(RewardLoopWorker pid=365529)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 24 local_trigger_step: 4 trigger_parameter_sync_step: 4 17:47:17.721
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006625652313232422
[36m(FullyAsyncTrainer pid=363373)[0m step:6 - fully_async/count/stale_samples_processed:255.0 - fully_async/count/stale_trajectory_processed:2040.0 - fully_async/count/current_param_version:5.0 - fully_async/processing_time/avg:46.043431532473505 - fully_async/processing_time/max:373.1202162709087 - fully_async/processing_time/min:0.6329476120881736 - fully_async/processing_time/tp50:41.59429400798399 - fully_async/processing_time/tp99:121.36482835226806 - fully_async/processing_time/tp95:88.6485841636022 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:80.0 - fully_async/count/total_generated_samples:1472.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:50.364198207855225 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:4.345498024415569 - rollout_corr/training_log_ppl:1.0803253825168078 - rollout_corr/kl:0.17379367370165888 - rollout_corr/k3_kl:0.13054768418279789 - rollout_corr/rollout_ppl:3.029682174730463 - rollout_corr/rollout_log_ppl:0.8725159113832406 - rollout_corr/log_ppl_diff:0.20780947149618295 - rollout_corr/log_ppl_abs_diff:0.20832279084042377 - rollout_corr/log_ppl_diff_max:2.8065967559814453 - rollout_corr/log_ppl_diff_min:-0.3898705244064331 - rollout_corr/ppl_ratio:1.273229200555449 - rollout_corr/chi2_token:3.4834294601255245 - rollout_corr/chi2_seq:-0.9040410820724202 - actor/kl_loss:0.006552711549324866 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.017858155989210634 - actor/ppo_kl:0.17296758604173712 - actor/pg_clipfrac_lower:2.800870802026011e-05 - actor/pg_loss:0.025564499677524766 - actor/grad_norm:0.23291811893929248 - perf/mfu/actor:0.049000946996369865 - perf/max_memory_allocated_gb:20.29266595840454 - perf/max_memory_reserved_gb:59.427734375 - perf/cpu_memory_used_gb:80.48671054840088 - actor/lr:1e-06 - training/global_step:24.0 - training/epoch:0.0 - critic/score/mean:0.03369140625 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.03369140625 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.02352039108518511 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.02352039108518511 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:369.47265625 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.0009765625 - response_length_non_aborted/mean:369.47265625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.0009765625 - response/aborted_ratio:0.0 - prompt_length/mean:103.81640625 - prompt_length/max:256.0 - prompt_length/min:72.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:53.21603406406939 - timing_s/reward:0.0009219665080308914 - timing_s/old_log_prob:0.001056515146046877 - timing_s/ref:120.94783759536222 - timing_s/adv:0.23419600073248148 - timing_s/update_actor:227.68817157670856 - timing_s/step:402.09447278268635 - timing_per_token_ms/gen:0.0051405077449386705 - timing_per_token_ms/update_actor:0.214731382849962 - timing_per_token_ms/ref:0.11871948015125922 - timing_per_token_ms/adv:0.00021977464644772096 - perf/total_num_tokens:969296.0 - perf/time_per_step:402.09447278268635 - perf/throughput:1205.3087838935057 - trainer/idle_ratio:0.1323470917065558
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 5 to 6
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 9.95 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 5 to 6 ,reset staleness_samples to: 51,idle_ratio: 0.0028471203333713113
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.163045883178711 seconds, while cache cost 5.7220458984375e-06 seconds,  register cost 0.0005061626434326172 seconds, update cost 0.18154358863830566 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:6 - timing_s/wait_last_valid:0.003045335877686739 - timing_s/param_sync:11.12113591702655
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:47:28,865 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.163651943206787 seconds, while cache cost 0.7697622776031494 seconds,  register cost 0.2078244686126709 seconds, update cost 0.1815013885498047 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 11.12 seconds, pause:9.95s, sync:1.17s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 6,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 180,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1587,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 42.28 seconds.mq_len: 0
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=1600, queue_size=1
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.55s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 6,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 239,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1646,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 46,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=1700, queue_size=100
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 6,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1771,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 72,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 171,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 25 local_trigger_step: 1 trigger_parameter_sync_step: 4 17:49:42.326
[36m(FullyAsyncTrainer pid=363373)[0m step:6 - rollouter/active_time:412.15620708465576 - rollouter/version_time:413.3330159187317 - rollouter/idle_ratio:0.0028471203333713113
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:49:42,329 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 111
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 111
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.55s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=1800, queue_size=136
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 6,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1838,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 5,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 174,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 26 local_trigger_step: 2 trigger_parameter_sync_step: 4 17:50:57.430
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:50:57,434 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 111
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 111
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.56s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 6,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1842,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 1,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 114,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 27 local_trigger_step: 3 trigger_parameter_sync_step: 4 17:52:15.762
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:52:15,765 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 51
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  24%|█████████████████████████████▍                                                                                            | 7/29 [46:42<2:24:04, 392.94s/it]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 51
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 6,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1843,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 51,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 28 local_trigger_step: 4 trigger_parameter_sync_step: 4 17:53:40.311
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006840229034423828
[36m(FullyAsyncTrainer pid=363373)[0m step:7 - fully_async/count/stale_samples_processed:306.0 - fully_async/count/stale_trajectory_processed:2448.0 - fully_async/count/current_param_version:6.0 - fully_async/processing_time/avg:46.62071585206104 - fully_async/processing_time/max:411.07645578030497 - fully_async/processing_time/min:0.5783413569442928 - fully_async/processing_time/tp50:39.308562499529216 - fully_async/processing_time/tp99:177.5968686984142 - fully_async/processing_time/tp95:102.20226303210362 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:80.0 - fully_async/count/total_generated_samples:1728.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:43.2276508808136 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:13.533128091749228 - rollout_corr/training_log_ppl:0.7832190791916299 - rollout_corr/kl:0.05143944585193667 - rollout_corr/k3_kl:0.03863191844608829 - rollout_corr/rollout_ppl:3.8343873150062944 - rollout_corr/rollout_log_ppl:0.7226321657398157 - rollout_corr/log_ppl_diff:0.06058691156853641 - rollout_corr/log_ppl_abs_diff:0.06151805551556716 - rollout_corr/log_ppl_diff_max:5.042859077453613 - rollout_corr/log_ppl_diff_min:-0.050084590911865234 - rollout_corr/ppl_ratio:1.205089430202952 - rollout_corr/chi2_token:0.3759358712214048 - rollout_corr/chi2_seq:-0.021244823810866384 - actor/kl_loss:0.006799237899215379 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.013112158356321067 - actor/ppo_kl:0.051306929892505126 - actor/pg_clipfrac_lower:4.847980512510587e-05 - actor/pg_loss:0.11024760649730998 - actor/grad_norm:0.5735904700543137 - perf/mfu/actor:0.05329743771231482 - perf/max_memory_allocated_gb:20.29266595840454 - perf/max_memory_reserved_gb:59.427734375 - perf/cpu_memory_used_gb:80.67323780059814 - actor/lr:1e-06 - training/global_step:28.0 - training/epoch:0.0 - critic/score/mean:0.08341121673583984 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.08341121673583984 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.11174125433899462 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.11174125433899462 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:363.52099609375 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.00830078125 - response_length_non_aborted/mean:363.52099609375 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.00830078125 - response/aborted_ratio:0.0 - prompt_length/mean:105.45703125 - prompt_length/max:211.0 - prompt_length/min:63.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:46.01704978244379 - timing_s/reward:0.0009369938634335995 - timing_s/old_log_prob:0.001043116208165884 - timing_s/ref:119.20150239160284 - timing_s/adv:0.2365011963993311 - timing_s/update_actor:205.88733233558014 - timing_s/step:371.35036097839475 - timing_per_token_ms/gen:0.0060420101563541965 - timing_per_token_ms/update_actor:0.17861628646058353 - timing_per_token_ms/ref:0.10116378058414965 - timing_per_token_ms/adv:0.0001888333189351641 - perf/total_num_tokens:960467.0 - perf/time_per_step:371.35036097839475 - perf/throughput:1293.2086526985768 - trainer/idle_ratio:0.12391815012971288
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 6 to 7
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 0.02 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 6 to 7 ,reset staleness_samples to: 50,idle_ratio: 0.2518429461311694
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.140575885772705 seconds, while cache cost 5.4836273193359375e-06 seconds,  register cost 0.0005199909210205078 seconds, update cost 0.18468332290649414 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:7 - timing_s/wait_last_valid:0.0030152159743010998 - timing_s/param_sync:1.1765051227994263
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:53:41,510 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1419718265533447 seconds, while cache cost 0.7548036575317383 seconds,  register cost 0.1985933780670166 seconds, update cost 0.18458127975463867 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 1.17 seconds, pause:0.03s, sync:1.15s
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 41.02 seconds.mq_len: 0
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 7,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 193,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1857,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 1,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=1900, queue_size=44
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 7,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 300,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 1964,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 108,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=2000, queue_size=144
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 29 local_trigger_step: 1 trigger_parameter_sync_step: 4 17:55:54.187
[36m(FullyAsyncTrainer pid=363373)[0m step:7 - rollouter/active_time:278.7975404262543 - rollouter/version_time:372.6457419395447 - rollouter/idle_ratio:0.2518429461311694
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:55:54,191 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 113
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.29 seconds.mq_len: 113
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 7,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2090,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 10,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 170,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 30 local_trigger_step: 2 trigger_parameter_sync_step: 4 17:57:08.694
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:57:08,698 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 110
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 110
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.56s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 7,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2095,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 5,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 111,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 31 local_trigger_step: 3 trigger_parameter_sync_step: 4 17:58:25.734
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 17:58:25,737 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 48
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 48
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 32 local_trigger_step: 4 trigger_parameter_sync_step: 4 17:59:49.449
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  28%|█████████████████████████████████▋                                                                                        | 8/29 [52:51<2:14:52, 385.36s/it]
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006654262542724609
[36m(FullyAsyncTrainer pid=363373)[0m step:8 - fully_async/count/stale_samples_processed:357.0 - fully_async/count/stale_trajectory_processed:2856.0 - fully_async/count/current_param_version:7.0 - fully_async/processing_time/avg:44.14910709455489 - fully_async/processing_time/max:277.5243727406487 - fully_async/processing_time/min:0.8859860617667437 - fully_async/processing_time/tp50:40.01785224158084 - fully_async/processing_time/tp99:110.11421628059352 - fully_async/processing_time/tp95:82.41992315248352 - fully_async/monitor/active_tasks_size:105.75 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:80.0 - fully_async/count/total_generated_samples:1984.0 - fully_async/count/staleness_samples:265.5 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:41.931934118270874 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:2.8894070561826806 - rollout_corr/training_log_ppl:0.7742062237090126 - rollout_corr/kl:0.0607262064471748 - rollout_corr/k3_kl:0.04673101332662517 - rollout_corr/rollout_ppl:2.616356608205216 - rollout_corr/rollout_log_ppl:0.7018719916321753 - rollout_corr/log_ppl_diff:0.07233423372744592 - rollout_corr/log_ppl_abs_diff:0.07258511681944402 - rollout_corr/log_ppl_diff_max:1.8254094123840332 - rollout_corr/log_ppl_diff_min:-0.026539325714111328 - rollout_corr/ppl_ratio:1.0830916218365403 - rollout_corr/chi2_token:0.1376310838432646 - rollout_corr/chi2_seq:-0.6367794964211385 - actor/kl_loss:0.009836525643807631 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.009910454134719575 - actor/ppo_kl:0.06041797470065517 - actor/pg_clipfrac_lower:5.611879185756994e-06 - actor/pg_loss:0.015772187990129125 - actor/grad_norm:0.3480419338361518 - perf/mfu/actor:0.04988302669230374 - perf/max_memory_allocated_gb:20.302605628967285 - perf/max_memory_reserved_gb:59.427734375 - perf/cpu_memory_used_gb:80.6858606338501 - actor/lr:1e-06 - training/global_step:32.0 - training/epoch:0.0 - critic/score/mean:0.064453125 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.064453125 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.015280653082299978 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-1.870825171470642 - critic/returns/mean:-0.015280653082299978 - critic/returns/max:2.4748666286468506 - critic/returns/min:-1.870825171470642 - response_length/mean:338.38525390625 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.00048828125 - response_length_non_aborted/mean:338.38525390625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.00048828125 - response/aborted_ratio:0.0 - prompt_length/mean:104.48046875 - prompt_length/max:199.0 - prompt_length/min:67.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:44.703268450219184 - timing_s/reward:0.001221996732056141 - timing_s/old_log_prob:0.0011594542302191257 - timing_s/ref:115.21702551562339 - timing_s/adv:0.24492902867496014 - timing_s/update_actor:207.6788180298172 - timing_s/step:367.85217637801543 - timing_per_token_ms/gen:0.005718362236352939 - timing_per_token_ms/update_actor:0.21302549085884523 - timing_per_token_ms/ref:0.11582582098498437 - timing_per_token_ms/adv:0.00022877292101400963 - perf/total_num_tokens:906989.0 - perf/time_per_step:367.85217637801543 - perf/throughput:1232.817226923176 - trainer/idle_ratio:0.12152508893757591
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 7,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2098,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 2,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 50,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=2100, queue_size=52
[36m(MessageQueue pid=367620)[0m Parameter version updated from 7 to 8
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 25.24 seconds
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 7 to 8 ,reset staleness_samples to: 52,idle_ratio: 0.0030108769337756636
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.1741993427276611 seconds, while cache cost 5.4836273193359375e-06 seconds,  register cost 0.0004870891571044922 seconds, update cost 0.18619775772094727 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:8 - timing_s/wait_last_valid:0.0032561267726123333 - timing_s/param_sync:26.426758855115622
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:00:15,895 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1736974716186523 seconds, while cache cost 0.7845685482025146 seconds,  register cost 0.19819879531860352 seconds, update cost 0.1860947608947754 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 26.42 seconds, pause:25.24s, sync:1.18s
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 38.49 seconds.mq_len: 0
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 8,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 194,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2113,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 1,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=2200, queue_size=88
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 8,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 305,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2224,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 112,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 33 local_trigger_step: 1 trigger_parameter_sync_step: 4 18:02:20.058
[36m(FullyAsyncTrainer pid=363373)[0m step:8 - rollouter/active_time:393.1868932247162 - rollouter/version_time:394.37430572509766 - rollouter/idle_ratio:0.0030108769337756636
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:02:20,062 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 95
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.29 seconds.mq_len: 95
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=2300, queue_size=124
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 8,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2344,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 11,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 168,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 34 local_trigger_step: 2 trigger_parameter_sync_step: 4 18:03:31.975
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:03:31,979 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 112
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 112
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.55s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 8,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2353,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 2,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 113,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 35 local_trigger_step: 3 trigger_parameter_sync_step: 4 18:04:49.853
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:04:49,856 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 49
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.28 seconds.mq_len: 49
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 36 local_trigger_step: 4 trigger_parameter_sync_step: 4 18:06:20.875
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006680488586425781
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  31%|█████████████████████████████████████▊                                                                                    | 9/29 [59:23<2:09:05, 387.26s/it]
[36m(FullyAsyncTrainer pid=363373)[0m step:9 - fully_async/count/stale_samples_processed:409.0 - fully_async/count/stale_trajectory_processed:3272.0 - fully_async/count/current_param_version:8.0 - fully_async/processing_time/avg:41.3238812267025 - fully_async/processing_time/max:391.85093027399853 - fully_async/processing_time/min:0.5365428128279746 - fully_async/processing_time/tp50:36.92066988762235 - fully_async/processing_time/tp99:111.79385670326411 - fully_async/processing_time/tp95:77.76352112408495 - fully_async/monitor/active_tasks_size:105.75 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:80.0 - fully_async/count/total_generated_samples:2240.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:39.36254405975342 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:2.599081047465938 - rollout_corr/training_log_ppl:0.7346572180780969 - rollout_corr/kl:0.05225241658401611 - rollout_corr/k3_kl:0.0407936719311923 - rollout_corr/rollout_ppl:2.4245149790464815 - rollout_corr/rollout_log_ppl:0.6753222476167368 - rollout_corr/log_ppl_diff:0.0593349701700719 - rollout_corr/log_ppl_abs_diff:0.0595430852948549 - rollout_corr/log_ppl_diff_max:1.3030970096588135 - rollout_corr/log_ppl_diff_min:-0.0719071626663208 - rollout_corr/ppl_ratio:1.0643525732760941 - rollout_corr/chi2_token:1.3492601944409188 - rollout_corr/chi2_seq:-0.6949461662606038 - actor/kl_loss:0.015629057403086098 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.011283860378997404 - actor/ppo_kl:0.05202673331395301 - actor/pg_clipfrac_lower:5.383777899182998e-06 - actor/pg_loss:0.05603930759126346 - actor/grad_norm:0.4489685891609778 - perf/mfu/actor:0.047830872091600106 - perf/max_memory_allocated_gb:20.302605628967285 - perf/max_memory_reserved_gb:59.427734375 - perf/cpu_memory_used_gb:80.891282081604 - actor/lr:1e-06 - training/global_step:36.0 - training/epoch:0.0 - critic/score/mean:0.103515625 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.103515625 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.05769772222265601 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.05769772222265601 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:321.1142578125 - response_length/max:3072.0 - response_length/min:4.0 - response_length/clip_ratio:0.001953125 - response_length_non_aborted/mean:321.1142578125 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:4.0 - response_length_non_aborted/clip_ratio:0.001953125 - response/aborted_ratio:0.0 - prompt_length/mean:103.44921875 - prompt_length/max:168.0 - prompt_length/min:66.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:42.121667832601815 - timing_s/reward:0.0008824439719319344 - timing_s/old_log_prob:0.0010559558868408203 - timing_s/ref:114.58488596556708 - timing_s/adv:0.2517894874326885 - timing_s/update_actor:207.90109894890338 - timing_s/step:364.8679095688276 - timing_per_token_ms/gen:0.00584249764610398 - timing_per_token_ms/update_actor:0.21823941500667435 - timing_per_token_ms/ref:0.12297794734979811 - timing_per_token_ms/adv:0.00024801150742143654 - perf/total_num_tokens:869506.0 - perf/time_per_step:364.8679095688276 - perf/throughput:1191.5353162018473 - trainer/idle_ratio:0.11544360774938502
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 8 to 9
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 73.29 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 8 to 9 ,reset staleness_samples to: 51,idle_ratio: 0.0027517850157319224
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.1956439018249512 seconds, while cache cost 5.4836273193359375e-06 seconds,  register cost 0.0004916191101074219 seconds, update cost 0.17745733261108398 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:9 - timing_s/wait_last_valid:0.0033410671167075634 - timing_s/param_sync:74.49587062001228
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:07:35,396 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1963894367218018 seconds, while cache cost 0.8089003562927246 seconds,  register cost 0.20371556282043457 seconds, update cost 0.17743587493896484 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 74.49 seconds, pause:73.29s, sync:1.20s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 9,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 180,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2355,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 45.10 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.56s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=2400, queue_size=32
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 9,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 245,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2420,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 52,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=2500, queue_size=132
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 37 local_trigger_step: 1 trigger_parameter_sync_step: 4 18:09:43.690
[36m(FullyAsyncTrainer pid=363373)[0m step:9 - rollouter/active_time:438.2866017818451 - rollouter/version_time:439.496000289917 - rollouter/idle_ratio:0.0027517850157319224
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:09:43,694 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 81
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 81
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 9,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2524,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 87,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 92,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 38 local_trigger_step: 2 trigger_parameter_sync_step: 4 18:10:58.539
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:10:58,542 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 100
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.31 seconds.mq_len: 100
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 9,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2596,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 15,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 100,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=2600, queue_size=104
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 39 local_trigger_step: 3 trigger_parameter_sync_step: 4 18:12:16.171
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:12:16,174 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 42
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.31 seconds.mq_len: 42
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.58s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 9,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2604,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 7,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 44,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 40 local_trigger_step: 4 trigger_parameter_sync_step: 4 18:13:47.788
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006620883941650391
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  34%|█████████████████████████████████████████                                                                              | 10/29 [1:06:50<2:08:27, 405.67s/it]
[36m(FullyAsyncTrainer pid=363373)[0m step:10 - fully_async/count/stale_samples_processed:460.0 - fully_async/count/stale_trajectory_processed:3680.0 - fully_async/count/current_param_version:9.0 - fully_async/processing_time/avg:43.07527110980618 - fully_async/processing_time/max:354.85901199886575 - fully_async/processing_time/min:1.28614618210122 - fully_async/processing_time/tp50:37.77212382451398 - fully_async/processing_time/tp99:118.43620265634148 - fully_async/processing_time/tp95:86.77761244788417 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:79.75 - fully_async/count/total_generated_samples:2496.0 - fully_async/count/staleness_samples:265.75 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:46.02991986274719 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:2.972508210251349 - rollout_corr/training_log_ppl:0.8798111472258433 - rollout_corr/kl:0.07726252542704266 - rollout_corr/k3_kl:0.05694519286385015 - rollout_corr/rollout_ppl:2.6934512736757226 - rollout_corr/rollout_log_ppl:0.7917799361940911 - rollout_corr/log_ppl_diff:0.08803120837268183 - rollout_corr/log_ppl_abs_diff:0.08810230340941674 - rollout_corr/log_ppl_diff_max:1.8278988599777222 - rollout_corr/log_ppl_diff_min:-0.020794957876205444 - rollout_corr/ppl_ratio:1.0982805668647453 - rollout_corr/chi2_token:0.20999418405419212 - rollout_corr/chi2_seq:-0.8218230729937137 - actor/kl_loss:0.022068221554963317 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.018751921580057788 - actor/ppo_kl:0.07702811239226325 - actor/pg_clipfrac_lower:1.9742238625668546e-05 - actor/pg_loss:0.04764248511792119 - actor/grad_norm:0.4151287135203707 - perf/mfu/actor:0.050056886896773345 - perf/max_memory_allocated_gb:20.302605628967285 - perf/max_memory_reserved_gb:59.427734375 - perf/cpu_memory_used_gb:80.95976543426514 - actor/lr:1e-06 - training/global_step:40.0 - training/epoch:0.0 - critic/score/mean:0.12109375 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.12109375 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.046133624855428934 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.046133624855428934 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:335.96337890625 - response_length/max:3072.0 - response_length/min:5.0 - response_length/clip_ratio:0.0009765625 - response_length_non_aborted/mean:335.96337890625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:5.0 - response_length_non_aborted/clip_ratio:0.0009765625 - response/aborted_ratio:0.0 - prompt_length/mean:104.48046875 - prompt_length/max:196.0 - prompt_length/min:69.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:48.895016819704324 - timing_s/reward:0.0008909851312637329 - timing_s/old_log_prob:0.001098634209483862 - timing_s/ref:117.32203518040478 - timing_s/adv:0.23681082157418132 - timing_s/update_actor:205.83467377070338 - timing_s/step:372.2965566269122 - timing_per_token_ms/gen:0.005662913653791894 - timing_per_token_ms/update_actor:0.2169395073823613 - timing_per_token_ms/ref:0.12094144300728049 - timing_per_token_ms/adv:0.00024391943040638669 - perf/total_num_tokens:902029.0 - perf/time_per_step:372.2965566269122 - perf/throughput:1211.4388166420058 - trainer/idle_ratio:0.13133351880206418
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 9 to 10
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 34.83 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 9 to 10 ,reset staleness_samples to: 51,idle_ratio: 0.002814791776973413
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.136134147644043 seconds, while cache cost 5.9604644775390625e-06 seconds,  register cost 0.0004830360412597656 seconds, update cost 0.15817642211914062 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:10 - timing_s/wait_last_valid:0.0032355780713260174 - timing_s/param_sync:35.973125289194286
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:14:23,784 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.135538101196289 seconds, while cache cost 0.7710733413696289 seconds,  register cost 0.20160603523254395 seconds, update cost 0.15819692611694336 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 35.97 seconds, pause:34.83s, sync:1.14s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 10,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 180,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2611,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 50.58 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 10,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 231,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2662,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 38,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=2700, queue_size=76
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 10,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2748,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 119,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 124,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 41 local_trigger_step: 1 trigger_parameter_sync_step: 4 18:16:52.072
[36m(FullyAsyncTrainer pid=363373)[0m step:10 - rollouter/active_time:407.2326898574829 - rollouter/version_time:408.382200717926 - rollouter/idle_ratio:0.002814791776973413
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:16:52,076 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 77
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.28 seconds.mq_len: 77
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.57s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=2800, queue_size=112
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 10,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2823,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 44,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 135,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 42 local_trigger_step: 2 trigger_parameter_sync_step: 4 18:18:09.375
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:18:09,378 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 78
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.31 seconds.mq_len: 78
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.55s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 10,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2838,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 29,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 86,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 43 local_trigger_step: 3 trigger_parameter_sync_step: 4 18:19:28.207
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:19:28,210 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 29
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 29
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.60s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 10,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2849,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 18,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 33,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  38%|█████████████████████████████████████████████▏                                                                         | 11/29 [1:13:53<2:03:17, 410.96s/it]

[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 44 local_trigger_step: 4 trigger_parameter_sync_step: 4 18:20:50.735
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006482601165771484
[36m(FullyAsyncTrainer pid=363373)[0m step:11 - fully_async/count/stale_samples_processed:511.0 - fully_async/count/stale_trajectory_processed:4088.0 - fully_async/count/current_param_version:10.0 - fully_async/processing_time/avg:45.72998190939211 - fully_async/processing_time/max:406.0448738527484 - fully_async/processing_time/min:1.0789738106541336 - fully_async/processing_time/tp50:39.35716840164969 - fully_async/processing_time/tp99:169.3710924096777 - fully_async/processing_time/tp95:93.10669805431971 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:80.0 - fully_async/count/total_generated_samples:2752.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:51.474971294403076 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:4.591318985106488 - rollout_corr/training_log_ppl:1.08425762093859 - rollout_corr/kl:0.14824227538977083 - rollout_corr/k3_kl:0.10942612741769749 - rollout_corr/rollout_ppl:3.5059001692563503 - rollout_corr/rollout_log_ppl:0.9182193841535539 - rollout_corr/log_ppl_diff:0.16603823625159395 - rollout_corr/log_ppl_abs_diff:0.1660428352567647 - rollout_corr/log_ppl_diff_max:1.3731963634490967 - rollout_corr/log_ppl_diff_min:-0.0032722949981689453 - rollout_corr/ppl_ratio:1.193526598881683 - rollout_corr/chi2_token:0.45383644785357385 - rollout_corr/chi2_seq:-0.9968447973731429 - actor/kl_loss:0.030284775676390437 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.03093381584881269 - actor/ppo_kl:0.14775463807269712 - actor/pg_clipfrac_lower:3.526805510438242e-05 - actor/pg_loss:0.08782904601389513 - actor/grad_norm:0.3849801882483598 - perf/mfu/actor:0.05216345181463027 - perf/max_memory_allocated_gb:20.384252548217773 - perf/max_memory_reserved_gb:59.427734375 - perf/cpu_memory_used_gb:81.05796813964844 - actor/lr:1e-06 - training/global_step:44.0 - training/epoch:0.0 - critic/score/mean:0.08364391326904297 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.08364391326904297 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.08634884539060295 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.08634884539060295 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:372.8857421875 - response_length/max:3072.0 - response_length/min:9.0 - response_length/clip_ratio:0.00439453125 - response_length_non_aborted/mean:372.8857421875 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:9.0 - response_length_non_aborted/clip_ratio:0.00439453125 - response/aborted_ratio:0.0 - prompt_length/mean:103.46484375 - prompt_length/max:206.0 - prompt_length/min:70.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:54.37544150883332 - timing_s/reward:0.0011939569376409054 - timing_s/old_log_prob:0.001257417257875204 - timing_s/ref:116.98056286014616 - timing_s/adv:0.2447711182758212 - timing_s/update_actor:215.23594588879496 - timing_s/step:386.8452723277733 - timing_per_token_ms/gen:0.005759214396652936 - timing_per_token_ms/update_actor:0.21335452005443678 - timing_per_token_ms/ref:0.10554847916128725 - timing_per_token_ms/adv:0.00019852701939567768 - perf/total_num_tokens:975566.0 - perf/time_per_step:386.8452723277733 - perf/throughput:1260.9253231010211 - trainer/idle_ratio:0.14056121503473126
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 10 to 11
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 26.49 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 10 to 11 ,reset staleness_samples to: 51,idle_ratio: 0.002721867166947556
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.1145689487457275 seconds, while cache cost 6.9141387939453125e-06 seconds,  register cost 0.00048351287841796875 seconds, update cost 0.17778992652893066 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:11 - timing_s/wait_last_valid:0.0033706678077578545 - timing_s/param_sync:27.610537617933005
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:21:18,367 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.0900146961212158 seconds, while cache cost 0.8199353218078613 seconds,  register cost 0.087158203125 seconds, update cost 0.17775964736938477 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 27.61 seconds, pause:26.49s, sync:1.12s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 11,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 180,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2867,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 39.19 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.56s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=2900, queue_size=20
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 11,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 263,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 2950,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 70,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=3000, queue_size=120
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 45 local_trigger_step: 1 trigger_parameter_sync_step: 4 18:23:33.647
[36m(FullyAsyncTrainer pid=363373)[0m step:11 - rollouter/active_time:413.45047187805176 - rollouter/version_time:414.5789005756378 - rollouter/idle_ratio:0.002721867166947556
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:23:33,650 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 124
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.31 seconds.mq_len: 124
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.57s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 11,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3077,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 46,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 133,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=3100, queue_size=156
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 46 local_trigger_step: 2 trigger_parameter_sync_step: 4 18:24:45.898
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:24:45,901 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 102
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.31 seconds.mq_len: 102
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 11,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3110,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 13,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 102,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 47 local_trigger_step: 3 trigger_parameter_sync_step: 4 18:26:00.962
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:26:00,965 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 41
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.28 seconds.mq_len: 41
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 11,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3114,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 9,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 42,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 48 local_trigger_step: 4 trigger_parameter_sync_step: 4 18:27:18.781
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  41%|█████████████████████████████████████████████████▏                                                                     | 12/29 [1:20:21<1:54:27, 403.99s/it]
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006377696990966797
[36m(FullyAsyncTrainer pid=363373)[0m step:12 - fully_async/count/stale_samples_processed:562.0 - fully_async/count/stale_trajectory_processed:4496.0 - fully_async/count/current_param_version:11.0 - fully_async/processing_time/avg:42.87981732558433 - fully_async/processing_time/max:412.42839926388115 - fully_async/processing_time/min:2.9860994927585125 - fully_async/processing_time/tp50:33.46100828575436 - fully_async/processing_time/tp99:172.34681842777994 - fully_async/processing_time/tp95:118.11819490530759 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:80.0 - fully_async/count/total_generated_samples:3008.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:40.081682205200195 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:3.334148075952263 - rollout_corr/training_log_ppl:0.9135702386929953 - rollout_corr/kl:0.07554673164355674 - rollout_corr/k3_kl:0.0677504495089212 - rollout_corr/rollout_ppl:2.9273914250541604 - rollout_corr/rollout_log_ppl:0.8272508917714407 - rollout_corr/log_ppl_diff:0.08631934321325445 - rollout_corr/log_ppl_abs_diff:0.08648467861029632 - rollout_corr/log_ppl_diff_max:1.002781867980957 - rollout_corr/log_ppl_diff_min:-0.021570861339569092 - rollout_corr/ppl_ratio:1.0973766678807588 - rollout_corr/chi2_token:59.13595566044932 - rollout_corr/chi2_seq:-0.8720510322169103 - actor/kl_loss:0.040062209566008714 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.022813907589429215 - actor/ppo_kl:0.07526625373178705 - actor/pg_clipfrac_lower:1.9646663811825516e-05 - actor/pg_loss:0.16360548192590907 - actor/grad_norm:0.6467331694609688 - perf/mfu/actor:0.05169050080940295 - perf/max_memory_allocated_gb:20.397120475769043 - perf/max_memory_reserved_gb:59.427734375 - perf/cpu_memory_used_gb:81.20337772369385 - actor/lr:1e-06 - training/global_step:48.0 - training/epoch:0.0 - critic/score/mean:0.11992263793945312 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.11992263793945312 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.16491964273154736 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.16491964273154736 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:346.640625 - response_length/max:3072.0 - response_length/min:18.0 - response_length/clip_ratio:0.01171875 - response_length_non_aborted/mean:346.640625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:18.0 - response_length_non_aborted/clip_ratio:0.01171875 - response/aborted_ratio:0.0 - prompt_length/mean:101.8671875 - prompt_length/max:181.0 - prompt_length/min:64.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:42.94204613985494 - timing_s/reward:0.000869236420840025 - timing_s/old_log_prob:0.0010337834246456623 - timing_s/ref:115.87259588297457 - timing_s/adv:0.24830151163041592 - timing_s/update_actor:201.2247283346951 - timing_s/step:360.29522736696526 - timing_per_token_ms/gen:0.00637005545851554 - timing_per_token_ms/update_actor:0.17463143015086546 - timing_per_token_ms/ref:0.09421796993840309 - timing_per_token_ms/adv:0.0001680310375370887 - perf/total_num_tokens:918544.0 - perf/time_per_step:360.29522736696526 - perf/throughput:1274.7101962919583 - trainer/idle_ratio:0.11918572014865442
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 11 to 12
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 25.84 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 11 to 12 ,reset staleness_samples to: 51,idle_ratio: 0.003016400719508816
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.1542937755584717 seconds, while cache cost 5.9604644775390625e-06 seconds,  register cost 0.0004878044128417969 seconds, update cost 0.17824029922485352 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:12 - timing_s/wait_last_valid:0.0029961545951664448 - timing_s/param_sync:27.004314087331295
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:27:45,810 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1549139022827148 seconds, while cache cost 0.7750539779663086 seconds,  register cost 0.19619178771972656 seconds, update cost 0.17816805839538574 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 27.00 seconds, pause:25.84s, sync:1.16s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 12,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 180,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3123,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 39.07 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 12,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 246,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3189,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 53,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=3200, queue_size=64
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 49 local_trigger_step: 1 trigger_parameter_sync_step: 4 18:29:53.235
[36m(FullyAsyncTrainer pid=363373)[0m step:12 - rollouter/active_time:386.26941323280334 - rollouter/version_time:387.438081741333 - rollouter/idle_ratio:0.003016400719508816
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:29:53,238 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 96
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.31 seconds.mq_len: 96
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.52s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=3300, queue_size=100
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 12,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3304,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 75,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 104,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 50 local_trigger_step: 2 trigger_parameter_sync_step: 4 18:31:05.475
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:31:05,478 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 12,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3364,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 15,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 134,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 100
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 100
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 51 local_trigger_step: 3 trigger_parameter_sync_step: 4 18:32:21.635
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:32:21,638 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 44
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.34 seconds.mq_len: 44
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 12,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3373,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 6,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 45,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 52 local_trigger_step: 4 trigger_parameter_sync_step: 4 18:33:40.054
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006253719329833984
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  45%|█████████████████████████████████████████████████████▎                                                                 | 13/29 [1:26:42<1:45:53, 397.11s/it]
[36m(FullyAsyncTrainer pid=363373)[0m step:13 - fully_async/count/stale_samples_processed:613.0 - fully_async/count/stale_trajectory_processed:4904.0 - fully_async/count/current_param_version:12.0 - fully_async/processing_time/avg:39.18060297450893 - fully_async/processing_time/max:385.2479658620432 - fully_async/processing_time/min:3.089109217748046 - fully_async/processing_time/tp50:32.092451427015476 - fully_async/processing_time/tp99:152.6223564461665 - fully_async/processing_time/tp95:87.38944423708011 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:80.0 - fully_async/count/total_generated_samples:3264.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:40.02720046043396 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:3.271065450728692 - rollout_corr/training_log_ppl:0.8813130205773851 - rollout_corr/kl:0.05220719038921617 - rollout_corr/k3_kl:0.04008575389099163 - rollout_corr/rollout_ppl:3.062647089125618 - rollout_corr/rollout_log_ppl:0.8214719004786544 - rollout_corr/log_ppl_diff:0.05984112264336029 - rollout_corr/log_ppl_abs_diff:0.06003523608040418 - rollout_corr/log_ppl_diff_max:1.2477582693099976 - rollout_corr/log_ppl_diff_min:-0.02880859375 - rollout_corr/ppl_ratio:1.0655222982240975 - rollout_corr/chi2_token:0.05277924222593439 - rollout_corr/chi2_seq:-0.5000833897236212 - actor/kl_loss:0.053140240817417576 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.015693301837863386 - actor/ppo_kl:0.05199064407020043 - actor/pg_clipfrac_lower:1.266040833196e-05 - actor/pg_loss:0.1095602495217072 - actor/grad_norm:0.5493384032140193 - perf/mfu/actor:0.04949677823318826 - perf/max_memory_allocated_gb:20.397120475769043 - perf/max_memory_reserved_gb:59.427734375 - perf/cpu_memory_used_gb:81.1875171661377 - actor/lr:1e-06 - training/global_step:52.0 - training/epoch:0.0 - critic/score/mean:0.1267070770263672 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.1267070770263672 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.1099829119630158 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.1099829119630158 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:316.5625 - response_length/max:3072.0 - response_length/min:24.0 - response_length/clip_ratio:0.0048828125 - response_length_non_aborted/mean:316.5625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:24.0 - response_length_non_aborted/clip_ratio:0.0048828125 - response/aborted_ratio:0.0 - prompt_length/mean:103.96484375 - prompt_length/max:201.0 - prompt_length/min:73.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:42.75603131670505 - timing_s/reward:0.0007683336734771729 - timing_s/old_log_prob:0.0010017640888690948 - timing_s/ref:113.35165468463674 - timing_s/adv:0.23295629024505615 - timing_s/update_actor:197.80456667765975 - timing_s/step:354.1526193669997 - timing_per_token_ms/gen:0.006529273885891384 - timing_per_token_ms/update_actor:0.2080107790745171 - timing_per_token_ms/ref:0.11159374604292867 - timing_per_token_ms/adv:0.00021421820679604734 - perf/total_num_tokens:861240.0 - perf/time_per_step:354.1526193669997 - perf/throughput:1215.9164621446976 - trainer/idle_ratio:0.12072770037145487
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 12 to 13
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 45.37 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 12 to 13 ,reset staleness_samples to: 51,idle_ratio: 0.0028768748731711202
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.1399364471435547 seconds, while cache cost 5.7220458984375e-06 seconds,  register cost 0.0004723072052001953 seconds, update cost 0.17741799354553223 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:13 - timing_s/wait_last_valid:0.0023985528387129307 - timing_s/param_sync:46.515929139219224
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:34:26,591 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.140425205230713 seconds, while cache cost 0.7633664608001709 seconds,  register cost 0.1959245204925537 seconds, update cost 0.1773982048034668 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 46.51 seconds, pause:45.37s, sync:1.14s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 13,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 180,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3379,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 43.23 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=3400, queue_size=8
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 13,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 244,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3443,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 51,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=3500, queue_size=108
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 13,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3549,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 86,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 157,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 53 local_trigger_step: 1 trigger_parameter_sync_step: 4 18:36:42.246
[36m(FullyAsyncTrainer pid=363373)[0m step:13 - rollouter/active_time:399.622793674469 - rollouter/version_time:400.77577543258667 - rollouter/idle_ratio:0.0028768748731711202
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:36:42,249 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 95
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 95
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=3600, queue_size=144
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 13,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3606,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 29,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 150,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 54 local_trigger_step: 2 trigger_parameter_sync_step: 4 18:37:55.607
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:37:55,610 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 87
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.31 seconds.mq_len: 87
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 55 local_trigger_step: 3 trigger_parameter_sync_step: 4 18:39:21.091
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:39:21,095 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 31
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.31 seconds.mq_len: 31
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.57s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 13,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3615,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 20,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 31,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 13,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3618,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 17,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 34,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  48%|█████████████████████████████████████████████████████████▍                                                             | 14/29 [1:33:47<1:41:22, 405.48s/it]
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 56 local_trigger_step: 4 trigger_parameter_sync_step: 4 18:40:44.890
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.00067901611328125
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m step:14 - fully_async/count/stale_samples_processed:664.0 - fully_async/count/stale_trajectory_processed:5312.0 - fully_async/count/current_param_version:13.0 - fully_async/processing_time/avg:39.53039780895415 - fully_async/processing_time/max:398.61851972108707 - fully_async/processing_time/min:1.749879782088101 - fully_async/processing_time/tp50:32.35594011860667 - fully_async/processing_time/tp99:162.92585630882405 - fully_async/processing_time/tp95:86.77325246624531 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:80.0 - fully_async/count/total_generated_samples:3520.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:44.14959502220154 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:3.876264509737148 - rollout_corr/training_log_ppl:1.019961644346795 - rollout_corr/kl:0.08887022890155251 - rollout_corr/k3_kl:0.06579851658511195 - rollout_corr/rollout_ppl:3.3328809461552344 - rollout_corr/rollout_log_ppl:0.9172596225936993 - rollout_corr/log_ppl_diff:0.10270201777585769 - rollout_corr/log_ppl_abs_diff:0.10273310344543277 - rollout_corr/log_ppl_diff_max:1.937260389328003 - rollout_corr/log_ppl_diff_min:-0.020767688751220703 - rollout_corr/ppl_ratio:1.1167168350285523 - rollout_corr/chi2_token:0.20880858063439786 - rollout_corr/chi2_seq:-0.9782660590659447 - actor/kl_loss:0.0611157094676741 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.019809357946017975 - actor/ppo_kl:0.08862580678296042 - actor/pg_clipfrac_lower:3.086959747658891e-05 - actor/pg_loss:0.076482003924742 - actor/grad_norm:0.44356591173704957 - perf/mfu/actor:0.04722216978074827 - perf/max_memory_allocated_gb:20.48794460296631 - perf/max_memory_reserved_gb:59.484375 - perf/cpu_memory_used_gb:81.17360973358154 - actor/lr:1e-06 - training/global_step:56.0 - training/epoch:0.0 - critic/score/mean:0.09143543243408203 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.09143543243408203 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.07665230985730886 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.07665230985730886 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:324.74853515625 - response_length/max:3072.0 - response_length/min:11.0 - response_length/clip_ratio:0.00390625 - response_length_non_aborted/mean:324.74853515625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:11.0 - response_length_non_aborted/clip_ratio:0.00390625 - response/aborted_ratio:0.0 - prompt_length/mean:103.86328125 - prompt_length/max:194.0 - prompt_length/min:69.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:46.95455150445923 - timing_s/reward:0.0007991255261003971 - timing_s/old_log_prob:0.0010175453498959541 - timing_s/ref:118.6484202039428 - timing_s/adv:0.24912195187062025 - timing_s/update_actor:212.3487856495194 - timing_s/step:378.208471941296 - timing_per_token_ms/gen:0.006538357029119561 - timing_per_token_ms/update_actor:0.2160692715364287 - timing_per_token_ms/ref:0.10988676444288419 - timing_per_token_ms/adv:0.0002172790748755111 - perf/total_num_tokens:877797.0 - perf/time_per_step:378.208471941296 - perf/throughput:1160.46713006504 - trainer/idle_ratio:0.12414991991968738
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 13 to 14
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 25.70 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 13 to 14 ,reset staleness_samples to: 51,idle_ratio: 0.003123605763467374
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.2526359558105469 seconds, while cache cost 7.152557373046875e-06 seconds,  register cost 0.0004911422729492188 seconds, update cost 0.17693281173706055 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:14 - timing_s/wait_last_valid:0.002967835869640112 - timing_s/param_sync:26.95929296966642
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:41:11,872 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.2517049312591553 seconds, while cache cost 0.8600306510925293 seconds,  register cost 0.21060800552368164 seconds, update cost 0.17702126502990723 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 26.96 seconds, pause:25.70s, sync:1.26s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 14,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 184,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3639,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 41.28 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=3700, queue_size=52
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 14,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 304,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3759,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 111,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=3800, queue_size=152
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 57 local_trigger_step: 1 trigger_parameter_sync_step: 4 18:43:23.497
[36m(FullyAsyncTrainer pid=363373)[0m step:14 - rollouter/active_time:404.00790190696716 - rollouter/version_time:405.2738175392151 - rollouter/idle_ratio:0.003123605763467374
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:43:23,501 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 128
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.29 seconds.mq_len: 128
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 14,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3875,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 16,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 163,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 58 local_trigger_step: 2 trigger_parameter_sync_step: 4 18:44:32.339
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:44:32,342 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 106
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 106
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 14,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3885,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 6,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 109,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 59 local_trigger_step: 3 trigger_parameter_sync_step: 4 18:45:41.749
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:45:41,752 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 46
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 46
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 14,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3888,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 3,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 48,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  52%|█████████████████████████████████████████████████████████████▌                                                         | 15/29 [1:40:04<1:32:37, 396.95s/it]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 60 local_trigger_step: 4 trigger_parameter_sync_step: 4 18:47:02.069
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006368160247802734
[36m(FullyAsyncTrainer pid=363373)[0m step:15 - fully_async/count/stale_samples_processed:715.0 - fully_async/count/stale_trajectory_processed:5720.0 - fully_async/count/current_param_version:14.0 - fully_async/processing_time/avg:40.41503838875815 - fully_async/processing_time/max:402.83724980195984 - fully_async/processing_time/min:1.4974599336273968 - fully_async/processing_time/tp50:31.423625861410983 - fully_async/processing_time/tp99:172.2113432160765 - fully_async/processing_time/tp95:98.46787223968421 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:80.0 - fully_async/count/total_generated_samples:3776.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:42.16283321380615 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:3.77608344418875 - rollout_corr/training_log_ppl:0.9007258872263355 - rollout_corr/kl:0.06160652890094185 - rollout_corr/k3_kl:0.047846424483400145 - rollout_corr/rollout_ppl:3.3051244630335175 - rollout_corr/rollout_log_ppl:0.8334690745207761 - rollout_corr/log_ppl_diff:0.06725681094217068 - rollout_corr/log_ppl_abs_diff:0.06752185623640931 - rollout_corr/log_ppl_diff_max:0.852275013923645 - rollout_corr/log_ppl_diff_min:-0.03322041034698486 - rollout_corr/ppl_ratio:1.0744474933559733 - rollout_corr/chi2_token:0.7732475534604919 - rollout_corr/chi2_seq:-0.7339772696374128 - actor/kl_loss:0.06626644921322034 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.01996505901355041 - actor/ppo_kl:0.0613649725478818 - actor/pg_clipfrac_lower:3.619368091810585e-05 - actor/pg_loss:0.1671662662443007 - actor/grad_norm:0.6661974738141557 - perf/mfu/actor:0.05092135616886256 - perf/max_memory_allocated_gb:20.516846656799316 - perf/max_memory_reserved_gb:59.484375 - perf/cpu_memory_used_gb:81.29922103881836 - actor/lr:1e-06 - training/global_step:60.0 - training/epoch:0.0 - critic/score/mean:0.15723133087158203 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.15723133087158203 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.16683428874239326 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.16683428874239326 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:322.0009765625 - response_length/max:3072.0 - response_length/min:11.0 - response_length/clip_ratio:0.009765625 - response_length_non_aborted/mean:322.0009765625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:11.0 - response_length_non_aborted/clip_ratio:0.009765625 - response/aborted_ratio:0.0 - prompt_length/mean:103.58984375 - prompt_length/max:189.0 - prompt_length/min:68.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:44.911393186077476 - timing_s/reward:0.0008812947198748589 - timing_s/old_log_prob:0.0010330644436180592 - timing_s/ref:108.9234727807343 - timing_s/adv:0.23353082314133644 - timing_s/update_actor:196.03087795665488 - timing_s/step:350.1068969652988 - timing_per_token_ms/gen:0.007112365622720366 - timing_per_token_ms/update_actor:0.1890508143446786 - timing_per_token_ms/ref:0.09841992961983546 - timing_per_token_ms/adv:0.00019182366823641302 - perf/total_num_tokens:871610.0 - perf/time_per_step:350.1068969652988 - perf/throughput:1244.7769632004572 - trainer/idle_ratio:0.12827908725982315
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 14 to 15
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 48.03 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 14 to 15 ,reset staleness_samples to: 51,idle_ratio: 0.002879153774205667
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.130742073059082 seconds, while cache cost 5.4836273193359375e-06 seconds,  register cost 0.0005092620849609375 seconds, update cost 0.175323486328125 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:15 - timing_s/wait_last_valid:0.0026823249645531178 - timing_s/param_sync:49.16800021426752
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:47:51,267 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1312167644500732 seconds, while cache cost 0.7441232204437256 seconds,  register cost 0.20774412155151367 seconds, update cost 0.1753251552581787 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 49.16 seconds, pause:48.03s, sync:1.14s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 15,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 180,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3891,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=3900, queue_size=1
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 42.43 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 15,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 241,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 3952,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 48,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=4000, queue_size=96
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 61 local_trigger_step: 1 trigger_parameter_sync_step: 4 18:49:51.861
[36m(FullyAsyncTrainer pid=363373)[0m step:15 - rollouter/active_time:398.2414085865021 - rollouter/version_time:399.3913176059723 - rollouter/idle_ratio:0.002879153774205667
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:49:51,864 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 53
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.34 seconds.mq_len: 53
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 15,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4047,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 100,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 79,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=4100, queue_size=132
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 62 local_trigger_step: 2 trigger_parameter_sync_step: 4 18:50:58.672
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:50:58,675 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 69
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.29 seconds.mq_len: 69
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 15,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4107,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 40,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 75,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 63 local_trigger_step: 3 trigger_parameter_sync_step: 4 18:52:11.744
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:52:11,748 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 26
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.38 seconds.mq_len: 26
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.57s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 15,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4122,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 25,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 26,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 64 local_trigger_step: 4 trigger_parameter_sync_step: 4 18:53:27.436
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0007524490356445312
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  55%|█████████████████████████████████████████████████████████████████▋                                                     | 16/29 [1:46:29<1:25:15, 393.46s/it]
[36m(FullyAsyncTrainer pid=363373)[0m step:16 - fully_async/count/stale_samples_processed:766.0 - fully_async/count/stale_trajectory_processed:6128.0 - fully_async/count/current_param_version:15.0 - fully_async/processing_time/avg:39.19432427938705 - fully_async/processing_time/max:396.8852447080426 - fully_async/processing_time/min:1.7605368657968938 - fully_async/processing_time/tp50:32.68567987839924 - fully_async/processing_time/tp99:140.8675659925874 - fully_async/processing_time/tp95:86.72386514958924 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:63.75 - fully_async/count/total_generated_samples:4032.0 - fully_async/count/staleness_samples:265.5 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:43.440171241760254 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:4.262571392021481 - rollout_corr/training_log_ppl:1.1381005449758637 - rollout_corr/kl:0.14811603395445716 - rollout_corr/k3_kl:0.12853878153014986 - rollout_corr/rollout_ppl:3.386267950042846 - rollout_corr/rollout_log_ppl:0.9667750227829767 - rollout_corr/log_ppl_diff:0.17132552785651078 - rollout_corr/log_ppl_abs_diff:0.17137260035626473 - rollout_corr/log_ppl_diff_max:1.209226369857788 - rollout_corr/log_ppl_diff_min:-0.010881185531616211 - rollout_corr/ppl_ratio:1.2018569215044144 - rollout_corr/chi2_token:204.4011759203152 - rollout_corr/chi2_seq:-0.927660638888677 - actor/kl_loss:0.0723912692114356 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.03326065272621308 - actor/ppo_kl:0.147609707672622 - actor/pg_clipfrac_lower:4.806833988700491e-05 - actor/pg_loss:0.08271299184713349 - actor/grad_norm:0.4409430652010562 - perf/mfu/actor:0.05438642788763478 - perf/max_memory_allocated_gb:20.516846656799316 - perf/max_memory_reserved_gb:59.484375 - perf/cpu_memory_used_gb:81.23846435546875 - actor/lr:1e-06 - training/global_step:64.0 - training/epoch:0.0 - critic/score/mean:0.10431098937988281 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.10431098937988281 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.08138541737571359 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.08138541737571359 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:322.1748046875 - response_length/max:3072.0 - response_length/min:13.0 - response_length/clip_ratio:0.001953125 - response_length_non_aborted/mean:322.1748046875 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:13.0 - response_length_non_aborted/clip_ratio:0.001953125 - response/aborted_ratio:0.0 - prompt_length/mean:103.4921875 - prompt_length/max:195.0 - prompt_length/min:65.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:46.31209855526686 - timing_s/reward:0.0008594058454036713 - timing_s/old_log_prob:0.000986725091934204 - timing_s/ref:106.53260089969262 - timing_s/adv:0.23304444877430797 - timing_s/update_actor:182.9939381601289 - timing_s/step:336.08012139983475 - timing_per_token_ms/gen:0.00616582003427305 - timing_per_token_ms/update_actor:0.19679766925801784 - timing_per_token_ms/ref:0.10991596770056383 - timing_per_token_ms/adv:0.00022555588507778678 - perf/total_num_tokens:871766.0 - perf/time_per_step:336.08012139983475 - perf/throughput:1296.96156435694 - trainer/idle_ratio:0.13780076715745207
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 15 to 16
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 20.85 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 15 to 16 ,reset staleness_samples to: 51,idle_ratio: 0.0033400139553565467
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.1824076175689697 seconds, while cache cost 5.9604644775390625e-06 seconds,  register cost 0.0004830360412597656 seconds, update cost 0.175492525100708 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:16 - timing_s/wait_last_valid:0.004180812276899815 - timing_s/param_sync:22.04109493084252
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:53:49,502 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1830215454101562 seconds, while cache cost 0.8055393695831299 seconds,  register cost 0.19804906845092773 seconds, update cost 0.1754755973815918 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 22.04 seconds, pause:20.85s, sync:1.19s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 16,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 180,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4147,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 35.87 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=4200, queue_size=40
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 16,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 286,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4253,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 93,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=4300, queue_size=140
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 65 local_trigger_step: 1 trigger_parameter_sync_step: 4 18:55:55.523
[36m(FullyAsyncTrainer pid=363373)[0m step:16 - rollouter/active_time:357.0324957370758 - rollouter/version_time:358.2289855480194 - rollouter/idle_ratio:0.0033400139553565467
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:55:55,527 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 142
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.29 seconds.mq_len: 142
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 16,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4379,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 24,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 155,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 66 local_trigger_step: 2 trigger_parameter_sync_step: 4 18:57:01.736
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:57:01,739 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 107
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 107
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 16,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4396,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 7,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 108,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 67 local_trigger_step: 3 trigger_parameter_sync_step: 4 18:58:11.363
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:58:11,366 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 45
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 45
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 16,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4398,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 5,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 46,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 68 local_trigger_step: 4 trigger_parameter_sync_step: 4 18:59:24.433
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006427764892578125
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  59%|█████████████████████████████████████████████████████████████████████▊                                                 | 17/29 [1:52:26<1:16:29, 382.50s/it]
[36m(FullyAsyncTrainer pid=363373)[0m step:17 - fully_async/count/stale_samples_processed:817.0 - fully_async/count/stale_trajectory_processed:6536.0 - fully_async/count/current_param_version:16.0 - fully_async/processing_time/avg:37.62347669034648 - fully_async/processing_time/max:355.7636433560401 - fully_async/processing_time/min:1.5778179271146655 - fully_async/processing_time/tp50:29.780272963340394 - fully_async/processing_time/tp99:152.5217858893471 - fully_async/processing_time/tp95:103.377285806334 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:80.0 - fully_async/count/total_generated_samples:4288.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:36.78322649002075 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:5.868124731438611 - rollout_corr/training_log_ppl:0.8772765600425843 - rollout_corr/kl:0.07581308860041178 - rollout_corr/k3_kl:0.059423911610511006 - rollout_corr/rollout_ppl:3.4219230508938745 - rollout_corr/rollout_log_ppl:0.7947714702757408 - rollout_corr/log_ppl_diff:0.08250508799726872 - rollout_corr/log_ppl_abs_diff:0.08289593989071795 - rollout_corr/log_ppl_diff_max:1.9125494956970215 - rollout_corr/log_ppl_diff_min:-0.04553258419036865 - rollout_corr/ppl_ratio:1.0983778892356424 - rollout_corr/chi2_token:0.5129062850150181 - rollout_corr/chi2_seq:-0.3942198349196837 - actor/kl_loss:0.08086988180405846 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.02514870056749422 - actor/ppo_kl:0.07554696864509862 - actor/pg_clipfrac_lower:7.088683382621612e-05 - actor/pg_loss:0.18035429592342908 - actor/grad_norm:0.665222000607119 - perf/mfu/actor:0.05017332462152283 - perf/max_memory_allocated_gb:20.516846656799316 - perf/max_memory_reserved_gb:59.484375 - perf/cpu_memory_used_gb:81.46423721313477 - actor/lr:1e-06 - training/global_step:68.0 - training/epoch:0.0 - critic/score/mean:0.18064498901367188 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.18064498901367188 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.18011304643005133 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.18011304643005133 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:306.8662109375 - response_length/max:3072.0 - response_length/min:12.0 - response_length/clip_ratio:0.01171875 - response_length_non_aborted/mean:306.8662109375 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:12.0 - response_length_non_aborted/clip_ratio:0.01171875 - response/aborted_ratio:0.0 - prompt_length/mean:102.84375 - prompt_length/max:216.0 - prompt_length/min:66.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:39.49022268131375 - timing_s/reward:0.0009007048793137074 - timing_s/old_log_prob:0.001070285215973854 - timing_s/ref:105.80633199959993 - timing_s/adv:0.25586997997015715 - timing_s/update_actor:189.28514665178955 - timing_s/step:334.8455765382387 - timing_per_token_ms/gen:0.007566363051024704 - timing_per_token_ms/update_actor:0.19012755784697155 - timing_per_token_ms/ref:0.09485094146608496 - timing_per_token_ms/adv:0.0001866913008380844 - perf/total_num_tokens:839086.0 - perf/time_per_step:334.8455765382387 - perf/throughput:1252.9447285444103 - trainer/idle_ratio:0.11793562599685127
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=4400, queue_size=48
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 16 to 17
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 2.71 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 16 to 17 ,reset staleness_samples to: 50,idle_ratio: 0.003296956546897545
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.0989463329315186 seconds, while cache cost 7.152557373046875e-06 seconds,  register cost 0.000476837158203125 seconds, update cost 0.17446470260620117 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:17 - timing_s/wait_last_valid:0.003454238176345825 - timing_s/param_sync:3.821559571661055
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 18:59:28,275 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.0998890399932861 seconds, while cache cost 0.709003210067749 seconds,  register cost 0.21261978149414062 seconds, update cost 0.17450952529907227 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 3.82 seconds, pause:2.71s, sync:1.10s
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 40.69 seconds.mq_len: 0
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 17,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 193,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4417,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 1,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=4500, queue_size=84
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 17,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 292,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4516,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 100,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 69 local_trigger_step: 1 trigger_parameter_sync_step: 4 19:01:32.680
[36m(FullyAsyncTrainer pid=363373)[0m step:17 - rollouter/active_time:337.65482330322266 - rollouter/version_time:338.7717390060425 - rollouter/idle_ratio:0.003296956546897545
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:01:32,683 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 70
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.34 seconds.mq_len: 70
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=4600, queue_size=120
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 17,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4609,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 51,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 129,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 70 local_trigger_step: 2 trigger_parameter_sync_step: 4 19:02:40.928
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:02:40,932 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 74
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.29 seconds.mq_len: 74
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 17,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4627,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 33,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 83,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 71 local_trigger_step: 3 trigger_parameter_sync_step: 4 19:03:55.368
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:03:55,370 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 26
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.29 seconds.mq_len: 26
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 17,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4637,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 23,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 29,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 72 local_trigger_step: 4 trigger_parameter_sync_step: 4 19:05:13.791
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0007162094116210938
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  62%|█████████████████████████████████████████████████████████████████████████▊                                             | 18/29 [1:58:16<1:08:17, 372.54s/it]
[36m(FullyAsyncTrainer pid=363373)[0m step:18 - fully_async/count/stale_samples_processed:868.0 - fully_async/count/stale_trajectory_processed:6944.0 - fully_async/count/current_param_version:17.0 - fully_async/processing_time/avg:35.756288703012615 - fully_async/processing_time/max:336.7061585979536 - fully_async/processing_time/min:3.891354752704501 - fully_async/processing_time/tp50:29.063846101111267 - fully_async/processing_time/tp99:142.02446811685672 - fully_async/processing_time/tp95:81.48519867853611 - fully_async/monitor/active_tasks_size:105.75 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:4544.0 - fully_async/count/staleness_samples:265.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:41.60857081413269 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:5.427573920603005 - rollout_corr/training_log_ppl:1.1834241879692686 - rollout_corr/kl:0.20202763283340863 - rollout_corr/k3_kl:0.16027442203056846 - rollout_corr/rollout_ppl:3.2233173026637028 - rollout_corr/rollout_log_ppl:0.943606075880013 - rollout_corr/log_ppl_diff:0.2398181123865733 - rollout_corr/log_ppl_abs_diff:0.2398728515842498 - rollout_corr/log_ppl_diff_max:2.3322534561157227 - rollout_corr/log_ppl_diff_min:-0.007100582122802734 - rollout_corr/ppl_ratio:1.306684064479315 - rollout_corr/chi2_token:1.4730352139448106 - rollout_corr/chi2_seq:-0.9518936635954383 - actor/kl_loss:0.08682586626096656 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.03675937402641196 - actor/ppo_kl:0.20104672868131682 - actor/pg_clipfrac_lower:5.8124597275459486e-05 - actor/pg_loss:0.07593175456711598 - actor/grad_norm:0.46623127300721423 - perf/mfu/actor:0.048394874020221176 - perf/max_memory_allocated_gb:20.516846656799316 - perf/max_memory_reserved_gb:59.484375 - perf/cpu_memory_used_gb:81.39355754852295 - actor/lr:1e-06 - training/global_step:72.0 - training/epoch:0.0 - critic/score/mean:0.0869140625 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.0869140625 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.07406765781342983 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.07406765781342983 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:298.32666015625 - response_length/max:3072.0 - response_length/min:32.0 - response_length/clip_ratio:0.0029296875 - response_length_non_aborted/mean:298.32666015625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:32.0 - response_length_non_aborted/clip_ratio:0.0029296875 - response/aborted_ratio:0.0 - prompt_length/mean:104.125 - prompt_length/max:238.0 - prompt_length/min:56.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:44.34709100192413 - timing_s/reward:0.0008647558279335499 - timing_s/old_log_prob:0.001022594515234232 - timing_s/ref:106.78123319754377 - timing_s/adv:0.22860463429242373 - timing_s/update_actor:194.06073961779475 - timing_s/step:345.4254674911499 - timing_per_token_ms/gen:0.006089086211603359 - timing_per_token_ms/update_actor:0.2312904765911338 - timing_per_token_ms/ref:0.11475188632073773 - timing_per_token_ms/adv:0.00025310149641649086 - perf/total_num_tokens:824221.0 - perf/time_per_step:345.4254674911499 - perf/throughput:1193.0518701854508 - trainer/idle_ratio:0.12838396463358723
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 17 to 18
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 55.19 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 17 to 18 ,reset staleness_samples to: 52,idle_ratio: 0.0024994487765103157
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:0.9904093742370605 seconds, while cache cost 6.4373016357421875e-06 seconds,  register cost 0.0004935264587402344 seconds, update cost 0.18422293663024902 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:18 - timing_s/wait_last_valid:0.0034064678475260735 - timing_s/param_sync:56.19121783319861
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:06:10,007 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:0.9912235736846924 seconds, while cache cost 0.7035038471221924 seconds,  register cost 0.09925055503845215 seconds, update cost 0.18422698974609375 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 56.19 seconds, pause:55.19s, sync:1.00s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 18,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 181,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4660,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 37.70 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.55s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=4700, queue_size=28
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 18,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 258,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4737,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 65,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=4800, queue_size=128
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 73 local_trigger_step: 1 trigger_parameter_sync_step: 4 19:08:10.160
[36m(FullyAsyncTrainer pid=363373)[0m step:18 - rollouter/active_time:400.72079968452454 - rollouter/version_time:401.72489047050476 - rollouter/idle_ratio:0.0024994487765103157
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:08:10,163 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 78
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 78
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 18,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4848,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 67,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 112,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 74 local_trigger_step: 2 trigger_parameter_sync_step: 4 19:09:17.737
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:09:17,741 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 77
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.29 seconds.mq_len: 77
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 18,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4884,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 31,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 84,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 75 local_trigger_step: 3 trigger_parameter_sync_step: 4 19:10:31.144
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:10:31,147 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 24
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 24
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 18,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4889,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 26,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 25,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 76 local_trigger_step: 4 trigger_parameter_sync_step: 4 19:11:44.455
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006449222564697266
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  66%|█████████████████████████████████████████████████████████████████████████████▉                                         | 19/29 [2:04:46<1:02:59, 377.98s/it]
[36m(FullyAsyncTrainer pid=363373)[0m step:19 - fully_async/count/stale_samples_processed:920.0 - fully_async/count/stale_trajectory_processed:7360.0 - fully_async/count/current_param_version:18.0 - fully_async/processing_time/avg:38.852633982866564 - fully_async/processing_time/max:399.50743506196886 - fully_async/processing_time/min:0.9860872612334788 - fully_async/processing_time/tp50:29.127119156881236 - fully_async/processing_time/tp99:174.06389561405402 - fully_async/processing_time/tp95:117.7173465910251 - fully_async/monitor/active_tasks_size:105.75 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:80.0 - fully_async/count/total_generated_samples:4800.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:38.60883569717407 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:7.884584468494481 - rollout_corr/training_log_ppl:1.287924075405277 - rollout_corr/kl:0.25038581452529396 - rollout_corr/k3_kl:0.19770863543148015 - rollout_corr/rollout_ppl:3.973112235045213 - rollout_corr/rollout_log_ppl:0.9995675380865933 - rollout_corr/log_ppl_diff:0.28835653587735416 - rollout_corr/log_ppl_abs_diff:0.28835653587735416 - rollout_corr/log_ppl_diff_max:2.3968665599823 - rollout_corr/log_ppl_diff_min:0.00866769254207611 - rollout_corr/ppl_ratio:1.3725215662327526 - rollout_corr/chi2_token:0.8976968757082551 - rollout_corr/chi2_seq:-0.9996915421710352 - actor/kl_loss:0.0907235443546714 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.044486356631815965 - actor/ppo_kl:0.24944382529571252 - actor/pg_clipfrac_lower:0.00013465809732759998 - actor/pg_loss:0.19511143130060796 - actor/grad_norm:0.511747084538436 - perf/mfu/actor:0.05508566169676002 - perf/max_memory_allocated_gb:20.516846656799316 - perf/max_memory_reserved_gb:59.484375 - perf/cpu_memory_used_gb:81.40456008911133 - actor/lr:1e-06 - training/global_step:76.0 - training/epoch:0.0 - critic/score/mean:0.07640266418457031 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.07640266418457031 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.187433788087219 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.187433788087219 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:328.8310546875 - response_length/max:3072.0 - response_length/min:5.0 - response_length/clip_ratio:0.01318359375 - response_length_non_aborted/mean:328.8310546875 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:5.0 - response_length_non_aborted/clip_ratio:0.01318359375 - response/aborted_ratio:0.0 - prompt_length/mean:104.859375 - prompt_length/max:232.0 - prompt_length/min:70.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:41.36625242838636 - timing_s/reward:0.0010569761507213116 - timing_s/old_log_prob:0.001082544680684805 - timing_s/ref:108.03837358020246 - timing_s/adv:0.2656669528223574 - timing_s/update_actor:184.68585037905723 - timing_s/step:334.36421134276316 - timing_per_token_ms/gen:0.0063998432345048015 - timing_per_token_ms/update_actor:0.1664624680426375 - timing_per_token_ms/ref:0.09440062925374898 - timing_per_token_ms/adv:0.0001958667184021999 - perf/total_num_tokens:888198.0 - perf/time_per_step:334.36421134276316 - perf/throughput:1328.1893962770603 - trainer/idle_ratio:0.1237161485144145
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=4900, queue_size=36
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 18 to 19
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 67.48 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 18 to 19 ,reset staleness_samples to: 51,idle_ratio: 0.0027751698773931244
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.1047539710998535 seconds, while cache cost 5.7220458984375e-06 seconds,  register cost 0.0004999637603759766 seconds, update cost 0.17514705657958984 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:19 - timing_s/wait_last_valid:0.0029130959883332253 - timing_s/param_sync:68.58981157140806
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:12:53,066 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1053903102874756 seconds, while cache cost 0.71687912940979 seconds,  register cost 0.20958685874938965 seconds, update cost 0.17525839805603027 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 68.59 seconds, pause:67.48s, sync:1.11s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 19,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 180,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 4915,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 36.71 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=5000, queue_size=72
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 19,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 278,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5013,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 85,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=5100, queue_size=172
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 77 local_trigger_step: 1 trigger_parameter_sync_step: 4 19:14:52.423
[36m(FullyAsyncTrainer pid=363373)[0m step:19 - rollouter/active_time:401.9374511241913 - rollouter/version_time:403.05599999427795 - rollouter/idle_ratio:0.0027751698773931244
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:14:52,426 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 132
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 132
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 19,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5141,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 30,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 149,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 78 local_trigger_step: 2 trigger_parameter_sync_step: 4 19:15:58.199
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:15:58,202 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 96
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.29 seconds.mq_len: 96
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 19,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5156,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 15,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 100,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 79 local_trigger_step: 3 trigger_parameter_sync_step: 4 19:17:07.511
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:17:07,515 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 39
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 39
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.56s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 19,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5160,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 11,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 40,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 80 local_trigger_step: 4 trigger_parameter_sync_step: 4 19:18:17.519
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006303787231445312
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  69%|███████████████████████████████████████████████████████████████████████████████████▍                                     | 20/29 [2:11:19<57:22, 382.51s/it]
[36m(FullyAsyncRollouter pid=360588)[0m /home/ma-user/work/verl/verl/experimental/agent_loop/agent_loop.py:809: RuntimeWarning: coroutine 'FullyAsyncAgentLoopManager.wake_up' was never awaited
[36m(FullyAsyncRollouter pid=360588)[0m   self.wake_up()
[36m(FullyAsyncRollouter pid=360588)[0m /home/ma-user/work/verl/verl/experimental/agent_loop/agent_loop.py:822: RuntimeWarning: coroutine 'FullyAsyncAgentLoopManager.sleep' was never awaited
[36m(FullyAsyncRollouter pid=360588)[0m   self.sleep()
[36m(FullyAsyncTrainer pid=363373)[0m step:20 - fully_async/count/stale_samples_processed:971.0 - fully_async/count/stale_trajectory_processed:7768.0 - fully_async/count/current_param_version:19.0 - fully_async/processing_time/avg:37.41864415363648 - fully_async/processing_time/max:400.6534028039314 - fully_async/processing_time/min:1.8534750719554722 - fully_async/processing_time/tp50:28.472709530207794 - fully_async/processing_time/tp99:163.2684372230235 - fully_async/processing_time/tp95:107.98662781338778 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:80.0 - fully_async/count/total_generated_samples:5056.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:37.590734243392944 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:7.361822160416178 - rollout_corr/training_log_ppl:1.133056786771686 - rollout_corr/kl:0.19851953392120314 - rollout_corr/k3_kl:0.16391364883341353 - rollout_corr/rollout_ppl:3.8897472085105993 - rollout_corr/rollout_log_ppl:0.9182119479861169 - rollout_corr/log_ppl_diff:0.21484483702307833 - rollout_corr/log_ppl_abs_diff:0.21487141093682674 - rollout_corr/log_ppl_diff_max:2.037355422973633 - rollout_corr/log_ppl_diff_min:-0.01426023244857788 - rollout_corr/ppl_ratio:1.2717911173722574 - rollout_corr/chi2_token:3.1434475489271185 - rollout_corr/chi2_seq:-0.9609711968177368 - actor/kl_loss:0.10297125310079003 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.03844826741598866 - actor/ppo_kl:0.19755019044692054 - actor/pg_clipfrac_lower:0.00015063313424665438 - actor/pg_loss:0.20792068211904977 - actor/grad_norm:0.5303502270073859 - perf/mfu/actor:0.05247840933145782 - perf/max_memory_allocated_gb:20.516846656799316 - perf/max_memory_reserved_gb:59.484375 - perf/cpu_memory_used_gb:81.56021976470947 - actor/lr:1e-06 - training/global_step:80.0 - training/epoch:0.0 - critic/score/mean:0.08621692657470703 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.08621692657470703 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.2040009032934904 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.2040009032934904 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:298.99267578125 - response_length/max:3072.0 - response_length/min:14.0 - response_length/clip_ratio:0.0126953125 - response_length_non_aborted/mean:298.99267578125 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:14.0 - response_length_non_aborted/clip_ratio:0.0126953125 - response/aborted_ratio:0.0 - prompt_length/mean:104.67578125 - prompt_length/max:217.0 - prompt_length/min:69.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:40.43490596907213 - timing_s/reward:0.0008470639586448669 - timing_s/old_log_prob:0.001074736937880516 - timing_s/ref:104.16827194904909 - timing_s/adv:0.25344528863206506 - timing_s/update_actor:179.50114199891686 - timing_s/step:324.366296262946 - timing_per_token_ms/gen:0.007666822189014442 - timing_per_token_ms/update_actor:0.1717075522925001 - timing_per_token_ms/ref:0.0976748993917926 - timing_per_token_ms/adv:0.00022956230269028212 - perf/total_num_tokens:826713.0 - perf/time_per_step:324.366296262946 - perf/throughput:1274.3509568112297 - trainer/idle_ratio:0.12465816095854106
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(MessageQueue pid=367620)[0m Parameter version updated from 19 to 20
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 20.54 seconds
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.168046474456787 seconds, while cache cost 5.245208740234375e-06 seconds,  register cost 0.0005052089691162109 seconds, update cost 0.1811082363128662 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:20 - timing_s/wait_last_valid:0.0031663067638874054 - timing_s/param_sync:21.721413503866643
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1688084602355957 seconds, while cache cost 0.7868697643280029 seconds,  register cost 0.19707536697387695 seconds, update cost 0.18111062049865723 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 21.72 seconds, pause:20.54s, sync:1.17s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 19 to 20 ,reset staleness_samples to: 51,idle_ratio: 0.0034271945082179345
[36m(FullyAsyncRollouter pid=360588)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:18:39,266 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'green'}
[36m(FullyAsyncTrainer pid=363373)[0m 
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:18:39,265 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncRollouter pid=360588)[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': True, 'validate': True, 'global_steps': 5300}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncRollouter pid=360588)[0m validation generation end
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 20,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 51,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5171,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 415.18 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.56s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=5200, queue_size=16
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 20,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 266,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5257,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 73,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=5300, queue_size=116
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 81 local_trigger_step: 1 trigger_parameter_sync_step: 4 19:26:51.830
[36m(FullyAsyncTrainer pid=363373)[0m step:20 - val-aux/openai/gsm8k/reward/mean@1:0.05307050796057619 - val-core/openai/gsm8k/acc/mean@1:0.12964366944655042 - val-aux/num_turns/min:2 - val-aux/num_turns/max:2 - val-aux/num_turns/mean:2.0
[36m(FullyAsyncTrainer pid=363373)[0m ('[FullyAsyncTrainer] parameter version: 20 Validation metrics: '
[36m(FullyAsyncTrainer pid=363373)[0m  "{'val-aux/openai/gsm8k/reward/mean@1': 0.05307050796057619, "
[36m(FullyAsyncTrainer pid=363373)[0m  "'val-core/openai/gsm8k/acc/mean@1': 0.12964366944655042, "
[36m(FullyAsyncTrainer pid=363373)[0m  "'val-aux/num_turns/min': 2, 'val-aux/num_turns/max': 2, "
[36m(FullyAsyncTrainer pid=363373)[0m  "'val-aux/num_turns/mean': 2.0}")
[36m(FullyAsyncTrainer pid=363373)[0m step:20 - rollouter/active_time:345.00812339782715 - rollouter/version_time:346.1945996284485 - rollouter/idle_ratio:0.0034271945082179345 - rollouter/validate_time:378.18386703915894
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:26:51,835 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 106
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 106
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 20,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5382,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 45,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 134,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=5400, queue_size=152
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 82 local_trigger_step: 2 trigger_parameter_sync_step: 4 19:27:58.720
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:27:58,723 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 89
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.34 seconds.mq_len: 89
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 20,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5407,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 20,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 95,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 83 local_trigger_step: 3 trigger_parameter_sync_step: 4 19:29:07.875
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:29:07,878 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 32
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.31 seconds.mq_len: 32
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 20,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5411,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 16,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  72%|██████████████████████████████████████████████████████████████████████████████████████▏                                | 21/29 [2:23:19<1:04:30, 483.79s/it]
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 35,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 84 local_trigger_step: 4 trigger_parameter_sync_step: 4 19:30:17.441
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0007269382476806641
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m step:21 - fully_async/count/stale_samples_processed:1022.0 - fully_async/count/stale_trajectory_processed:8176.0 - fully_async/count/current_param_version:20.0 - fully_async/processing_time/avg:33.73148461535993 - fully_async/processing_time/max:343.96823178604245 - fully_async/processing_time/min:1.2204381078481674 - fully_async/processing_time/tp50:27.914661709277425 - fully_async/processing_time/tp99:144.06306248058794 - fully_async/processing_time/tp95:75.02867958534621 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:5312.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:416.12113904953003 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:10.388839790184882 - rollout_corr/training_log_ppl:1.1699820415975812 - rollout_corr/kl:0.20194924516264318 - rollout_corr/k3_kl:0.15726895658410198 - rollout_corr/rollout_ppl:3.6311304617084956 - rollout_corr/rollout_log_ppl:0.9316436935998125 - rollout_corr/log_ppl_diff:0.23833835131814352 - rollout_corr/log_ppl_abs_diff:0.23833835131814352 - rollout_corr/log_ppl_diff_max:5.946187973022461 - rollout_corr/log_ppl_diff_min:0.0033835172653198242 - rollout_corr/ppl_ratio:1.4813611696210496 - rollout_corr/chi2_token:0.3589405465266553 - rollout_corr/chi2_seq:-0.9986559208286436 - actor/kl_loss:0.11403731756711163 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.044004301489508804 - actor/ppo_kl:0.2010895691382556 - actor/pg_clipfrac_lower:5.502074822947462e-05 - actor/pg_loss:0.13796299999730194 - actor/grad_norm:0.5064919099539842 - perf/mfu/actor:0.050056935400629145 - perf/max_memory_allocated_gb:20.516846656799316 - perf/max_memory_reserved_gb:59.484375 - perf/cpu_memory_used_gb:81.81384181976318 - actor/lr:1e-06 - training/global_step:84.0 - training/epoch:0.0 - critic/score/mean:0.10417842864990234 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.10417842864990234 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.13669462781399488 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.13669462781399488 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:275.3076171875 - response_length/max:3072.0 - response_length/min:7.0 - response_length/clip_ratio:0.00537109375 - response_length_non_aborted/mean:275.3076171875 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:7.0 - response_length_non_aborted/clip_ratio:0.00537109375 - response/aborted_ratio:0.0 - prompt_length/mean:102.80078125 - prompt_length/max:190.0 - prompt_length/min:69.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:418.9518351396546 - timing_s/reward:0.001007244922220707 - timing_s/old_log_prob:0.0011506169103085995 - timing_s/ref:102.47866220027208 - timing_s/adv:0.2270067185163498 - timing_s/update_actor:176.42345297057182 - timing_s/step:698.0890993941575 - timing_per_token_ms/gen:0.007289830728674913 - timing_per_token_ms/update_actor:0.1998956063010708 - timing_per_token_ms/ref:0.11194270037887998 - timing_per_token_ms/adv:0.0002453041629011424 - perf/total_num_tokens:774366.0 - perf/time_per_step:698.0890993941575 - perf/throughput:554.6326397819705 - trainer/idle_ratio:0.600140921127755
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 20 to 21
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 72.79 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 20 to 21 ,reset staleness_samples to: 51,idle_ratio: 0.0027859296000394274
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.0829086303710938 seconds, while cache cost 7.152557373046875e-06 seconds,  register cost 0.0005023479461669922 seconds, update cost 0.17846441268920898 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:21 - timing_s/wait_last_valid:0.0037034801207482815 - timing_s/param_sync:73.88240975001827
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:31:31,349 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.0835812091827393 seconds, while cache cost 0.7010393142700195 seconds,  register cost 0.20032167434692383 seconds, update cost 0.17855334281921387 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 73.88 seconds, pause:72.79s, sync:1.09s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 21,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 180,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5427,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 34.92 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=5500, queue_size=60
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 21,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 295,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5542,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 102,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=5600, queue_size=160
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 85 local_trigger_step: 1 trigger_parameter_sync_step: 4 19:33:29.141
[36m(FullyAsyncTrainer pid=363373)[0m step:21 - rollouter/active_time:392.7941267490387 - rollouter/version_time:393.8914806842804 - rollouter/idle_ratio:0.0027859296000394274
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:33:29,144 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 146
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 146
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.56s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 21,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5667,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 16,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 163,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 86 local_trigger_step: 2 trigger_parameter_sync_step: 4 19:34:35.059
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:34:35,062 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 106
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 106
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 21,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5676,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 7,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 108,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 87 local_trigger_step: 3 trigger_parameter_sync_step: 4 19:35:43.819
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:35:43,822 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 44
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.28 seconds.mq_len: 44
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 88 local_trigger_step: 4 trigger_parameter_sync_step: 4 19:36:53.540
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006275177001953125
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  76%|███████████████████████████████████████████████████████████████████████████████████████████▊                             | 22/29 [2:29:55<53:22, 457.47s/it]
[36m(FullyAsyncTrainer pid=363373)[0m step:22 - fully_async/count/stale_samples_processed:1073.0 - fully_async/count/stale_trajectory_processed:8584.0 - fully_async/count/current_param_version:21.0 - fully_async/processing_time/avg:34.45334730929903 - fully_async/processing_time/max:391.8257637047209 - fully_async/processing_time/min:0.8705196320079267 - fully_async/processing_time/tp50:28.15301916532917 - fully_async/processing_time/tp99:151.950114807902 - fully_async/processing_time/tp95:81.4536800681031 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:80.0 - fully_async/count/total_generated_samples:5568.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:35.787604570388794 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:11.271447916015964 - rollout_corr/training_log_ppl:1.021751223156684 - rollout_corr/kl:0.14373259791142606 - rollout_corr/k3_kl:0.118347794303866 - rollout_corr/rollout_ppl:3.9504822673679194 - rollout_corr/rollout_log_ppl:0.8672385600425706 - rollout_corr/log_ppl_diff:0.1545126648531336 - rollout_corr/log_ppl_abs_diff:0.1545619171280802 - rollout_corr/log_ppl_diff_max:2.032224178314209 - rollout_corr/log_ppl_diff_min:-0.01127094030380249 - rollout_corr/ppl_ratio:1.1902198301362468 - rollout_corr/chi2_token:3.4634961509176465 - rollout_corr/chi2_seq:-0.962336306698976 - actor/kl_loss:0.12439559726254712 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.03008806315827664 - actor/ppo_kl:0.14291227017322003 - actor/pg_clipfrac_lower:8.14350602133526e-05 - actor/pg_loss:0.16120370349785534 - actor/grad_norm:0.572083996407954 - perf/mfu/actor:0.04852853305257797 - perf/max_memory_allocated_gb:20.516846656799316 - perf/max_memory_reserved_gb:59.484375 - perf/cpu_memory_used_gb:81.91180610656738 - actor/lr:1e-06 - training/global_step:88.0 - training/epoch:0.0 - critic/score/mean:0.0964059829711914 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.0964059829711914 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.16149637708440423 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.16149637708440423 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:273.015625 - response_length/max:3072.0 - response_length/min:6.0 - response_length/clip_ratio:0.00830078125 - response_length_non_aborted/mean:273.015625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:6.0 - response_length_non_aborted/clip_ratio:0.00830078125 - response/aborted_ratio:0.0 - prompt_length/mean:104.140625 - prompt_length/max:184.0 - prompt_length/min:68.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:38.57066529849544 - timing_s/reward:0.0010211351327598095 - timing_s/old_log_prob:0.001040124800056219 - timing_s/ref:102.57188868289813 - timing_s/adv:0.22993040876463056 - timing_s/update_actor:180.72835015505552 - timing_s/step:322.10852666711435 - timing_per_token_ms/gen:0.007584861925728789 - timing_per_token_ms/update_actor:0.20171768941387624 - timing_per_token_ms/ref:0.10567074812654773 - timing_per_token_ms/adv:0.0002089302285444267 - perf/total_num_tokens:772416.0 - perf/time_per_step:322.10852666711435 - perf/throughput:1198.9996166699734 - trainer/idle_ratio:0.11974431629485116
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 21,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5677,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 6,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 45,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 21 to 22
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 12.98 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 21 to 22 ,reset staleness_samples to: 51,idle_ratio: 0.003394570990444934
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.1287462711334229 seconds, while cache cost 7.152557373046875e-06 seconds,  register cost 0.0004849433898925781 seconds, update cost 0.16519927978515625 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:22 - timing_s/wait_last_valid:0.003079076297581196 - timing_s/param_sync:14.11949728615582
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:37:07,682 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1295139789581299 seconds, while cache cost 0.7575411796569824 seconds,  register cost 0.20299100875854492 seconds, update cost 0.16527724266052246 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 14.12 seconds, pause:12.98s, sync:1.13s
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 33.62 seconds.mq_len: 0
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=5700, queue_size=4
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 22,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 242,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5745,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 50,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=5800, queue_size=104
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=5900, queue_size=204
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 89 local_trigger_step: 1 trigger_parameter_sync_step: 4 19:38:56.012
[36m(FullyAsyncTrainer pid=363373)[0m step:22 - rollouter/active_time:335.18561911582947 - rollouter/version_time:336.3273060321808 - rollouter/idle_ratio:0.003394570990444934
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:38:56,015 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 169
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.29 seconds.mq_len: 169
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.55s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 22,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5930,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 9,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 170,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 90 local_trigger_step: 2 trigger_parameter_sync_step: 4 19:40:03.022
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:40:03,025 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 115
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 115
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.55s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 22,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5939,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 115,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 22,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5939,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 115,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 91 local_trigger_step: 3 trigger_parameter_sync_step: 4 19:41:12.977
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:41:12,980 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 51
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.38 seconds.mq_len: 51
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 22,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5939,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 51,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  79%|███████████████████████████████████████████████████████████████████████████████████████████████▉                         | 23/29 [2:35:25<41:54, 419.06s/it]
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 92 local_trigger_step: 4 trigger_parameter_sync_step: 4 19:42:23.001
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.000629425048828125
[36m(FullyAsyncTrainer pid=363373)[0m step:23 - fully_async/count/stale_samples_processed:1124.0 - fully_async/count/stale_trajectory_processed:8992.0 - fully_async/count/current_param_version:22.0 - fully_async/processing_time/avg:31.845300918527073 - fully_async/processing_time/max:334.2117798710242 - fully_async/processing_time/min:1.5556277157738805 - fully_async/processing_time/tp50:28.022534983989317 - fully_async/processing_time/tp99:123.12743558485872 - fully_async/processing_time/tp95:60.17808324486832 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:95.75 - fully_async/count/total_generated_samples:5824.0 - fully_async/count/staleness_samples:265.5 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:34.615575313568115 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:3.693849764537677 - rollout_corr/training_log_ppl:0.7731663736062379 - rollout_corr/kl:0.0494703056539249 - rollout_corr/k3_kl:0.040696211446306654 - rollout_corr/rollout_ppl:3.1982243624945434 - rollout_corr/rollout_log_ppl:0.7238311372866333 - rollout_corr/log_ppl_diff:0.04933523588509617 - rollout_corr/log_ppl_abs_diff:0.05008657442631132 - rollout_corr/log_ppl_diff_max:1.4838523864746094 - rollout_corr/log_ppl_diff_min:-0.0315910279750824 - rollout_corr/ppl_ratio:1.055824787653456 - rollout_corr/chi2_token:0.43475620342819565 - rollout_corr/chi2_seq:15.990014503204419 - actor/kl_loss:0.1288531844389033 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.013389087201156795 - actor/ppo_kl:0.04918483910042947 - actor/pg_clipfrac_lower:3.208893859349058e-05 - actor/pg_loss:0.08926856282216397 - actor/grad_norm:0.671770678663038 - perf/mfu/actor:0.045429039293075464 - perf/max_memory_allocated_gb:20.516846656799316 - perf/max_memory_reserved_gb:59.484375 - perf/cpu_memory_used_gb:81.84230899810791 - actor/lr:1e-06 - training/global_step:92.0 - training/epoch:0.0 - critic/score/mean:0.1982421875 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.1982421875 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.09334252940607257 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.09334252940607257 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:237.916015625 - response_length/max:3072.0 - response_length/min:11.0 - response_length/clip_ratio:0.00390625 - response_length_non_aborted/mean:237.916015625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:11.0 - response_length_non_aborted/clip_ratio:0.00390625 - response/aborted_ratio:0.0 - prompt_length/mean:104.30078125 - prompt_length/max:194.0 - prompt_length/min:68.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:37.40493817906827 - timing_s/reward:0.0008476534858345985 - timing_s/old_log_prob:0.0009855260141193867 - timing_s/ref:102.4517965731211 - timing_s/adv:0.24918635748326778 - timing_s/update_actor:175.1137478016317 - timing_s/step:315.2274625841528 - timing_per_token_ms/gen:0.009236659969257861 - timing_per_token_ms/update_actor:0.2223057339443961 - timing_per_token_ms/ref:0.12541897767452662 - timing_per_token_ms/adv:0.0002947102740686462 - perf/total_num_tokens:700860.0 - perf/time_per_step:315.2274625841528 - perf/throughput:1111.6734472538208 - trainer/idle_ratio:0.11866015058596832
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(MessageQueue pid=367620)[0m Parameter version updated from 22 to 23
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 0.02 seconds
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 22 to 23 ,reset staleness_samples to: 51,idle_ratio: 0.5259978718609359
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.1305272579193115 seconds, while cache cost 6.4373016357421875e-06 seconds,  register cost 0.0005767345428466797 seconds, update cost 0.18113970756530762 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:23 - timing_s/wait_last_valid:0.003075846005231142 - timing_s/param_sync:1.1660580500029027
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:42:24,188 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1317927837371826 seconds, while cache cost 0.748772144317627 seconds,  register cost 0.1981217861175537 seconds, update cost 0.18110942840576172 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 1.16 seconds, pause:0.03s, sync:1.14s
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 32.35 seconds.mq_len: 0
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 23,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 230,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 5989,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 37,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=6000, queue_size=48
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=6100, queue_size=148
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 93 local_trigger_step: 1 trigger_parameter_sync_step: 4 19:44:06.141
[36m(FullyAsyncTrainer pid=363373)[0m step:23 - rollouter/active_time:150.0226993560791 - rollouter/version_time:316.5021641254425 - rollouter/idle_ratio:0.5259978718609359
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:44:06,145 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 133
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 133
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 23,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 6160,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 35,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 144,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 94 local_trigger_step: 2 trigger_parameter_sync_step: 4 19:45:12.299
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:45:12,302 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 106
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 106
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.55s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 23,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 6187,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 8,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 107,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 95 local_trigger_step: 3 trigger_parameter_sync_step: 4 19:46:19.970
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:46:19,973 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 45
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.29 seconds.mq_len: 45
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 96 local_trigger_step: 4 trigger_parameter_sync_step: 4 19:47:30.411
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006797313690185547
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  83%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                    | 24/29 [2:40:32<32:07, 385.57s/it]
[36m(FullyAsyncTrainer pid=363373)[0m step:24 - fully_async/count/stale_samples_processed:1175.0 - fully_async/count/stale_trajectory_processed:9400.0 - fully_async/count/current_param_version:23.0 - fully_async/processing_time/avg:28.734029781475783 - fully_async/processing_time/max:149.08876903587952 - fully_async/processing_time/min:2.017555112950504 - fully_async/processing_time/tp50:25.92745139822364 - fully_async/processing_time/tp99:77.46087511365882 - fully_async/processing_time/tp95:54.93770848293205 - fully_async/monitor/active_tasks_size:105.75 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:95.75 - fully_async/count/total_generated_samples:6080.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:33.23582315444946 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:3.02812801864626 - rollout_corr/training_log_ppl:0.7999025912545811 - rollout_corr/kl:0.06538288295211317 - rollout_corr/k3_kl:0.053868372160130615 - rollout_corr/rollout_ppl:2.7463140333311467 - rollout_corr/rollout_log_ppl:0.7273202311123098 - rollout_corr/log_ppl_diff:0.07258235900871923 - rollout_corr/log_ppl_abs_diff:0.0730683768320588 - rollout_corr/log_ppl_diff_max:2.3924784660339355 - rollout_corr/log_ppl_diff_min:-0.02511155605316162 - rollout_corr/ppl_ratio:1.084400335582283 - rollout_corr/chi2_token:0.458113243416165 - rollout_corr/chi2_seq:-0.5422927019711146 - actor/kl_loss:0.14760596044704064 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.017020009864812863 - actor/ppo_kl:0.06487350951853521 - actor/pg_clipfrac_lower:9.506661113998388e-06 - actor/pg_loss:0.019692300861762244 - actor/grad_norm:0.5680568381694179 - perf/mfu/actor:0.04333536950353526 - perf/max_memory_allocated_gb:20.516846656799316 - perf/max_memory_reserved_gb:59.484375 - perf/cpu_memory_used_gb:81.86835479736328 - actor/lr:1e-06 - training/global_step:96.0 - training/epoch:0.0 - critic/score/mean:0.1494140625 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.1494140625 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-0.017684705439023674 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.017684705439023674 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:217.8466796875 - response_length/max:1579.0 - response_length/min:10.0 - response_length/clip_ratio:0.0 - response_length_non_aborted/mean:217.8466796875 - response_length_non_aborted/max:1579.0 - response_length_non_aborted/min:10.0 - response_length_non_aborted/clip_ratio:0.0 - response/aborted_ratio:0.0 - prompt_length/mean:100.859375 - prompt_length/max:193.0 - prompt_length/min:68.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:36.01064356835559 - timing_s/reward:0.000896054320037365 - timing_s/old_log_prob:0.0010402253828942776 - timing_s/ref:99.59615995176136 - timing_s/adv:0.2497288715094328 - timing_s/update_actor:170.26459727995098 - timing_s/step:306.12900842539966 - timing_per_token_ms/gen:0.008001536965916748 - timing_per_token_ms/update_actor:0.2479429841325055 - timing_per_token_ms/ref:0.14529253820699012 - timing_per_token_ms/adv:0.00032517565912253116 - perf/total_num_tokens:652710.0 - perf/time_per_step:306.12900842539966 - perf/throughput:1066.0701567572262 - trainer/idle_ratio:0.11763224842225625
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 23 to 24
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 5.84 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 23 to 24 ,reset staleness_samples to: 51,idle_ratio: 0.0034921438945777483
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.0805060863494873 seconds, while cache cost 5.4836273193359375e-06 seconds,  register cost 0.0004937648773193359 seconds, update cost 0.17754530906677246 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:24 - timing_s/wait_last_valid:0.002919325139373541 - timing_s/param_sync:6.930234340019524
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:47:37,399 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.0813581943511963 seconds, while cache cost 0.6897127628326416 seconds,  register cost 0.2103288173675537 seconds, update cost 0.1775674819946289 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 6.93 seconds, pause:5.84s, sync:1.09s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 24,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 180,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 6195,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=6200, queue_size=1
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 33.89 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.55s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=6300, queue_size=92
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 24,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 306,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 6321,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 113,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=6400, queue_size=192
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 97 local_trigger_step: 1 trigger_parameter_sync_step: 4 19:49:24.092
[36m(FullyAsyncTrainer pid=363373)[0m step:24 - rollouter/active_time:312.1100823879242 - rollouter/version_time:313.20383524894714 - rollouter/idle_ratio:0.0034921438945777483
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:49:24,095 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 131
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.28 seconds.mq_len: 131
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 24,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 6445,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 6,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 173,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 98 local_trigger_step: 2 trigger_parameter_sync_step: 4 19:50:31.194
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:50:31,198 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 113
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.29 seconds.mq_len: 113
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.57s
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 99 local_trigger_step: 3 trigger_parameter_sync_step: 4 19:51:38.026
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:51:38,029 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 49
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 49
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 1.16s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 24,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 6450,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 1,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 50,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 100 local_trigger_step: 4 trigger_parameter_sync_step: 4 19:52:45.775
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006356239318847656
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  86%|████████████████████████████████████████████████████████████████████████████████████████████████████████▎                | 25/29 [2:45:48<24:17, 364.49s/it]
[36m(FullyAsyncTrainer pid=363373)[0m step:25 - fully_async/count/stale_samples_processed:1226.0 - fully_async/count/stale_trajectory_processed:9808.0 - fully_async/count/current_param_version:24.0 - fully_async/processing_time/avg:30.71398410348047 - fully_async/processing_time/max:310.5411215098575 - fully_async/processing_time/min:2.9133373899385333 - fully_async/processing_time/tp50:26.777330302575137 - fully_async/processing_time/tp99:117.44482805597589 - fully_async/processing_time/tp95:57.751031421619686 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:95.75 - fully_async/count/total_generated_samples:6336.0 - fully_async/count/staleness_samples:265.75 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:34.765920877456665 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:4.803006409165122 - rollout_corr/training_log_ppl:0.8642665685560621 - rollout_corr/kl:0.08589835322416611 - rollout_corr/k3_kl:0.07051478745365972 - rollout_corr/rollout_ppl:3.2092581428749853 - rollout_corr/rollout_log_ppl:0.7695402850165427 - rollout_corr/log_ppl_diff:0.09472628322284074 - rollout_corr/log_ppl_abs_diff:0.0950375885697389 - rollout_corr/log_ppl_diff_max:2.089918613433838 - rollout_corr/log_ppl_diff_min:-0.11447912454605103 - rollout_corr/ppl_ratio:1.1087463135956699 - rollout_corr/chi2_token:0.3687736677170238 - rollout_corr/chi2_seq:-0.8221017783629305 - actor/kl_loss:0.1442117332666195 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.019046365143615296 - actor/ppo_kl:0.08518172216768892 - actor/pg_clipfrac_lower:1.3646040970734344e-05 - actor/pg_loss:0.08370856723881959 - actor/grad_norm:0.5739405185410587 - perf/mfu/actor:0.04685278717826887 - perf/max_memory_allocated_gb:20.516846656799316 - perf/max_memory_reserved_gb:59.484375 - perf/cpu_memory_used_gb:81.87968254089355 - actor/lr:1e-06 - training/global_step:100.0 - training/epoch:0.0 - critic/score/mean:0.13504409790039062 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.13504409790039062 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.08694161847233772 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.08694161847233772 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:237.69140625 - response_length/max:3072.0 - response_length/min:16.0 - response_length/clip_ratio:0.0029296875 - response_length_non_aborted/mean:237.69140625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:16.0 - response_length_non_aborted/clip_ratio:0.0029296875 - response/aborted_ratio:0.0 - prompt_length/mean:104.1171875 - prompt_length/max:212.0 - prompt_length/min:68.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:38.29457439156249 - timing_s/reward:0.0009707054123282433 - timing_s/old_log_prob:0.0011058272793889046 - timing_s/ref:100.19521086011082 - timing_s/adv:0.25803640065714717 - timing_s/update_actor:169.52415405632928 - timing_s/step:308.2799260909669 - timing_per_token_ms/gen:0.009443940168122519 - timing_per_token_ms/update_actor:0.21390215943617003 - timing_per_token_ms/ref:0.12476009359407417 - timing_per_token_ms/adv:0.0002835216158001414 - perf/total_num_tokens:700024.0 - perf/time_per_step:308.2799260909669 - perf/throughput:1135.370714656 - trainer/idle_ratio:0.12422013615074817
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 24 to 25
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 70.56 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 24 to 25 ,reset staleness_samples to: 51,idle_ratio: 0.0026442168809104327
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:0.9919915199279785 seconds, while cache cost 5.7220458984375e-06 seconds,  register cost 0.0004878044128417969 seconds, update cost 0.16733622550964355 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:25 - timing_s/wait_last_valid:0.0026456639170646667 - timing_s/param_sync:71.5637283148244
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:53:57,360 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:0.9922068119049072 seconds, while cache cost 0.7295405864715576 seconds,  register cost 0.09176063537597656 seconds, update cost 0.16743779182434082 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 71.56 seconds, pause:70.56s, sync:1.00s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 25,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 180,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 6451,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 30.89 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.55s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=6500, queue_size=36
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 25,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 6586,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 121,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 122,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=6600, queue_size=136
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 101 local_trigger_step: 1 trigger_parameter_sync_step: 4 19:55:41.623
[36m(FullyAsyncTrainer pid=363373)[0m step:25 - rollouter/active_time:378.951961517334 - rollouter/version_time:379.9566493034363 - rollouter/idle_ratio:0.0026442168809104327
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:55:41,627 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 153
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 153
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 25,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 6699,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 8,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 171,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 102 local_trigger_step: 2 trigger_parameter_sync_step: 4 19:56:46.429
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:56:46,432 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 107
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.28 seconds.mq_len: 107
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.56s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=6700, queue_size=108
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 25,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 6702,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 5,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 110,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 103 local_trigger_step: 3 trigger_parameter_sync_step: 4 19:57:51.293
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:57:51,296 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 46
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 46
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.60s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 104 local_trigger_step: 4 trigger_parameter_sync_step: 4 19:58:59.701
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006761550903320312
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 26/29 [2:52:01<18:21, 367.32s/it]
[36m(FullyAsyncTrainer pid=363373)[0m step:26 - fully_async/count/stale_samples_processed:1277.0 - fully_async/count/stale_trajectory_processed:10216.0 - fully_async/count/current_param_version:25.0 - fully_async/processing_time/avg:31.12830885980111 - fully_async/processing_time/max:377.70447149593383 - fully_async/processing_time/min:3.4899205057881773 - fully_async/processing_time/tp50:27.393882653850596 - fully_async/processing_time/tp99:80.87687215980023 - fully_async/processing_time/tp95:59.24086168028879 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:6592.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:31.766963720321655 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:3.209089820846417 - rollout_corr/training_log_ppl:0.7925752929131555 - rollout_corr/kl:0.06538311555236433 - rollout_corr/k3_kl:0.05235933513047155 - rollout_corr/rollout_ppl:2.606271334588061 - rollout_corr/rollout_log_ppl:0.7240737262841747 - rollout_corr/log_ppl_diff:0.06850155576786937 - rollout_corr/log_ppl_abs_diff:0.06881125274715486 - rollout_corr/log_ppl_diff_max:2.5129103660583496 - rollout_corr/log_ppl_diff_min:-0.015379711985588074 - rollout_corr/ppl_ratio:1.0801224787957975 - rollout_corr/chi2_token:0.06133309990934475 - rollout_corr/chi2_seq:-0.6914193460502727 - actor/kl_loss:0.14815536597490606 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.015683908386914292 - actor/ppo_kl:0.06481089672999327 - actor/pg_clipfrac_lower:3.9960536449717564e-05 - actor/pg_loss:0.05075359662245977 - actor/grad_norm:0.5724240705701222 - perf/mfu/actor:0.045431790576262655 - perf/max_memory_allocated_gb:20.516846656799316 - perf/max_memory_reserved_gb:59.484375 - perf/cpu_memory_used_gb:82.0091781616211 - actor/lr:1e-06 - training/global_step:104.0 - training/epoch:0.0 - critic/score/mean:0.22119140625 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.22119140625 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.0511843697167933 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.0511843697167933 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:231.4365234375 - response_length/max:3072.0 - response_length/min:14.0 - response_length/clip_ratio:0.0009765625 - response_length_non_aborted/mean:231.4365234375 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:14.0 - response_length_non_aborted/clip_ratio:0.0009765625 - response/aborted_ratio:0.0 - prompt_length/mean:99.76953125 - prompt_length/max:186.0 - prompt_length/min:62.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:34.68843401083723 - timing_s/reward:0.0009101857431232929 - timing_s/old_log_prob:0.0010400647297501564 - timing_s/ref:98.59662991808727 - timing_s/adv:0.24089004378765821 - timing_s/update_actor:168.70544444862753 - timing_s/step:302.2393619827926 - timing_per_token_ms/gen:0.009084441267972736 - timing_per_token_ms/update_actor:0.2276735265339862 - timing_per_token_ms/ref:0.12948048121099204 - timing_per_token_ms/adv:0.00028859196493523305 - perf/total_num_tokens:678310.0 - perf/time_per_step:302.2393619827926 - perf/throughput:1122.1404047938306 - trainer/idle_ratio:0.11477139768714885
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 25 to 26
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 16.99 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 25 to 26 ,reset staleness_samples to: 51,idle_ratio: 0.0034005204688081214
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.0770533084869385 seconds, while cache cost 5.7220458984375e-06 seconds,  register cost 0.0004975795745849609 seconds, update cost 0.17890167236328125 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:26 - timing_s/wait_last_valid:0.00313774636015296 - timing_s/param_sync:18.076276277191937
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 19:59:17,799 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.077505111694336 seconds, while cache cost 0.6962370872497559 seconds,  register cost 0.19854354858398438 seconds, update cost 0.17891764640808105 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 18.07 seconds, pause:16.99s, sync:1.08s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 26,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 180,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 6707,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 31.75 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=6800, queue_size=80
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 26,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 283,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 6810,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 90,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=6900, queue_size=180
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 105 local_trigger_step: 1 trigger_parameter_sync_step: 4 20:01:01.435
[36m(FullyAsyncTrainer pid=363373)[0m step:26 - rollouter/active_time:319.34489035606384 - rollouter/version_time:320.43453454971313 - rollouter/idle_ratio:0.0034005204688081214
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 20:01:01,439 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 128
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.31 seconds.mq_len: 128
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 26,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 6947,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 16,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 163,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 106 local_trigger_step: 2 trigger_parameter_sync_step: 4 20:02:07.804
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 20:02:07,807 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 110
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.33 seconds.mq_len: 110
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.56s
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 107 local_trigger_step: 3 trigger_parameter_sync_step: 4 20:03:15.207
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 20:03:15,211 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 46
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.31 seconds.mq_len: 46
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 108 local_trigger_step: 4 trigger_parameter_sync_step: 4 20:04:23.335
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006458759307861328
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋        | 27/29 [2:57:25<11:48, 354.21s/it]
[36m(FullyAsyncTrainer pid=363373)[0m step:27 - fully_async/count/stale_samples_processed:1328.0 - fully_async/count/stale_trajectory_processed:10624.0 - fully_async/count/current_param_version:26.0 - fully_async/processing_time/avg:31.281819781504737 - fully_async/processing_time/max:318.5033216350712 - fully_async/processing_time/min:1.561525063123554 - fully_async/processing_time/tp50:27.734579399228096 - fully_async/processing_time/tp99:101.60390493239139 - fully_async/processing_time/tp95:57.34840077151894 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:6848.0 - fully_async/count/staleness_samples:266.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:32.705971240997314 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:3.7267234289907103 - rollout_corr/training_log_ppl:0.8721243029005391 - rollout_corr/kl:0.09589774097345326 - rollout_corr/k3_kl:0.0802345650256015 - rollout_corr/rollout_ppl:2.7328640111992435 - rollout_corr/rollout_log_ppl:0.7615073509473631 - rollout_corr/log_ppl_diff:0.11061694993552038 - rollout_corr/log_ppl_abs_diff:0.11077683071225475 - rollout_corr/log_ppl_diff_max:2.202803611755371 - rollout_corr/log_ppl_diff_min:-0.01127249002456665 - rollout_corr/ppl_ratio:1.1293813703269697 - rollout_corr/chi2_token:3.549513666917795 - rollout_corr/chi2_seq:-0.857892010818356 - actor/kl_loss:0.15469564823636225 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.01468879141140103 - actor/ppo_kl:0.09526514523270367 - actor/pg_clipfrac_lower:2.246706177369722e-05 - actor/pg_loss:0.06433767863844048 - actor/grad_norm:0.48135271040309613 - perf/mfu/actor:0.046155777705630265 - perf/max_memory_allocated_gb:20.516846656799316 - perf/max_memory_reserved_gb:59.615234375 - perf/cpu_memory_used_gb:81.82902717590332 - actor/lr:1e-06 - training/global_step:108.0 - training/epoch:0.0 - critic/score/mean:0.11865234375 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.11865234375 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.06790449842810631 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.06790449842810631 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:234.99365234375 - response_length/max:3072.0 - response_length/min:11.0 - response_length/clip_ratio:0.00244140625 - response_length_non_aborted/mean:234.99365234375 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:11.0 - response_length_non_aborted/clip_ratio:0.00244140625 - response/aborted_ratio:0.0 - prompt_length/mean:103.90234375 - prompt_length/max:189.0 - prompt_length/min:72.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:35.51486055087298 - timing_s/reward:0.0008417540229856968 - timing_s/old_log_prob:0.001045225653797388 - timing_s/ref:99.29030321026221 - timing_s/adv:0.23187124263495207 - timing_s/update_actor:170.40148680703714 - timing_s/step:305.4462917316705 - timing_per_token_ms/gen:0.008263003184691475 - timing_per_token_ms/update_actor:0.2304215727149357 - timing_per_token_ms/ref:0.12935257011478632 - timing_per_token_ms/adv:0.00029077279589726033 - perf/total_num_tokens:694059.0 - perf/time_per_step:305.4462917316705 - perf/throughput:1136.1391818921136 - trainer/idle_ratio:0.11627203050830356
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 26 to 27
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 47.55 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 26 to 27 ,reset staleness_samples to: 51,idle_ratio: 0.0032897231565578444
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.1522116661071777 seconds, while cache cost 5.9604644775390625e-06 seconds,  register cost 0.0004923343658447266 seconds, update cost 0.18040776252746582 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:27 - timing_s/wait_last_valid:0.0026382743380963802 - timing_s/param_sync:48.711817923001945
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 20:05:12,065 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1529028415679932 seconds, while cache cost 0.7534682750701904 seconds,  register cost 0.2141578197479248 seconds, update cost 0.18034577369689941 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 48.71 seconds, pause:47.55s, sync:1.16s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 27,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 180,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 6963,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 33.87 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=7000, queue_size=24
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 27,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 300,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 7083,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 107,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=7100, queue_size=124
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 109 local_trigger_step: 1 trigger_parameter_sync_step: 4 20:06:59.298
[36m(FullyAsyncTrainer pid=363373)[0m step:27 - rollouter/active_time:353.0974323749542 - rollouter/version_time:354.26285910606384 - rollouter/idle_ratio:0.0032897231565578444
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 20:06:59,302 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 143
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.29 seconds.mq_len: 143
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=7200, queue_size=160
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 27,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 7213,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 6,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 173,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 110 local_trigger_step: 2 trigger_parameter_sync_step: 4 20:08:05.357
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 20:08:05,360 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 111
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 111
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 111 local_trigger_step: 3 trigger_parameter_sync_step: 4 20:09:11.476
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 20:09:11,479 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 47
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.34 seconds.mq_len: 47
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.56s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 27,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 7216,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 3,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 48,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 112 local_trigger_step: 4 trigger_parameter_sync_step: 4 20:10:20.038
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.0006315708160400391
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress:  97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 28/29 [3:03:22<05:54, 354.96s/it]
[36m(FullyAsyncTrainer pid=363373)[0m step:28 - fully_async/count/stale_samples_processed:1379.0 - fully_async/count/stale_trajectory_processed:11032.0 - fully_async/count/current_param_version:27.0 - fully_async/processing_time/avg:30.988109450705224 - fully_async/processing_time/max:352.0974198798649 - fully_async/processing_time/min:1.0918139000423253 - fully_async/processing_time/tp50:27.20712920866208 - fully_async/processing_time/tp99:94.02986757699631 - fully_async/processing_time/tp95:58.90237768134685 - fully_async/monitor/active_tasks_size:105.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:79.75 - fully_async/count/total_generated_samples:7104.0 - fully_async/count/staleness_samples:265.75 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:34.799537658691406 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:7.6202995143379235 - rollout_corr/training_log_ppl:0.9347195909894777 - rollout_corr/kl:0.13625212221540456 - rollout_corr/k3_kl:0.10902785077818077 - rollout_corr/rollout_ppl:3.8849171056891936 - rollout_corr/rollout_log_ppl:0.7919105998776628 - rollout_corr/log_ppl_diff:0.1428089933385226 - rollout_corr/log_ppl_abs_diff:0.14286284788342363 - rollout_corr/log_ppl_diff_max:1.9664483070373535 - rollout_corr/log_ppl_diff_min:-0.012851983308792114 - rollout_corr/ppl_ratio:1.1683671175530463 - rollout_corr/chi2_token:0.13439527007214952 - rollout_corr/chi2_seq:-0.950338018369494 - actor/kl_loss:0.16375729882539333 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.027910222609661462 - actor/ppo_kl:0.13535027895510818 - actor/pg_clipfrac_lower:9.625241230727018e-05 - actor/pg_loss:0.0750427632329802 - actor/grad_norm:0.5747210171754312 - perf/mfu/actor:0.045956794866483505 - perf/max_memory_allocated_gb:20.516846656799316 - perf/max_memory_reserved_gb:59.615234375 - perf/cpu_memory_used_gb:81.9547176361084 - actor/lr:1e-06 - training/global_step:112.0 - training/epoch:0.0 - critic/score/mean:0.13818359375 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.13818359375 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.0763543559005484 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.0763543559005484 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:234.00634765625 - response_length/max:3072.0 - response_length/min:4.0 - response_length/clip_ratio:0.00244140625 - response_length_non_aborted/mean:234.00634765625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:4.0 - response_length_non_aborted/clip_ratio:0.00244140625 - response/aborted_ratio:0.0 - prompt_length/mean:101.328125 - prompt_length/max:183.0 - prompt_length/min:68.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:37.62751686014235 - timing_s/reward:0.0008179540745913982 - timing_s/old_log_prob:0.0010126857087016106 - timing_s/ref:100.54367653559893 - timing_s/adv:0.24361408362165093 - timing_s/update_actor:169.4589647501707 - timing_s/step:307.8813903997652 - timing_per_token_ms/gen:0.008914199804815075 - timing_per_token_ms/update_actor:0.22805686525345273 - timing_per_token_ms/ref:0.13026600641691558 - timing_per_token_ms/adv:0.0003388258647906491 - perf/total_num_tokens:686765.0 - perf/time_per_step:307.8813903997652 - perf/throughput:1115.3077474222744 - trainer/idle_ratio:0.12221432679411157
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 27 to 28
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 77.01 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 27 to 28 ,reset staleness_samples to: 51,idle_ratio: 0.0027179634523883944
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.0337786674499512 seconds, while cache cost 5.9604644775390625e-06 seconds,  register cost 0.00048065185546875 seconds, update cost 0.182051420211792 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:28 - timing_s/wait_last_valid:0.002700554206967354 - timing_s/param_sync:78.0563071127981
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 20:11:38,119 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.0339910984039307 seconds, while cache cost 0.7346885204315186 seconds,  register cost 0.11321735382080078 seconds, update cost 0.18184828758239746 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 78.05 seconds, pause:77.01s, sync:1.04s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Feed] Maximum count has been reached, stop adding new samples7473 >= 7473
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Feed] Sample addition is complete, 7473 samples have been added
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter] Sample feed completed
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 28,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 180,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 7219,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 126,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 32.66 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.55s
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=7300, queue_size=68
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 28,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 299,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 7338,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 106,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 7,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Processor] Received end signal, waiting for remaining tasks to complete...
[36m(MessageQueue pid=367620)[0m MessageQueue stats: produced=7400, queue_size=168
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 113 local_trigger_step: 1 trigger_parameter_sync_step: 4 20:13:21.521
[36m(FullyAsyncTrainer pid=363373)[0m step:28 - rollouter/active_time:384.9988510608673 - rollouter/version_time:386.04811573028564 - rollouter/idle_ratio:0.0027179634523883944
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 20:13:21,524 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 139
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 139
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.54s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 28,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 306,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 7465,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 8,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 169,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 114 local_trigger_step: 2 trigger_parameter_sync_step: 4 20:14:27.280
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 20:14:27,283 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 105
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.29 seconds.mq_len: 105
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.53s
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 115 local_trigger_step: 3 trigger_parameter_sync_step: 4 20:15:34.486
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 20:15:34,489 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 42
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 42
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=363373)[0m [BatchUtils] Batch assembly completed in 0.55s
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 28,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 306,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 7467,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 6,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 43,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] global_steps: 116 local_trigger_step: 4 trigger_parameter_sync_step: 4 20:16:43.268
[36m(FullyAsyncTrainer pid=363373)[0m aggregated metrics done. cost 0.000659942626953125
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [3:09:45<00:00, 363.44s/it]
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress: 30it [3:09:50, 255.75s/it]                                                                                                                                       
[36m(FullyAsyncTrainer pid=363373)[0m step:29 - fully_async/count/stale_samples_processed:1430.0 - fully_async/count/stale_trajectory_processed:11440.0 - fully_async/count/current_param_version:28.0 - fully_async/processing_time/avg:30.483302249445842 - fully_async/processing_time/max:383.98370129894465 - fully_async/processing_time/min:3.2306699943728745 - fully_async/processing_time/tp50:27.04013274423778 - fully_async/processing_time/tp99:87.61952149802225 - fully_async/processing_time/tp95:55.03263864743057 - fully_async/monitor/active_tasks_size:105.0 - fully_async/monitor/queue/pending_queue_size:72.5 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:7360.0 - fully_async/count/staleness_samples:265.75 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:128.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:33.589683055877686 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:7.517173207925785 - rollout_corr/training_log_ppl:0.9667890808135863 - rollout_corr/kl:0.1430029799454347 - rollout_corr/k3_kl:0.11674245574809332 - rollout_corr/rollout_ppl:4.34017825772442 - rollout_corr/rollout_log_ppl:0.8108301050737088 - rollout_corr/log_ppl_diff:0.15595897749064425 - rollout_corr/log_ppl_abs_diff:0.15598660346610407 - rollout_corr/log_ppl_diff_max:2.27899169921875 - rollout_corr/log_ppl_diff_min:-0.007935941219329834 - rollout_corr/ppl_ratio:1.1901097922378563 - rollout_corr/chi2_token:0.8116438027591771 - rollout_corr/chi2_seq:-0.9726102372627534 - actor/kl_loss:0.17419554684554772 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.026353476558806457 - actor/ppo_kl:0.14175570816229163 - actor/pg_clipfrac_lower:4.853086259087603e-05 - actor/pg_loss:0.054872226207242344 - actor/grad_norm:0.5433117687316136 - perf/mfu/actor:0.046288301799182634 - perf/max_memory_allocated_gb:20.516846656799316 - perf/max_memory_reserved_gb:59.615234375 - perf/cpu_memory_used_gb:81.98885345458984 - actor/lr:1e-06 - training/global_step:116.0 - training/epoch:0.0 - critic/score/mean:0.12080955505371094 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.12080955505371094 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.05546493735164404 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.05546493735164404 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:232.85009765625 - response_length/max:3072.0 - response_length/min:13.0 - response_length/clip_ratio:0.00146484375 - response_length_non_aborted/mean:232.85009765625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:13.0 - response_length_non_aborted/clip_ratio:0.00146484375 - response/aborted_ratio:0.0 - prompt_length/mean:104.09375 - prompt_length/max:177.0 - prompt_length/min:66.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:36.416616844944656 - timing_s/reward:0.000779374036937952 - timing_s/old_log_prob:0.00101041654124856 - timing_s/ref:99.35863952990621 - timing_s/adv:0.24769298499450088 - timing_s/update_actor:169.03663254668936 - timing_s/step:305.0669474955648 - timing_per_token_ms/gen:0.008769780417538954 - timing_per_token_ms/update_actor:0.2245529779927699 - timing_per_token_ms/ref:0.1297720295212086 - timing_per_token_ms/adv:0.00031486166451226275 - perf/total_num_tokens:690061.0 - perf/time_per_step:305.0669474955648 - perf/throughput:1130.999286656632 - trainer/idle_ratio:0.1193725414827973
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter] Streaming process completed
[36m(WorkerDict pid=361271)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 28 to 29
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 3.09 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 28 to 29 ,reset staleness_samples to: 50,idle_ratio: None
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.1201341152191162 seconds, while cache cost 5.4836273193359375e-06 seconds,  register cost 0.0005247592926025391 seconds, update cost 0.18303799629211426 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:29 - timing_s/wait_last_valid:0.0030269259586930275 - timing_s/param_sync:4.223766766954213
[36m(FullyAsyncTrainer pid=363373)[0m [Rank 0 | Local Rank 0] 2026-01-02 20:16:47,514 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.121211290359497 seconds, while cache cost 0.7215077877044678 seconds,  register cost 0.21278166770935059 seconds, update cost 0.18310880661010742 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 4.22 seconds, pause:3.10s, sync:1.13s
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] Detected termination signal (None), stopping sample collection. Collected 49/64 samples
[36m(FullyAsyncTrainer pid=363373)[0m [FullyAsyncTrainer] not enough samples collected after loop
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=363373)[0m step:29
[36m(FullyAsyncTrainer pid=363373)[0m step:30
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(WorkerDict pid=365376)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:1
[36m(MessageQueue pid=367620)[0m Parameter version updated from 29 to 30
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] rollout paused. cost 0.02 seconds
[36m(WorkerDict pid=365376)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 942.29MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 29 to 30 ,reset staleness_samples to: 0,idle_ratio: None
[36m(FullyAsyncRollouter pid=360588)[0m [Rank 0 | Local Rank 0] 2026-01-02 20:16:48,866 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'green'}
[36m(WorkerDict pid=361271)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.0801317691802979 seconds, while cache cost 1.6689300537109375e-06 seconds,  register cost 0.0004253387451171875 seconds, update cost 0.16731858253479004 seconds
[36m(FullyAsyncTrainer pid=363373)[0m step:30 - timing_s/wait_last_valid:0.001471277792006731 - timing_s/param_sync:1.1099470010958612
[36m(WorkerDict pid=365376)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.0801305770874023 seconds, while cache cost 0.6999845504760742 seconds,  register cost 0.2092275619506836 seconds, update cost 0.1674027442932129 seconds
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] sync_weights success. cost 1.11 seconds, pause:0.02s, sync:1.08s
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(FullyAsyncRollouter pid=360588)[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': True, 'validate': True, 'global_steps': 7473}
[36m(WorkerDict pid=365376)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(FullyAsyncRollouter pid=360588)[0m validation generation end
total time: 11982.09 seconds
[36m(FullyAsyncTrainer pid=363373)[0m Training Progress: 30it [3:16:25, 392.84s/it]
/home/ma-user/.conda/envs/test01/lib/python3.10/subprocess.py:1072: ResourceWarning: subprocess 353388 is still running
  _warn("subprocess %s is still running" % self.pid,
/home/ma-user/.conda/envs/test01/lib/python3.10/subprocess.py:1072: ResourceWarning: subprocess 353756 is still running
  _warn("subprocess %s is still running" % self.pid,
[36m(FullyAsyncTaskRunner pid=357514)[0m [ASYNC MAIN] One component completed successfully
[36m(FullyAsyncTaskRunner pid=357514)[0m [ASYNC MAIN] One component completed successfully
[36m(FullyAsyncTaskRunner pid=357514)[0m [ASYNC MAIN] Training completed or interrupted
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 30,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/staleness_samples': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'count/total_generated_samples': 7473,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'monitor/queue/pending_queue_size': 0,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_concurrent_samples': 128,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=360588)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter] Rollouter fit completed
[36m(FullyAsyncRollouter pid=360588)[0m [FullyAsyncRollouter][Public][Resume]
[36m(FullyAsyncTrainer pid=363373)[0m step:30 - val-aux/openai/gsm8k/reward/mean@1:0.30022744503411675 - val-core/openai/gsm8k/acc/mean@1:0.312357846853677 - val-aux/num_turns/min:2 - val-aux/num_turns/max:2 - val-aux/num_turns/mean:2.0
[36m(FullyAsyncTrainer pid=363373)[0m ('[FullyAsyncTrainer] parameter version: 30 Validation metrics: '
[36m(FullyAsyncTrainer pid=363373)[0m  "{'val-aux/openai/gsm8k/reward/mean@1': 0.30022744503411675, "
[36m(FullyAsyncTrainer pid=363373)[0m  "'val-core/openai/gsm8k/acc/mean@1': 0.312357846853677, "
[36m(FullyAsyncTrainer pid=363373)[0m  "'val-aux/num_turns/min': 2, 'val-aux/num_turns/max': 2, "
[36m(FullyAsyncTrainer pid=363373)[0m  "'val-aux/num_turns/mean': 2.0}")
[36m(FullyAsyncTrainer pid=363373)[0m step:30 - rollouter/validate_time:393.8852049903944
[36m(ParameterSynchronizer pid=367621)[0m [ParameterSynchronizer] Wait last validate cost: 393.90 seconds
