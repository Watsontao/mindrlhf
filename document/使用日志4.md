## 一、mindrlhf运行Qwen2.5步骤

### 0. 整体思路

**（1）准备资源**

下载`mindRLHF`和`mindFormers`两个核心代码库；

获取预训练模型；

获取数据集；

配置环境。

**（2）处理模型**

运行`convert_weight.py`脚本，将pytorch的权重文件转换成mindspore支持的、单文件的`.safetensors`格式；

mindformers从1.5.0及以上版本已支持safetensor格式的权重直接加载及保存，无需转换成ckpt。

当前版本为v1.6.0





**（3）处理数据**

目的：原始的`.jsonl`格式文件读取效率低，需要转换为mindspore支持的`.mindrecord`格式文件；

运行`rlhf_data.py`脚本，将`GSM8K`的`train.jsonl`文件，连同Qwen2.5的tokenizer一起处理，生成最终用于训练的`gsm8k_train.mindrecord`文件。

**（4）编写与核对配置文件**

模型并行配置文件

- 定义模型架构

- 定义2卡的并行策略

- 定义相关的重计算等优化策略

GRPO算法配置文件

- 定义GRPO算法的超参数等等

**（5）启动训练**

设置 `PYTHONPATH`：运行 `export` 命令，告诉 Python 去哪里找 `mindformers` 和 `mindrlhf` 的代码。

执行 `msrun` 命令：

- 这是最终的训练启动命令。
- 它会使用 **2 卡** (`--worker_num=2`) 来运行。
- 它会加载**第三步**处理好的 `gsm8k` 数据集。
- 它会加载**第二步**切分好的 `2卡` 分布式权重。
- 它会遵循**第四步**配置好的所有训练参数。
- 最终开始真正的 GRPO 算法微调，并将训练好的模型保存下来。







### 1. 模型以及数据集获取与预处理

下面是正式的步骤

####  1.1 模型权文件和tokenizer获取 以及版本对齐

```shell
mkdir models
cd models
mkdir Qwen2.5
mkdir Qwen2.5_new1 

pip install modelscope

modelscope download --model Qwen/Qwen2.5-7B  --local_dir   /home/ma-user/work/models/Qwen2.5

modelscope download --model Qwen/Qwen2.5-7B-Instruct  --local_dir   /home/ma-user/work/models/Qwen2.5-Instruct


modelscope download --model qwen/Qwen2.5-3B-Instruct  --local_dir   /home/ma-user/work/models/Qwen2.5-3B-Instruct

git clone https://gitee.com/mindspore/mindrlhf.git
cd mindrlhf
git checkout 0cd087455
git rev-parse HEAD  # 用于检查版本
bash build.sh


git clone https://gitee.com/mindspore/mindformers.git
cd mindformers
git checkout 6a52b43 
git rev-parse HEAD  # 用于检查版本  git status
bash build.sh

https://repo.mindspore.cn/mindspore/mindspore/version/202506/20250609/master_20250609160019_8f35b18d992cacea735567ab011e91f83a074731_newest/unified/aarch64/mindspore-2.7.0-cp310-cp310-linux_aarch64.whl
```



版本

**vllm**

```
https://repo.mindspore.cn/mirrors/vllm/version/202505/20250514/v0.8.4.dev0_newest/any/vllm-0.8.4.dev0%2Bg296c657.d20250514.empty-py3-none-any.whl
```



**vllm-mindspore**

```
https://repo.mindspore.cn/mindspore/vllm-mindspore/version/202508/20250807/r0.3.0_20250807104902_4739c2e599777d7790b444ec1fb27573fb941002_newest/ascend/aarch64/

https://repo.mindspore.cn/mindspore/vllm-mindspore/version/202508/20250807/r0.3.0_20250807104902_4739c2e599777d7790b444ec1fb27573fb941002_newest/ascend/aarch64/vllm_mindspore-0.3.0-cp310-cp310-linux_aarch64.whl
```

**msadapter**

```
https://repo.mindspore.cn/mindspore/msadapter/version/202508/20250807/r0.2.0_20250807013007_e7636d61563c4beafac4b877891172464fdcf321_newest/any/

https://repo.mindspore.cn/mindspore/msadapter/version/202508/20250807/r0.2.0_20250807013007_e7636d61563c4beafac4b877891172464fdcf321_newest/any/msadapter-0.0.1-py3-none-any.whl
```

**mindspore_gs**

```
https://repo.mindspore.cn/mindspore/golden-stick/version/202506/20250604/master_20250604160014_35fcbec4406d3b18faf02ef99fcbe2741e80348e_newest/any/

https://repo.mindspore.cn/mindspore/golden-stick/version/202506/20250604/master_20250604160014_35fcbec4406d3b18faf02ef99fcbe2741e80348e_newest/any/mindspore_gs-1.2.0.dev20250604-py3-none-any.whl
```

**mindspore**

```
https://repo.mindspore.cn/mindspore/mindspore/version/202508/20250807/r2.7_20250807154652_7edec76ede691ac90be9590b0ebb2a65923b55fe_newest/unified/aarch64/

https://repo.mindspore.cn/mindspore/mindspore/version/202508/20250807/r2.7_20250807154652_7edec76ede691ac90be9590b0ebb2a65923b55fe_newest/unified/aarch64/mindspore-2.7.0-cp310-cp310-linux_aarch64.whl
```

**mindformers**

```
git checkout 051d65f
```





#### 1.2 数据集文件获取与预处理（微调）

先把原始数据集转换为指定格式，

然后进行数据预处理和Mindrecord数据生成

```shell
mkdir data
cd data
git clone https://github.com/tatsu-lab/stanford_alpaca.git   获取alpaca 数据集

cd ../mindformers/research/qwen2_5/

# 执行research/qwen2_5/alpaca_converter.py，将原始数据集转换为指定格式。
python alpaca_converter.py \
--data_path /home/ma-user/work/data/stanford_alpaca/alpaca_data.json \
--output_path /home/ma-user/work/data/alpaca-data-conversation.json 


# 执行research/qwen2_5/qwen2_5_preprocess.py文件，进行数据预处理和Mindrecord数据生成。 
# 注意修改seq_length  正常来说同时output_file的文件名也要保持一致
export PYTHONPATH=/home/ma-user/work/vllm-mindspore//mindformers:$PYTHONPATH
python qwen2_5_preprocess.py \
 --dataset_type 'qa' \
 --input_glob /home/ma-user/work/data/alpaca-data-conversation.json \
 --vocab_file /home/ma-user/work/models/Qwen2.5/vocab.json \
 --merges_file /home/ma-user/work/models/Qwen2.5/merges.txt \
 --seq_length 4096 \
 --output_file /home/ma-user/work/data/alpaca-fastchat4096.mindrecord
```

#### 1.3 设置 msprobe 

不然后面会报错：识别不到save

```shell
git clone https://gitcode.com/Ascend/mstt.git
cd mstt/debug/accuracy_tools

pip install setuptools wheel

python setup.py bdist_wheel --include-mod=[adump]
cd ./dist
pip install ./mindstudio_probe*.whl
```



### 2. 微调

#### 2.1  执行单机1卡微调

```shell
cd mindformers
python run_mindformer.py \
  --register_path research/qwen2_5 \
  --config research/qwen2_5/finetune_qwen2_5_0_5b_8k.yaml \
  --run_mode finetune \
  --train_data /home/ma-user/work/data/alpaca-fastchat4096.mindrecord
```





### 3. GRPO

#### 3.1 数据集获取和预处理

获取数据集并将其转换为.mindrecord格式，这里用的是mindrlhf里面的rlhf_data.py程序，跟前面微调用的不一样

```shell
建议新开个terminal
cd data
# 下载gsm8k数据集
git clone https://github.com/openai/grade-school-math.git

# 下载完成后，需要转为MindSpore使用的.mindrecord文件   首先进入MindRLHF路径 并执行以下脚本：
cd mindrlhf

pip install jsonlines

export PYTHONPATH=/home/ma-user/work/mindformers:$PYTHONPATH

python examples/grpo/qwen_grpo_tutorial/rlhf_data.py \
--vocab_path /home/ma-user/work/models/Qwen2.5-Instruct/vocab.json \
--merges_file_path /home/ma-user/work/models/Qwen2.5-Instruct/merges.txt \
--file_path /home/ma-user/work/data/grade-school-math/grade_school_math/data/train.jsonl \
--output_path /home/ma-user/work/data/gsm8k_train.mindrecord \
--dataset_type gsm8k
# 此脚本会将train.jsonl转换成mindrecord的形式保存在/{path}/gsm8k_train.mindrecord。此数据路径将在训练拉起时作为mind_dataset_dir的值被传入。
```



#### 3.2 进行GRPO训练

```shell
# 告诉 Python，除了在site-packages之外，额外去哪些目录里找模块
export MINDRLHF_FILE=/home/ma-user/work/mindrlhf
export MINDFORMERS_FILE=/home/ma-user/work/vllm-mindspore/mindformers

export PYTHONPATH="$MINDRLHF_FILE:$MINDFORMERS_FILE:$PYTHONPATH"
export MINDFORMERS_PATH="$MINDFORMERS_FILE:$MINDFORMERS_PATH"
export MS_ENABLE_LCCL=off

export PYTHONPATH=/home/wst/mindformers:$PYTHONPATH


export PYTHONPATH=/home/ma-user/work/mindrlhf:$PYTHONPATH


# 备用
export PYTHONPATH=/home/ma-user/work/mindrlhf:$PYTHONPATH
export PYTHONPATH=/home/ma-user/work/mindformers:$PYTHONPATH
export PYTHONPATH=/home/ma-user/work/vllm-mindspore/mindformers:$PYTHONPATH
```

**（1）单机8卡拉起Qwen2.5-7b**

无增量KVcache  无vLLM

随后使用以下命令拉起单机8卡GRPO训练任务，可以参考run_grpo.sh

```yaml
# 在运行此命令前，请确保您已经设置好了 PYTHONPATH 环境变量
# 
export PYTHONPATH="/home/ma-user/work/mindrlhf:/home/ma-user/work/mindformers:$PYTHONPATH"
msrun --worker_num=8 --local_worker_num=8 \
--master_addr=127.0.0.1 --master_port=9887 \
--join=True --log_dir=./grpo_log \
examples/grpo/qwen_grpo_tutorial/main.py \
--config examples/grpo/qwen_grpo_tutorial/grpo_config.yaml \
--dataset_file /home/ma-user/work/data/gsm8k_train.mindrecord \
--tokenizer_dir /home/ma-user/work/models/Qwen2.5-Instruct/ \
--actor_checkpoint_path /home/ma-user/work/models/Qwen2.5-Instruct/ \
--ref_checkpoint_path /home/ma-user/work/models/Qwen2.5-Instruct/ \
--generate_checkpoint_path /home/ma-user/work/models/Qwen2.5-Instruct/ \
--verifier_function "qwen_accuracy_reward,format_reward" \
--verifier_weight "1.0,1.0" \
--save_checkpoint_dir "/home/ma-user/work/mindrlhf/output/grpo_checkpoints/"
```



**（3）bahs run_grpo_vllm.sh来启动vllm加速**

```shell
#!/bin/bash

export MS_ALLOC_CONF="memory_tracker:False,enable_vmm:True"
export GLOG_v=2

export vLLM_MODEL_BACKEND=MindFormers
export HCCL_EXEC_TIMEOUT=7200
export MS_JIT_MODULES=vllm_mindspore,research
export MS_ENABLE_LCCL=off

root_path="$(realpath "$(dirname "$0")")"
root_path=$root_path/../../../
cd $root_path
export PYTHONPATH=$root_path:$PYTHONPATH  # define mindrlhf path

export ASCEND_HOME_PATH=/usr/local/Ascend/ascend-toolkit/latest # need modify
export MINDFORMERS_PATH=/home/ma-user/work/mindformers # need modify
export MSADAPTER_PATH=/path/to/msadapter # need modify (msadapter lib path)
export QWEN_MODEL_PATH=/home/ma-user/work/models/Qwen2.5-Instruct
export DATASET_FILE=/home/ma-user/work/data/gsm8k_train.mindrecord
export SAVE_CHECKPOINT_DIR=/home/ma-user/work/mindrlhf/output/grpo_checkpoints

export PYTHONPATH=$MSADAPTER_PATH:$MINDFORMERS_PATH:$PYTHONPATH


msrun --worker_num=8 --local_worker_num=8 \
--master_addr=127.0.0.1 --master_port=9887 \
--join=True --log_dir=./prof_vllm_log \
examples/grpo/qwen_grpo_tutorial/main.py \
--config examples/grpo/qwen_grpo_tutorial/grpo_config.yaml \
--tokenizer_dir $QWEN_MODEL_PATH \
--dataset_file $DATASET_FILE \
--save_checkpoint_dir $SAVE_CHECKPOINT_DIR \
--actor_checkpoint_path $QWEN_MODEL_PATH \
--ref_checkpoint_path $QWEN_MODEL_PATH \
--generate_checkpoint_path $QWEN_MODEL_PATH \
--verifier_function "qwen_accuracy_reward,format_reward" \
--verifier_weight "1.0,1.0" > vllm.log 2>&1 &
```



























































## 附录

### 1. 查看cann版本

```shell
# 参考网址教程：https://www.hiascend.com/document/detail/zh/canncommercial/5046/envdeployment/instg/instg_000134.html
echo $ASCEND_HOME_PATH
cd $ASCEND_HOME_PATH
ls
cd arm64-linux/
cat ascend_toolkit_install.info
```

### 2. 无KV cache  无vllm

#### 2.1 grpo_config.yaml

```yaml

```



#### 2.2 finetune_qwen2_5_7b.yaml

```yaml

```



#### 2.3 predict_qwen2_5_7b.yaml

```yaml

```

我现在是没有启动kv cache  也没有启动vllm对吧？





```shell
ImportError: cannot import name 'DEFAULT_CIPHERS' from 'urllib3.util.ssl_' (/home/ma-user/anaconda3/envs/MindSpore/lib/python3.10/site-packages/urllib3/util/ssl_.py)
解决：
pip install "urllib3<2" -U
或者禁用 boto
pip uninstall -y boto3 botocore

cannot import name 'DEFAULT_CIPHERS' from 'urllib3.util.ssl_
pip install --upgrade 'urllib3==1.26.7' 
```







