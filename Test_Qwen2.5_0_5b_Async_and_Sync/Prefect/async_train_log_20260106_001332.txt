/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
  warnings.warn(f"Warning: The {path} owner does not match the current owner.")
/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
  warnings.warn(f"Warning: The {path} owner does not match the current owner.")
/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
  warnings.warn(f"Warning: The {path} owner does not match the current owner.")
/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
  warnings.warn(f"Warning: The {path} owner does not match the current owner.")
/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
[Rank 0 | Local Rank 0] 2026-01-06 00:16:33,467 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/ray/_private/node.py:1125: ResourceWarning: unclosed file <_io.TextIOWrapper name='/dev/null' mode='w' encoding='UTF-8'>
  process_info = ray._private.services.start_gcs_server(
/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/ray/_private/node.py:1086: ResourceWarning: unclosed file <_io.TextIOWrapper name='/dev/null' mode='w' encoding='UTF-8'>
  self._webui_url, process_info = ray._private.services.start_api_server(
2026-01-06 00:16:44,270	WARNING utils.py:460 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.
2026-01-06 00:16:45,540	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(pid=545998)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=545998)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=545998)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=545998)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=545998)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=545998)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=545998)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=545998)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=545998)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
[36m(pid=545998)[0m     *************************************************************************************************************
[36m(pid=545998)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(pid=545998)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(pid=545998)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(pid=545998)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(pid=545998)[0m     The device parameters have been replaced with npu in the function below:
[36m(pid=545998)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(pid=545998)[0m     *************************************************************************************************************
[36m(pid=545998)[0m     
[36m(pid=545998)[0m   warnings.warn(msg, ImportWarning)
[36m(pid=545998)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(pid=545998)[0m   warnings.warn(msg, RuntimeWarning)
[36m(pid=545998)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(pid=545998)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(pid=545998)[0m   import pkg_resources
ray init kwargs: {'num_cpus': None, 'runtime_env': {'env_vars': {'TOKENIZERS_PARALLELISM': 'true', 'NCCL_DEBUG': 'WARN', 'VLLM_LOGGING_LEVEL': 'WARN', 'VLLM_ALLOW_RUNTIME_LORA_UPDATING': 'true', 'VLLM_ALLREDUCE_USE_SYMM_MEM': '0', 'CUDA_DEVICE_MAX_CONNECTIONS': '1', 'NCCL_CUMEM_ENABLE': '0'}, 'working_dir': None}}
[36m(pid=545998)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:17:05,728 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(FullyAsyncTaskRunner pid=545998)[0m [ASYNC MAIN] Starting fully async PPO training...
[36m(FullyAsyncTaskRunner pid=545998)[0m [ASYNC MAIN] TaskRunner hostname: notebook-7f74bd20-3c19-4e51-b968-a157f487844c, PID: 545998
[36m(FullyAsyncTaskRunner pid=545998)[0m {'actor_rollout_ref': {'actor': {'_target_': 'verl.workers.config.McoreActorConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'calculate_entropy': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'checkpoint': {'_target_': 'verl.trainer.config.CheckpointConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                 'async_save': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                 'load_contents': ['model',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                   'optimizer',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                   'extra'],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                 'save_contents': ['model',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                   'optimizer',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                   'extra']},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'clip_ratio': 0.2,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'clip_ratio_c': 3,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'clip_ratio_high': 0.2,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'clip_ratio_low': 0.2,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'data_loader_seed': 42,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'entropy_coeff': 0.001,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'freeze_vision_tower': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'kl_loss_coef': 0.001,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'load_weight': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'loss_agg_mode': 'token-mean',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'loss_scale_factor': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'megatron': {'_target_': 'verl.workers.config.McoreEngineConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'context_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'dist_checkpointing_path': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'dist_checkpointing_prefix': '',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'dtype': 'bfloat16',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'expert_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'expert_tensor_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'forward_only': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'grad_offload': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'optimizer_offload': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'override_ddp_config': {},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'override_mcore_model_config': {},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'override_transformer_config': {'apply_rope_fusion': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                               'attention_backend': 'flash',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                               'bias_activation_fusion': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                               'bias_dropout_fusion': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                               'deallocate_pipeline_outputs': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                               'gradient_accumulation_fusion': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                               'masked_softmax_fusion': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                               'persist_layer_norm': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                               'recompute_granularity': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                               'recompute_method': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                               'recompute_modules': ['core_attn'],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                               'recompute_num_layers': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                               'use_flash_attn': True},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'param_offload': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'pipeline_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'seed': 42,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'sequence_parallel': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'tensor_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'use_dist_checkpointing': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'use_distributed_optimizer': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'use_mbridge': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'use_remove_padding': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'vanilla_mbridge': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'virtual_pipeline_model_parallel_size': None},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'optim': {'_target_': 'verl.workers.config.McoreOptimizerConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                            'betas': [0.9, 0.999],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                            'clip_grad': 1.0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                            'lr': 5e-07,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                            'lr_decay_steps': 51200,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                            'lr_decay_style': 'constant',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                            'lr_warmup_init': 0.0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                            'lr_warmup_steps': -1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                            'lr_wsd_decay_steps': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                            'lr_wsd_decay_style': 'exponential',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                            'min_lr': 0.0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                            'optimizer': 'adam',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                            'override_optimizer_config': {'optimizer_cpu_offload': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                          'optimizer_offload_fraction': 0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                          'overlap_cpu_optimizer_d2h_h2d': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                          'use_precision_aware_optimizer': True},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                            'total_training_steps': -1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                            'use_checkpoint_opt_param_scheduler': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                            'weight_decay': 0.01,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                            'weight_decay_incr_style': 'constant'},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'policy_loss': {'_target_': 'verl.workers.config.PolicyLossConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                  'clip_cov_lb': 1.0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                  'clip_cov_ratio': 0.0002,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                  'clip_cov_ub': 5.0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                  'kl_cov_ratio': 0.0002,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                  'loss_mode': 'vanilla',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                  'ppo_kl_coef': 0.1},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'ppo_epochs': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'ppo_max_token_len_per_gpu': 5120,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'ppo_micro_batch_size': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'ppo_micro_batch_size_per_gpu': 32,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'ppo_mini_batch_size': 64,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'all_ranks': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'enable': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'ranks': [],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'save_path': 'outputs/profile',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'tool': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                               'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                       'analysis': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                       'contents': [],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                       'discrete': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                       'level': 'level0'},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                               'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                        'discrete': False},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                               'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                         'step_end': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                         'step_start': 0},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                               'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                                'stack_depth': 32,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                                'trace_alloc_max_entries': 100000}}},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'rollout_n': 8,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'router_replay': {'_target_': 'verl.workers.config.RouterReplayConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                    'mode': 'disabled',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                    'record_file': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                    'replay_file': None},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'shuffle': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'strategy': 'megatron',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'use_dynamic_bsz': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'use_fused_kernels': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'use_kl_loss': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'use_rollout_log_probs': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'use_torch_compile': True},
[36m(FullyAsyncTaskRunner pid=545998)[0m                        'checkpoint_engine': {'device_buffer_size_M': 4096,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                              'enable': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                              'overlap_broadcast_and_consume': False},
[36m(FullyAsyncTaskRunner pid=545998)[0m                        'hybrid_engine': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                        'model': {'_target_': 'verl.workers.config.HFModelConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'custom_chat_template': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'enable_activation_offload': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'enable_gradient_checkpointing': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'exclude_modules': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'external_lib': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'fused_kernel_options': {'impl_backend': 'torch'},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'hf_config_path': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'lora': {'a2a_experimental': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                           'adapter_path': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                           'alpha': 32,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                           'dropout': 0.0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                           'dropout_position': 'pre',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                           'dtype': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                           'exclude_modules': [],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                           'freeze_language_model': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                           'freeze_vision_model': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                           'freeze_vision_projection': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                           'lora_A_init_method': 'xavier',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                           'lora_B_init_method': 'zero',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                           'rank': 0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                           'target_modules': ['linear_qkv',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                              'linear_proj',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                              'linear_fc1',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                              'linear_fc2'],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                           'type': 'lora'},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'lora_adapter_path': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'lora_alpha': 16,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'lora_rank': 0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'override_config': {'model_config': {'max_position_embeddings': 5120},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                      'moe_config': {'freeze_moe_router': False}},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'path': '/home/ma-user/work/models/Qwen2.5-0.5B-Instruct',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'target_modules': 'all-linear',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'tokenizer_path': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'trust_remote_code': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'use_fused_kernels': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'use_liger': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'use_remove_padding': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                  'use_shm': False},
[36m(FullyAsyncTaskRunner pid=545998)[0m                        'nccl_timeout': 600,
[36m(FullyAsyncTaskRunner pid=545998)[0m                        'ref': {'_target_': 'verl.workers.config.McoreActorConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'load_weight': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'log_prob_max_token_len_per_gpu': 5120,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'log_prob_micro_batch_size': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'log_prob_micro_batch_size_per_gpu': 32,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'log_prob_use_dynamic_bsz': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'megatron': {'_target_': 'verl.workers.config.McoreEngineConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'context_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'dist_checkpointing_path': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'dist_checkpointing_prefix': '',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'dtype': 'bfloat16',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'expert_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'expert_tensor_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'forward_only': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'grad_offload': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'optimizer_offload': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'override_ddp_config': {},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'override_mcore_model_config': {},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'override_transformer_config': {'apply_rope_fusion': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                             'attention_backend': 'flash',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                             'bias_activation_fusion': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                             'bias_dropout_fusion': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                             'deallocate_pipeline_outputs': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                             'gradient_accumulation_fusion': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                             'masked_softmax_fusion': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                             'persist_layer_norm': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                             'recompute_granularity': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                             'recompute_method': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                             'recompute_modules': ['core_attn'],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                             'recompute_num_layers': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                             'use_flash_attn': True},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'param_offload': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'pipeline_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'seed': 42,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'sequence_parallel': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'tensor_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'use_dist_checkpointing': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'use_distributed_optimizer': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'use_mbridge': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'use_remove_padding': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'vanilla_mbridge': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'virtual_pipeline_model_parallel_size': None},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'all_ranks': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'enable': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'ranks': [],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'save_path': 'outputs/profile',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'tool': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                     'analysis': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                     'contents': [],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                     'discrete': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                     'level': 'level0'},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                             'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                      'discrete': False},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                             'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                       'step_end': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                       'step_start': 0},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                             'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                              'stack_depth': 32,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                              'trace_alloc_max_entries': 100000}}},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'rollout_n': 8,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'router_replay': {'_target_': 'verl.workers.config.RouterReplayConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                  'mode': 'disabled',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                  'record_file': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                  'replay_file': None},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'strategy': 'megatron',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'use_torch_compile': True},
[36m(FullyAsyncTaskRunner pid=545998)[0m                        'rollout': {'_target_': 'verl.workers.config.RolloutConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'agent': {'_target_': 'verl.workers.config.AgentLoopConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                              'agent_loop_config_path': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                              'custom_async_server': {'_target_': 'verl.workers.config.CustomAsyncServerConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                      'name': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                      'path': None},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                              'default_agent_loop': 'single_turn_agent',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                              'num_workers': 8},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'calculate_log_probs': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'cudagraph_capture_sizes': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'data_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'disable_log_stats': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'do_sample': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'dtype': 'bfloat16',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'enable_chunked_prefill': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'enable_prefix_caching': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'enable_rollout_routing_replay': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'enforce_eager': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'engine_kwargs': {'sglang': {}, 'vllm': {}},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'expert_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'free_cache_engine': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'gpu_memory_utilization': 0.7,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'ignore_eos': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'layer_name_map': {'gate_proj_layer_name': 'gate_up',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                       'qkv_layer_name': 'qkv'},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'load_format': 'dummy',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'log_prob_max_token_len_per_gpu': 5120,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'log_prob_micro_batch_size': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'log_prob_micro_batch_size_per_gpu': 32,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'log_prob_use_dynamic_bsz': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'max_model_len': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'max_num_batched_tokens': 5120,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'max_num_seqs': 1024,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'mode': 'async',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'multi_stage_wake_up': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'multi_turn': {'_target_': 'verl.workers.config.MultiTurnConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'enable': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'format': 'hermes',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'interaction_config_path': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'max_assistant_turns': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'max_parallel_calls': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'max_tool_response_length': 256,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'max_user_turns': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'num_repeat_rollouts': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'tokenization_sanity_check_mode': 'strict',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'tool_config_path': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'tool_response_truncate_side': 'middle',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'use_inference_chat_template': False},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'n': 8,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'name': 'vllm',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'over_sample_rate': 0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'pipeline_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                 'all_ranks': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                 'enable': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                 'ranks': [],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                 'save_path': 'outputs/profile',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                 'tool': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                 'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                         'analysis': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                         'contents': [],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                         'discrete': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                         'level': 'level0'},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                 'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                          'discrete': False},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                 'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                           'step_end': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                           'step_start': 0},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                 'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                                  'stack_depth': 32,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                                  'trace_alloc_max_entries': 100000}}},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'prometheus': {'_target_': 'verl.workers.config.PrometheusConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'enable': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'file': '/tmp/ray/session_latest/metrics/prometheus/prometheus.yml',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'port': 9090,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'served_model_name': '/home/ma-user/work/models/Qwen2.5-0.5B-Instruct'},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'prompt_length': 2048,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'quantization': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'quantization_config_file': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'response_length': 3072,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'skip_dump_dir': '/tmp/rollout_dump',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'skip_rollout': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'skip_tokenizer_init': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'temperature': 1.0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'tensor_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'top_k': -1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'top_p': 1.0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'trace': {'_target_': 'verl.workers.config.TraceConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                              'backend': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                              'max_samples_per_step_per_worker': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                              'token2text': False},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'update_weights_bucket_megabytes': 512,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                    'val_kwargs': {'_target_': 'verl.workers.config.SamplingConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'do_sample': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'n': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'temperature': 1.0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'top_k': -1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'top_p': 0.7}}},
[36m(FullyAsyncTaskRunner pid=545998)[0m  'algorithm': {'_target_': 'verl.trainer.config.AlgoConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                'adv_estimator': 'grpo',
[36m(FullyAsyncTaskRunner pid=545998)[0m                'gamma': 1.0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                'kl_ctrl': {'_target_': 'verl.trainer.config.KLControlConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                            'horizon': 10000,
[36m(FullyAsyncTaskRunner pid=545998)[0m                            'kl_coef': 0.001,
[36m(FullyAsyncTaskRunner pid=545998)[0m                            'target_kl': 0.1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                            'type': 'fixed'},
[36m(FullyAsyncTaskRunner pid=545998)[0m                'kl_penalty': 'kl',
[36m(FullyAsyncTaskRunner pid=545998)[0m                'lam': 1.0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                'norm_adv_by_std_in_grpo': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                'pf_ppo': {'reweight_method': 'pow', 'weight_pow': 2.0},
[36m(FullyAsyncTaskRunner pid=545998)[0m                'rollout_correction': {'bypass_mode': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                       'loss_type': 'ppo_clip',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                       'rollout_is': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                       'rollout_is_batch_normalize': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                       'rollout_is_threshold': 2.0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                       'rollout_rs': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                       'rollout_rs_threshold': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                       'rollout_rs_threshold_lower': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                       'rollout_token_veto_threshold': None},
[36m(FullyAsyncTaskRunner pid=545998)[0m                'use_kl_in_reward': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                'use_pf_ppo': False},
[36m(FullyAsyncTaskRunner pid=545998)[0m  'async_training': {'checkpoint_engine': {'device_buffer_size_M': 4096,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                           'enable': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                           'overlap_broadcast_and_consume': False},
[36m(FullyAsyncTaskRunner pid=545998)[0m                     'compute_prox_log_prob': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                     'partial_rollout': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                     'require_batches': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                     'staleness_threshold': 0.2,
[36m(FullyAsyncTaskRunner pid=545998)[0m                     'trigger_parameter_sync_step': 4,
[36m(FullyAsyncTaskRunner pid=545998)[0m                     'use_rollout_log_probs': True},
[36m(FullyAsyncTaskRunner pid=545998)[0m  'critic': {'_target_': 'verl.workers.config.McoreCriticConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m             'checkpoint': {'_target_': 'verl.trainer.config.CheckpointConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                            'async_save': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                            'load_contents': ['model', 'optimizer', 'extra'],
[36m(FullyAsyncTaskRunner pid=545998)[0m                            'save_contents': ['model', 'optimizer', 'extra']},
[36m(FullyAsyncTaskRunner pid=545998)[0m             'cliprange_value': 0.5,
[36m(FullyAsyncTaskRunner pid=545998)[0m             'data_loader_seed': 42,
[36m(FullyAsyncTaskRunner pid=545998)[0m             'enable': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(FullyAsyncTaskRunner pid=545998)[0m             'load_weight': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m             'loss_agg_mode': 'token-mean',
[36m(FullyAsyncTaskRunner pid=545998)[0m             'megatron': {'_target_': 'verl.workers.config.McoreEngineConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'context_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'dist_checkpointing_path': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'dist_checkpointing_prefix': '',
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'dtype': 'bfloat16',
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'expert_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'expert_tensor_parallel_size': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'forward_only': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'grad_offload': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'optimizer_offload': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'override_ddp_config': {},
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'override_mcore_model_config': {},
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'override_transformer_config': {'attention_backend': 'flash',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                          'recompute_granularity': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                          'recompute_method': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                          'recompute_modules': ['core_attn'],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                          'recompute_num_layers': None},
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'param_offload': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'pipeline_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'seed': 42,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'sequence_parallel': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'tensor_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'use_dist_checkpointing': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'use_distributed_optimizer': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'use_mbridge': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'use_remove_padding': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'vanilla_mbridge': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'virtual_pipeline_model_parallel_size': None},
[36m(FullyAsyncTaskRunner pid=545998)[0m             'model': {'_target_': 'verl.trainer.config.BaseModelConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'external_lib': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'lora': {'a2a_experimental': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'adapter_path': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'alpha': 32,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'dropout': 0.0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'dropout_position': 'pre',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'dtype': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'exclude_modules': [],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'freeze_language_model': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'freeze_vision_model': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'freeze_vision_projection': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'lora_A_init_method': 'xavier',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'lora_B_init_method': 'zero',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'rank': 0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'target_modules': ['linear_qkv',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'linear_proj',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'linear_fc1',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'linear_fc2'],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'type': 'lora'},
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'override_config': {'model_config': {},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                           'moe_config': {'freeze_moe_router': False}},
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'path': '~/models/deepseek-llm-7b-chat',
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'tokenizer_path': '/home/ma-user/work/models/Qwen2.5-0.5B-Instruct',
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'trust_remote_code': False},
[36m(FullyAsyncTaskRunner pid=545998)[0m             'nccl_timeout': 600,
[36m(FullyAsyncTaskRunner pid=545998)[0m             'optim': {'_target_': 'verl.workers.config.McoreOptimizerConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'betas': [0.9, 0.999],
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'clip_grad': 1.0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'lr': 1e-05,
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'lr_decay_steps': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'lr_decay_style': 'constant',
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'lr_warmup_init': 0.0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'lr_warmup_steps': -1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'lr_wsd_decay_steps': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'lr_wsd_decay_style': 'exponential',
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'min_lr': 0.0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'optimizer': 'adam',
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'override_optimizer_config': {},
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'total_training_steps': -1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'use_checkpoint_opt_param_scheduler': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'weight_decay': 0.01,
[36m(FullyAsyncTaskRunner pid=545998)[0m                       'weight_decay_incr_style': 'constant'},
[36m(FullyAsyncTaskRunner pid=545998)[0m             'ppo_epochs': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(FullyAsyncTaskRunner pid=545998)[0m             'ppo_micro_batch_size': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m             'ppo_micro_batch_size_per_gpu': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m             'ppo_mini_batch_size': 64,
[36m(FullyAsyncTaskRunner pid=545998)[0m             'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'all_ranks': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'enable': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'ranks': [],
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'save_path': 'outputs/profile',
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'tool': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                          'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                  'analysis': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                  'contents': [],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                  'discrete': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                  'level': 'level0'},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                          'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                   'discrete': False},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                          'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                    'step_end': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                    'step_start': 0},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                          'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                           'stack_depth': 32,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                           'trace_alloc_max_entries': 100000}}},
[36m(FullyAsyncTaskRunner pid=545998)[0m             'rollout_n': 8,
[36m(FullyAsyncTaskRunner pid=545998)[0m             'shuffle': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m             'strategy': 'megatron',
[36m(FullyAsyncTaskRunner pid=545998)[0m             'use_dynamic_bsz': True},
[36m(FullyAsyncTaskRunner pid=545998)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(FullyAsyncTaskRunner pid=545998)[0m  'data': {'apply_chat_template_kwargs': {},
[36m(FullyAsyncTaskRunner pid=545998)[0m           'custom_cls': {'name': None, 'path': None},
[36m(FullyAsyncTaskRunner pid=545998)[0m           'datagen': {'name': None, 'path': None},
[36m(FullyAsyncTaskRunner pid=545998)[0m           'dataloader_num_workers': 8,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'filter_overlong_prompts': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'filter_overlong_prompts_workers': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'gen_batch_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'image_key': 'images',
[36m(FullyAsyncTaskRunner pid=545998)[0m           'image_patch_size': 14,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'max_prompt_length': 2048,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'max_response_length': 3072,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'prompt_key': 'prompt',
[36m(FullyAsyncTaskRunner pid=545998)[0m           'return_full_prompt': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'return_multi_modal_inputs': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'return_raw_chat': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'return_raw_input_ids': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'reward_fn_key': 'data_source',
[36m(FullyAsyncTaskRunner pid=545998)[0m           'sampler': {'class_name': None, 'class_path': None},
[36m(FullyAsyncTaskRunner pid=545998)[0m           'seed': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'shuffle': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'tokenizer': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'tool_config_path': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'train_batch_size': 0,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'train_files': '/home/ma-user/work/data/gsm8k/train.parquet',
[36m(FullyAsyncTaskRunner pid=545998)[0m           'train_max_samples': -1,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'truncation': 'error',
[36m(FullyAsyncTaskRunner pid=545998)[0m           'trust_remote_code': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'use_shm': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'val_batch_size': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'val_files': '/home/ma-user/work/data/gsm8k/test.parquet',
[36m(FullyAsyncTaskRunner pid=545998)[0m           'val_max_samples': -1,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'validation_shuffle': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m           'video_key': 'videos'},
[36m(FullyAsyncTaskRunner pid=545998)[0m  'global_profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                      'global_tool_config': {'nsys': {'controller_nsight_options': {'cuda-graph-trace': 'graph',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                                    'cuda-memory-usage': 'true',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                                    'trace': 'cuda,nvtx,cublas,ucx'},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                      'discrete': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                      'worker_nsight_options': {'capture-range': 'cudaProfilerApi',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                                'capture-range-end': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                                'cuda-graph-trace': 'graph',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                                'cuda-memory-usage': 'true',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                                'kill': 'none',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                                'trace': 'cuda,nvtx,cublas,ucx'}},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                             'torch_memory': {'context': 'all',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                              'kw_args': {},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                              'stack_depth': 32,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                              'stacks': 'all',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                              'trace_alloc_max_entries': 100000}},
[36m(FullyAsyncTaskRunner pid=545998)[0m                      'profile_continuous_steps': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                      'save_path': 'outputs/profile',
[36m(FullyAsyncTaskRunner pid=545998)[0m                      'steps': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                      'tool': None},
[36m(FullyAsyncTaskRunner pid=545998)[0m  'ray_kwargs': {'ray_init': {'num_cpus': None}, 'timeline_json_file': None},
[36m(FullyAsyncTaskRunner pid=545998)[0m  'reward_manager': {'_target_': 'verl.trainer.config.config.RewardManagerConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                     'module': {'_target_': 'verl.trainer.config.config.ModuleConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'name': 'custom_reward_manager',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'path': None},
[36m(FullyAsyncTaskRunner pid=545998)[0m                     'name': 'dapo',
[36m(FullyAsyncTaskRunner pid=545998)[0m                     'source': 'register'},
[36m(FullyAsyncTaskRunner pid=545998)[0m  'reward_model': {'enable': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'enable_resource_pool': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'launch_reward_fn_async': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'load_weight': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'max_length': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'megatron': {'_target_': 'verl.workers.config.MegatronEngineConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'context_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'dist_checkpointing_path': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'dist_checkpointing_prefix': '',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'dtype': 'bfloat16',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'expert_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'expert_tensor_parallel_size': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'override_transformer_config': {'apply_rope_fusion': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                'attention_backend': 'flash',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                'bias_activation_fusion': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                'bias_dropout_fusion': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                'deallocate_pipeline_outputs': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                'gradient_accumulation_fusion': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                'masked_softmax_fusion': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                'persist_layer_norm': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                'recompute_granularity': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                'recompute_method': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                'recompute_modules': ['core_attn'],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                'recompute_num_layers': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                'use_flash_attn': True},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'param_offload': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'pipeline_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'seed': 42,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'sequence_parallel': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'tensor_model_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'use_dist_checkpointing': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'use_distributed_optimizer': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'use_mbridge': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'use_remove_padding': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'vanilla_mbridge': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'virtual_pipeline_model_parallel_size': None},
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'micro_batch_size': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'micro_batch_size_per_gpu': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'model': {'external_lib': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                             'input_tokenizer': '/home/ma-user/work/models/Qwen2.5-0.5B-Instruct',
[36m(FullyAsyncTaskRunner pid=545998)[0m                             'override_config': {},
[36m(FullyAsyncTaskRunner pid=545998)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(FullyAsyncTaskRunner pid=545998)[0m                             'trust_remote_code': False},
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'n_gpus_per_node': 8,
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'nccl_timeout': 600,
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'nnodes': 0,
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'num_workers': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'all_ranks': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'enable': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'ranks': [],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'save_path': 'outputs/profile',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'tool': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                        'analysis': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                        'contents': [],
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                        'discrete': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                        'level': 'level0'},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                         'discrete': False},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                          'step_end': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                          'step_start': 0},
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                 'stack_depth': 32,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                                 'trace_alloc_max_entries': 100000}}},
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'reward_kwargs': {'max_resp_len': 3072,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                     'overlong_buffer_cfg': {'enable': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                             'len': 512,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                             'log': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                                             'penalty_factor': 1.0}},
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'reward_loop_class_name': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'reward_loop_module_path': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'reward_loop_source': 'register',
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'reward_manager': 'dapo',
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'rollout': {'_target_': 'verl.workers.config.RolloutConfig',
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'cudagraph_capture_sizes': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'data_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'disable_log_stats': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'dtype': 'bfloat16',
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'enable_chunked_prefill': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'enable_prefix_caching': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'enforce_eager': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'engine_kwargs': {},
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'expert_parallel_size': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'free_cache_engine': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'gpu_memory_utilization': 0.5,
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'limit_images': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'load_format': 'auto',
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'max_model_len': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'max_num_batched_tokens': 8192,
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'max_num_seqs': 1024,
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'name': '???',
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'prompt_length': 2048,
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'response_length': 2048,
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'skip_tokenizer_init': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m                               'tensor_model_parallel_size': 2},
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'sandbox_fusion': {'max_concurrent': 64,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                      'memory_limit_mb': 1024,
[36m(FullyAsyncTaskRunner pid=545998)[0m                                      'url': None},
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'strategy': 'megatron',
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'use_dynamic_bsz': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m                   'use_reward_loop': True},
[36m(FullyAsyncTaskRunner pid=545998)[0m  'rollout': {'n': 4,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'n_gpus_per_node': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'nnodes': 2,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'test_freq': 5,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'total_epochs': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'total_rollout_steps': 51200},
[36m(FullyAsyncTaskRunner pid=545998)[0m  'trainer': {'balance_batch': True,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'critic_warmup': 0,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'default_hdfs_dir': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m /home/ma-user/work/verl/verl/workers/megatron_workers.py:54: UserWarning: NPU not support router replay for now.
[36m(FullyAsyncTaskRunner pid=545998)[0m   from verl.utils.megatron.router_replay_patch import RouterReplay, RouterReplayAction, apply_router_replay_patch
[36m(FullyAsyncTaskRunner pid=545998)[0m /home/ma-user/work/verl/verl/workers/actor/megatron_actor.py:44: UserWarning: NPU not support router replay for now.
[36m(FullyAsyncTaskRunner pid=545998)[0m   from verl.utils.megatron.router_replay_utils import (
[36m(pid=551476)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=551476)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=551476)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=551476)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=551476)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=551476)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=551476)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=551476)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=551476)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
[36m(pid=551476)[0m     *************************************************************************************************************
[36m(pid=551476)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(pid=551476)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(pid=551476)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(pid=551476)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(pid=551476)[0m     The device parameters have been replaced with npu in the function below:
[36m(pid=551476)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(pid=551476)[0m     *************************************************************************************************************
[36m(pid=551476)[0m     
[36m(pid=551476)[0m   warnings.warn(msg, ImportWarning)
[36m(pid=551476)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(pid=551476)[0m   warnings.warn(msg, RuntimeWarning)
[36m(pid=551476)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(pid=551476)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(pid=551476)[0m   import pkg_resources
[36m(FullyAsyncRollouter pid=551476)[0m /home/ma-user/work/verl/verl/workers/megatron_workers.py:54: UserWarning: NPU not support router replay for now.
[36m(FullyAsyncRollouter pid=551476)[0m   from verl.utils.megatron.router_replay_patch import RouterReplay, RouterReplayAction, apply_router_replay_patch
[36m(FullyAsyncRollouter pid=551476)[0m /home/ma-user/work/verl/verl/workers/actor/megatron_actor.py:44: UserWarning: NPU not support router replay for now.
[36m(FullyAsyncRollouter pid=551476)[0m   from verl.utils.megatron.router_replay_utils import (
[36m(FullyAsyncRollouter pid=551476)[0m Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(FullyAsyncRollouter pid=551476)[0m Filtering prompts longer than 2048 tokens (num_proc=1):   0%|                                                                                                             | 0/7473 [00:00<?, ? examples/s]
[36m(FullyAsyncRollouter pid=551476)[0m Filtering prompts longer than 2048 tokens (num_proc=1):  13%|████████████▉                                                                                    | 1000/7473 [00:02<00:14, 457.61 examples/s]
[36m(FullyAsyncRollouter pid=551476)[0m Filtering prompts longer than 2048 tokens (num_proc=1):  27%|█████████████████████████▉                                                                       | 2000/7473 [00:02<00:07, 755.96 examples/s]
[36m(FullyAsyncRollouter pid=551476)[0m Filtering prompts longer than 2048 tokens (num_proc=1):  40%|██████████████████████████████████████▉                                                          | 3000/7473 [00:03<00:04, 947.51 examples/s]
[36m(FullyAsyncRollouter pid=551476)[0m Filtering prompts longer than 2048 tokens (num_proc=1):  54%|███████████████████████████████████████████████████▍                                            | 4000/7473 [00:04<00:03, 1072.19 examples/s]
[36m(FullyAsyncRollouter pid=551476)[0m Filtering prompts longer than 2048 tokens (num_proc=1):  67%|████████████████████████████████████████████████████████████████▏                               | 5000/7473 [00:05<00:02, 1158.61 examples/s]
[36m(FullyAsyncRollouter pid=551476)[0m Filtering prompts longer than 2048 tokens (num_proc=1):  80%|█████████████████████████████████████████████████████████████████████████████                   | 6000/7473 [00:05<00:01, 1220.84 examples/s]
[36m(FullyAsyncRollouter pid=551476)[0m Filtering prompts longer than 2048 tokens (num_proc=1):  94%|█████████████████████████████████████████████████████████████████████████████████████████▉      | 7000/7473 [00:06<00:00, 1262.18 examples/s]
[36m(FullyAsyncRollouter pid=551476)[0m Filtering prompts longer than 2048 tokens (num_proc=1): 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 7473/7473 [00:06<00:00, 1280.50 examples/s]
[36m(FullyAsyncRollouter pid=551476)[0m Filtering prompts longer than 2048 tokens (num_proc=1): 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 7473/7473 [00:07<00:00, 1051.48 examples/s]
[36m(FullyAsyncRollouter pid=551476)[0m Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(FullyAsyncRollouter pid=551476)[0m Filtering prompts longer than 2048 tokens (num_proc=1):   0%|                                                                                                             | 0/1319 [00:00<?, ? examples/s]
[36m(FullyAsyncRollouter pid=551476)[0m Filtering prompts longer than 2048 tokens (num_proc=1):  76%|█████████████████████████████████████████████████████████████████████████▌                       | 1000/1319 [00:02<00:00, 473.32 examples/s]
[36m(FullyAsyncRollouter pid=551476)[0m Filtering prompts longer than 2048 tokens (num_proc=1): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1319/1319 [00:02<00:00, 594.47 examples/s]
[36m(FullyAsyncRollouter pid=551476)[0m Filtering prompts longer than 2048 tokens (num_proc=1): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1319/1319 [00:02<00:00, 530.29 examples/s]
[36m(FullyAsyncRollouter pid=551476)[0m Using blocking ray.get inside async actor. This blocks the event loop. Please use `await` on object ref with asyncio.gather if you want to yield execution to the event loop instead.
[36m(pid=552782)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=552782)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=552782)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=552782)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=552781)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:345: ImportWarning: 
[36m(pid=552781)[0m     *************************************************************************************************************
[36m(pid=552781)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(pid=552781)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(pid=552781)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(pid=552781)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(pid=552781)[0m     The device parameters have been replaced with npu in the function below:
[36m(pid=552781)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(pid=552781)[0m     *************************************************************************************************************
[36m(pid=552781)[0m     
[36m(pid=552781)[0m   warnings.warn(msg, ImportWarning)
[36m(pid=552781)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(pid=552781)[0m   warnings.warn(msg, RuntimeWarning)
[36m(pid=552782)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=552782)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")[32m [repeated 6x across cluster][0m
[36m(pid=552782)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.[32m [repeated 3x across cluster][0m
[36m(pid=552781)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(pid=552781)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(pid=552781)[0m   import pkg_resources
[36m(pid=552781)[0m /home/ma-user/work/verl/verl/workers/megatron_workers.py:54: UserWarning: NPU not support router replay for now.
[36m(pid=552781)[0m   from verl.utils.megatron.router_replay_patch import RouterReplay, RouterReplayAction, apply_router_replay_patch
[36m(pid=552781)[0m /home/ma-user/work/verl/verl/workers/actor/megatron_actor.py:44: UserWarning: NPU not support router replay for now.
[36m(pid=552781)[0m   from verl.utils.megatron.router_replay_utils import (
[36m(pid=552781)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/ray/util/state/util.py:55: DeprecationWarning: Ray state API is no longer experimental. Please import from `ray.util.state`. instead. Importing from `ray.experimental` will be deprecated in future releases. 
[36m(pid=552781)[0m   warnings.warn(
[36m(WorkerDict pid=552781)[0m [W106 00:18:04.495178670 compiler_depend.ts:1060] Warning: The watchdog timeout 600000ms(which is set by init_process_group) is less than or equal to HCCL execution timeout 1836000ms! The plog may not be recorded. (function ProcessGroupHCCL)
[36m(pid=552782)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(WorkerDict pid=552782)[0m /home/ma-user/work/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.
[36m(WorkerDict pid=552782)[0m   warnings.warn("Torch profiler tool config is not fully supported now.", stacklevel=1)
[36m(pid=552782)[0m /home/ma-user/work/verl/verl/workers/actor/megatron_actor.py:44: UserWarning: NPU not support router replay for now.[32m [repeated 2x across cluster][0m
[36m(pid=552782)[0m   from verl.utils.megatron.router_replay_patch import RouterReplay, RouterReplayAction, apply_router_replay_patch
[36m(pid=552782)[0m   from verl.utils.megatron.router_replay_utils import (
[36m(pid=552782)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/ray/util/state/util.py:55: DeprecationWarning: Ray state API is no longer experimental. Please import from `ray.util.state`. instead. Importing from `ray.experimental` will be deprecated in future releases. 
[36m(pid=552782)[0m   warnings.warn(
[36m(WorkerDict pid=552782)[0m <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute
[36m(WorkerDict pid=552782)[0m <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute
[36m(WorkerDict pid=552781)[0m /home/ma-user/work/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.
[36m(WorkerDict pid=552781)[0m   warnings.warn("Torch profiler tool config is not fully supported now.", stacklevel=1)
[36m(FullyAsyncRollouter pid=551476)[0m /home/ma-user/work/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.
[36m(FullyAsyncRollouter pid=551476)[0m   warnings.warn("Torch profiler tool config is not fully supported now.", stacklevel=1)
[36m(pid=553954)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=553954)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=553954)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=553954)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(FullyAsyncRollouter pid=551476)[0m <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute[32m [repeated 2x across cluster][0m
[36m(FullyAsyncRollouter pid=551476)[0m <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute[32m [repeated 2x across cluster][0m
[36m(pid=553954)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(pid=553954)[0m   import pkg_resources
[36m(pid=553955)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.[32m [repeated 3x across cluster][0m
[36m(pid=553955)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")[32m [repeated 6x across cluster][0m
[36m(pid=553955)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.[32m [repeated 3x across cluster][0m
[36m(pid=553954)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
[36m(pid=553954)[0m     *************************************************************************************************************
[36m(pid=553954)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(pid=553954)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(pid=553954)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(pid=553954)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(pid=553954)[0m     The device parameters have been replaced with npu in the function below:
[36m(pid=553954)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(pid=553954)[0m     *************************************************************************************************************
[36m(pid=553954)[0m     
[36m(pid=553954)[0m   warnings.warn(msg, ImportWarning)
[36m(pid=553954)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(pid=553954)[0m   warnings.warn(msg, RuntimeWarning)
[36m(pid=553955)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(pid=553955)[0m   import pkg_resources
[36m(pid=553954)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(pid=553955)[0m     
[36m(vLLMHttpServerForPartial pid=553954)[0m /home/ma-user/work/verl/verl/workers/megatron_workers.py:54: UserWarning: NPU not support router replay for now.
[36m(vLLMHttpServerForPartial pid=553954)[0m   from verl.utils.megatron.router_replay_patch import RouterReplay, RouterReplayAction, apply_router_replay_patch
[36m(vLLMHttpServerForPartial pid=553954)[0m /home/ma-user/work/verl/verl/workers/actor/megatron_actor.py:44: UserWarning: NPU not support router replay for now.
[36m(vLLMHttpServerForPartial pid=553954)[0m   from verl.utils.megatron.router_replay_utils import (
[36m(FullyAsyncTaskRunner pid=545998)[0m              'default_local_dir': 'checkpoints/GRPO-Qwen2.5-0.5b-Base-MATH/GRPO-Qwen2.5-0.5b-Base-MATH-2gpu-async',
[36m(FullyAsyncTaskRunner pid=545998)[0m              'del_local_ckpt_after_load': False,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'device': 'npu',
[36m(FullyAsyncTaskRunner pid=545998)[0m              'esi_redundant_time': 0,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'experiment_name': 'GRPO-Qwen2.5-0.5b-Base-MATH-2gpu-async',
[36m(FullyAsyncTaskRunner pid=545998)[0m              'log_val_generations': 10,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'logger': ['console', 'tensorboard'],
[36m(FullyAsyncTaskRunner pid=545998)[0m              'max_actor_ckpt_to_keep': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'max_critic_ckpt_to_keep': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'n_gpus_per_node': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'nnodes': 2,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'project_name': 'GRPO-Qwen2.5-0.5b-Base-MATH',
[36m(FullyAsyncTaskRunner pid=545998)[0m              'ray_wait_register_center_timeout': 300,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'resume_from_path': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'resume_mode': 'auto',
[36m(FullyAsyncTaskRunner pid=545998)[0m              'rollout_data_dir': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'save_freq': -1,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'test_freq': -1,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'total_epochs': 1,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'total_training_steps': None,
[36m(FullyAsyncTaskRunner pid=545998)[0m              'use_legacy_worker_impl': 'auto',
[36m(FullyAsyncTaskRunner pid=545998)[0m              'val_before_train': True},
[36m(FullyAsyncTaskRunner pid=545998)[0m  'transfer_queue': {'enable': False}}
[36m(FullyAsyncTaskRunner pid=545998)[0m [ASYNC MAIN] Initializing model and tokenizer...
[36m(FullyAsyncTaskRunner pid=545998)[0m [ASYNC MAIN] Creating worker mapping and resource pools...
[36m(FullyAsyncTaskRunner pid=545998)[0m [ASYNC MAIN] Creating FullyAsyncRollouter...
[36m(pid=551476)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:17:25,349 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter] Creating datasets...
[36m(FullyAsyncRollouter pid=551476)[0m Using dataset class: RLHFDataset
[36m(FullyAsyncRollouter pid=551476)[0m dataset len: 7473
[36m(FullyAsyncRollouter pid=551476)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:17:30,253 WARNING [datasets.arrow_dataset:3258] => Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(FullyAsyncRollouter pid=551476)[0m filter dataset len: 7473
[36m(FullyAsyncRollouter pid=551476)[0m Using dataset class: RLHFDataset
[36m(FullyAsyncRollouter pid=551476)[0m dataset len: 1319
[36m(FullyAsyncRollouter pid=551476)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:17:38,825 WARNING [datasets.arrow_dataset:3258] => Setting TOKENIZERS_PARALLELISM=false for forked processes.
[36m(FullyAsyncRollouter pid=551476)[0m filter dataset len: 1319
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter] Rollouter _create_dataloader...
[36m(FullyAsyncRollouter pid=551476)[0m <verl.utils.dataset.rl_dataset.RLHFDataset object at 0xffcf0b6f5330>
[36m(FullyAsyncRollouter pid=551476)[0m <verl.utils.dataset.rl_dataset.RLHFDataset object at 0xffcf0b6f5030>
[36m(FullyAsyncRollouter pid=551476)[0m Size of train dataloader: 7473, Size of val dataloader: 1
[36m(FullyAsyncRollouter pid=551476)[0m Total training steps: 7473
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter] Total rollout steps: 7473
[36m(FullyAsyncRollouter pid=551476)[0m colocated worker base class <class 'verl.workers.megatron_workers.MegatronWorker'>
[36m(FullyAsyncRollouter pid=551476)[0m bind role rollout method chat_completion to class <class 'verl.single_controller.ray.base.create_colocated_worker_cls.<locals>.WorkerDict'>
[36m(FullyAsyncRollouter pid=551476)[0m bind role rollout method generate to class <class 'verl.single_controller.ray.base.create_colocated_worker_cls.<locals>.WorkerDict'>
[36m(FullyAsyncRollouter pid=551476)[0m bind role rollout method get_zeromq_address to class <class 'verl.single_controller.ray.base.create_colocated_worker_cls.<locals>.WorkerDict'>
[36m(FullyAsyncRollouter pid=551476)[0m bind role rollout method sleep to class <class 'verl.single_controller.ray.base.create_colocated_worker_cls.<locals>.WorkerDict'>
[36m(FullyAsyncRollouter pid=551476)[0m bind role rollout method wake_up to class <class 'verl.single_controller.ray.base.create_colocated_worker_cls.<locals>.WorkerDict'>
[36m(pid=552781)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:17:57,896 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(WorkerDict pid=552781)[0m [DetachAsyncRolloutWorker] (<class 'recipe.fully_async_policy.megatron_worker.DetachAsyncRolloutWorker'>, <class 'recipe.fully_async_policy.megatron_worker.DetachNcclSync'>, <class 'verl.workers.megatron_workers.AsyncActorRolloutRefWorker'>, <class 'verl.workers.megatron_workers.ActorRolloutRefWorker'>, <class 'verl.workers.megatron_workers.MegatronWorker'>, <class 'verl.single_controller.base.worker.Worker'>, <class 'verl.single_controller.base.worker.WorkerHelper'>, <class 'verl.utils.profiler.profile.DistProfilerExtension'>, <class 'object'>)
[36m(WorkerDict pid=552782)[0m WARNING 01-06 00:18:11 [_custom_ops.py:20] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
[36m(pid=552782)[0m [Rank 1 | Local Rank 0] 2026-01-06 00:17:57,933 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(WorkerDict pid=552782)[0m [DetachAsyncRolloutWorker] (<class 'recipe.fully_async_policy.megatron_worker.DetachAsyncRolloutWorker'>, <class 'recipe.fully_async_policy.megatron_worker.DetachNcclSync'>, <class 'verl.workers.megatron_workers.AsyncActorRolloutRefWorker'>, <class 'verl.workers.megatron_workers.ActorRolloutRefWorker'>, <class 'verl.workers.megatron_workers.MegatronWorker'>, <class 'verl.single_controller.base.worker.Worker'>, <class 'verl.single_controller.base.worker.WorkerHelper'>, <class 'verl.utils.profiler.profile.DistProfilerExtension'>, <class 'object'>)
[36m(FullyAsyncRollouter pid=551476)[0m WARNING 01-06 00:18:15 [api_server.py:1213] LoRA dynamic loading & unloading is enabled in the API server. This should ONLY be used for local development!
[36m(pid=553954)[0m WARNING 01-06 00:18:32 [_custom_ops.py:20] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")[32m [repeated 3x across cluster][0m
[36m(pid=553954)[0m WARNING 01-06 00:18:34 [api_server.py:1213] LoRA dynamic loading & unloading is enabled in the API server. This should ONLY be used for local development!
[36m(pid=553954)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:18:34,742 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(vLLMHttpServerForPartial pid=553954)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:18:37,672 INFO [/home/ma-user/work/verl/verl/workers/rollout/vllm_rollout/vllm_async_server.py:217] => vLLMHttpServer, replica_rank: 0, master address: 172.16.0.134, master port: 41023, data parallel master port: 41777
[36m(vLLMHttpServerForPartial pid=553954)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:18:37,680 INFO [/home/ma-user/work/verl/verl/workers/rollout/vllm_rollout/vllm_async_server.py:257] => override_generation_config: {'temperature': 1.0, 'top_k': -1, 'top_p': 1.0, 'repetition_penalty': 1.0, 'max_new_tokens': 3072}
[36m(vLLMHttpServerForPartial pid=553954)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:18:37,680 INFO [/home/ma-user/work/verl/verl/workers/rollout/vllm_rollout/vllm_async_server.py:259] => enable_sleep_mode: True
[36m(vLLMHttpServerForPartial pid=553954)[0m ['serve',
[36m(vLLMHttpServerForPartial pid=553954)[0m Using blocking ray.get inside async actor. This blocks the event loop. Please use `await` on object ref with asyncio.gather if you want to yield execution to the event loop instead.
[36m(vLLMHttpServerForPartial pid=553954)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(vLLMHttpServerForPartial pid=553954)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(vLLMHttpServerForPartial pid=553954)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(vLLMHttpServerForPartial pid=553954)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(vLLMHttpServerForPartial pid=553954)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=553955)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
[36m(pid=553955)[0m     *************************************************************************************************************[32m [repeated 2x across cluster][0m
[36m(pid=553955)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(pid=553955)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(pid=553955)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(pid=553955)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(pid=553955)[0m     The device parameters have been replaced with npu in the function below:
[36m(pid=553955)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(pid=553955)[0m   warnings.warn(msg, ImportWarning)
[36m(pid=553955)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(pid=553955)[0m   warnings.warn(msg, RuntimeWarning)
[36m(pid=553955)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(vLLMHttpServerForPartial pid=553955)[0m /home/ma-user/work/verl/verl/workers/actor/megatron_actor.py:44: UserWarning: NPU not support router replay for now.[32m [repeated 2x across cluster][0m
[36m(vLLMHttpServerForPartial pid=553955)[0m   from verl.utils.megatron.router_replay_patch import RouterReplay, RouterReplayAction, apply_router_replay_patch
[36m(vLLMHttpServerForPartial pid=553955)[0m   from verl.utils.megatron.router_replay_utils import (
[36m(vLLMHttpServerForPartial pid=553955)[0m Using blocking ray.get inside async actor. This blocks the event loop. Please use `await` on object ref with asyncio.gather if you want to yield execution to the event loop instead.
[36m(vLLMHttpServerForPartial pid=553955)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(vLLMHttpServerForPartial pid=553954)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(vLLMHttpServerForPartial pid=553954)[0m   import pkg_resources
[36m(vLLMHttpServerForPartial pid=553955)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.[32m [repeated 3x across cluster][0m
[36m(vLLMHttpServerForPartial pid=553955)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")[32m [repeated 6x across cluster][0m
[36m(vLLMHttpServerForPartial pid=553955)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.[32m [repeated 3x across cluster][0m
[36m(vLLMHttpServerForPartial pid=553954)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
[36m(vLLMHttpServerForPartial pid=553954)[0m     *************************************************************************************************************
[36m(vLLMHttpServerForPartial pid=553954)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(vLLMHttpServerForPartial pid=553954)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(vLLMHttpServerForPartial pid=553954)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(vLLMHttpServerForPartial pid=553954)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(vLLMHttpServerForPartial pid=553954)[0m     The device parameters have been replaced with npu in the function below:
[36m(vLLMHttpServerForPartial pid=553954)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(vLLMHttpServerForPartial pid=553954)[0m     *************************************************************************************************************
[36m(vLLMHttpServerForPartial pid=553954)[0m     
[36m(vLLMHttpServerForPartial pid=553954)[0m   warnings.warn(msg, ImportWarning)
[36m(vLLMHttpServerForPartial pid=553954)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(vLLMHttpServerForPartial pid=553954)[0m   warnings.warn(msg, RuntimeWarning)
[36m(vLLMHttpServerForPartial pid=553955)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(vLLMHttpServerForPartial pid=553955)[0m   import pkg_resources
[36m(vLLMHttpServerForPartial pid=553954)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(vLLMHttpServerForPartial pid=553955)[0m     
[36m(vLLMHttpServerForPartial pid=553954)[0m  '/home/ma-user/work/models/Qwen2.5-0.5B-Instruct',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '--dtype',
[36m(vLLMHttpServerForPartial pid=553954)[0m  'bfloat16',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '--load_format',
[36m(vLLMHttpServerForPartial pid=553954)[0m  'dummy',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '--max_model_len',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '5120',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '--max_num_seqs',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '1024',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '--max_num_batched_tokens',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '5120',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '--enable_prefix_caching',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '--enable_sleep_mode',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '--disable_custom_all_reduce',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '--enforce_eager',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '--gpu_memory_utilization',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '0.7',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '--disable_log_stats',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '--tensor_parallel_size',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '1',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '--seed',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '0',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '--override_generation_config',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '{"temperature": 1.0, "top_k": -1, "top_p": 1.0, "repetition_penalty": 1.0, '
[36m(vLLMHttpServerForPartial pid=553954)[0m  '"max_new_tokens": 3072}',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '--hf_overrides',
[36m(vLLMHttpServerForPartial pid=553954)[0m  '{}']
[36m(vLLMHttpServerForPartial pid=553954)[0m WARNING 01-06 00:18:37 [registry.py:582] Model architecture Qwen2VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_vl:AscendQwen2VLForConditionalGeneration.
[36m(vLLMHttpServerForPartial pid=553954)[0m WARNING 01-06 00:18:37 [registry.py:582] Model architecture Qwen3VLMoeForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_5_vl_without_padding:AscendQwen3VLMoeForConditionalGeneration.
[36m(vLLMHttpServerForPartial pid=553954)[0m WARNING 01-06 00:18:37 [registry.py:582] Model architecture Qwen3VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_5_vl_without_padding:AscendQwen3VLForConditionalGeneration.
[36m(vLLMHttpServerForPartial pid=553954)[0m WARNING 01-06 00:18:37 [registry.py:582] Model architecture Qwen2_5_VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_5_vl:AscendQwen2_5_VLForConditionalGeneration.
[36m(vLLMHttpServerForPartial pid=553954)[0m WARNING 01-06 00:18:37 [registry.py:582] Model architecture Qwen2_5OmniModel is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_5_omni_thinker:AscendQwen2_5OmniThinkerForConditionalGeneration.
[36m(vLLMHttpServerForPartial pid=553954)[0m WARNING 01-06 00:18:37 [registry.py:582] Model architecture DeepseekV32ForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.deepseek_v3_2:CustomDeepseekV3ForCausalLM.
[36m(vLLMHttpServerForPartial pid=553954)[0m WARNING 01-06 00:18:37 [registry.py:582] Model architecture Qwen3NextForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen3_next:CustomQwen3NextForCausalLM.
[36m(vLLMHttpServerForPartial pid=553954)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:18:37,824 INFO [/home/ma-user/work/verl/verl/workers/rollout/vllm_rollout/vllm_async_server.py:389] => replica_rank=0, node_rank=0, nnodes=1, get worker zmq addresses: ['ipc:///tmp/verl_vllm_zmq_552781_ma-user.ipc']
[36m(vLLMHttpServerForPartial pid=553954)[0m WARNING 01-06 00:18:37 [platform.py:270] If chunked prefill or prefix caching is enabled, block size must be set to 128.
[36m(pid=553955)[0m WARNING 01-06 00:18:33 [_custom_ops.py:20] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
[36m(vLLMHttpServerForPartial pid=553954)[0m WARNING 01-06 00:18:38 [__init__.py:3036] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: In a Ray actor and can only be spawned
[36m(vLLMHttpServerForPartial pid=553954)[0m WARNING 01-06 00:18:54 [_custom_ops.py:20] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
[36m(pid=553955)[0m WARNING 01-06 00:18:34 [api_server.py:1213] LoRA dynamic loading & unloading is enabled in the API server. This should ONLY be used for local development!
[36m(pid=553955)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:18:34,973 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(vLLMHttpServerForPartial pid=553955)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:18:37,873 INFO [/home/ma-user/work/verl/verl/workers/rollout/vllm_rollout/vllm_async_server.py:217] => vLLMHttpServer, replica_rank: 1, master address: 172.16.0.134, master port: 33825, data parallel master port: 33905
[36m(vLLMHttpServerForPartial pid=553955)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:18:37,880 INFO [/home/ma-user/work/verl/verl/workers/rollout/vllm_rollout/vllm_async_server.py:257] => override_generation_config: {'temperature': 1.0, 'top_k': -1, 'top_p': 1.0, 'repetition_penalty': 1.0, 'max_new_tokens': 3072}
[36m(vLLMHttpServerForPartial pid=553955)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:18:37,880 INFO [/home/ma-user/work/verl/verl/workers/rollout/vllm_rollout/vllm_async_server.py:259] => enable_sleep_mode: True
[36m(vLLMHttpServerForPartial pid=553955)[0m WARNING 01-06 00:18:37 [registry.py:582] Model architecture Qwen3NextForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen3_next:CustomQwen3NextForCausalLM.[32m [repeated 7x across cluster][0m
[36m(vLLMHttpServerForPartial pid=553955)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:18:37,995 INFO [/home/ma-user/work/verl/verl/workers/rollout/vllm_rollout/vllm_async_server.py:389] => replica_rank=1, node_rank=0, nnodes=1, get worker zmq addresses: ['ipc:///tmp/verl_vllm_zmq_552782_ma-user.ipc']
[36m(vLLMHttpServerForPartial pid=553955)[0m WARNING 01-06 00:18:38 [platform.py:270] If chunked prefill or prefix caching is enabled, block size must be set to 128.
[36m(vLLMHttpServerForPartial pid=553955)[0m WARNING 01-06 00:18:38 [__init__.py:3036] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: In a Ray actor and can only be spawned
[36m(vLLMHttpServerForPartial pid=553954)[0m WARNING 01-06 00:18:56 [api_server.py:1213] LoRA dynamic loading & unloading is enabled in the API server. This should ONLY be used for local development!
[36m(vLLMHttpServerForPartial pid=553954)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:18:57,117 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(vLLMHttpServerForPartial pid=553955)[0m WARNING 01-06 00:18:54 [_custom_ops.py:20] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
[36m(WorkerDict pid=552782)[0m WARNING 01-06 00:18:59 [registry.py:582] Model architecture Qwen3NextForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen3_next:CustomQwen3NextForCausalLM.[32m [repeated 28x across cluster][0m
[36m(vLLMHttpServerForPartial pid=553955)[0m [1;36m(EngineCore_DP0 pid=554978)[0;0m /home/ma-user/.conda/envs/test01/lib/python3.10/contextlib.py:142: ResourceWarning: Unclosed context <zmq.Context() at 0xfffefa3e0450>
[36m(vLLMHttpServerForPartial pid=553955)[0m [1;36m(EngineCore_DP0 pid=554978)[0;0m   next(self.gen)
[36m(vLLMHttpServerForPartial pid=553955)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
[36m(vLLMHttpServerForPartial pid=553955)[0m     *************************************************************************************************************[32m [repeated 2x across cluster][0m
[36m(vLLMHttpServerForPartial pid=553955)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(vLLMHttpServerForPartial pid=553955)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(vLLMHttpServerForPartial pid=553955)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(vLLMHttpServerForPartial pid=553955)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(vLLMHttpServerForPartial pid=553955)[0m     The device parameters have been replaced with npu in the function below:
[36m(vLLMHttpServerForPartial pid=553955)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(vLLMHttpServerForPartial pid=553955)[0m   warnings.warn(msg, ImportWarning)
[36m(vLLMHttpServerForPartial pid=553955)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(vLLMHttpServerForPartial pid=553955)[0m   warnings.warn(msg, RuntimeWarning)
[36m(vLLMHttpServerForPartial pid=553955)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(vLLMHttpServerForPartial pid=553954)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/websockets/legacy/__init__.py:6: DeprecationWarning: websockets.legacy is deprecated; see https://websockets.readthedocs.io/en/stable/howto/upgrade.html for upgrade instructions
[36m(vLLMHttpServerForPartial pid=553954)[0m   warnings.warn(  # deprecated in 14.0 - 2024-11-09
[36m(vLLMHttpServerForPartial pid=553954)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/uvicorn/protocols/websockets/websockets_impl.py:17: DeprecationWarning: websockets.server.WebSocketServerProtocol is deprecated
[36m(vLLMHttpServerForPartial pid=553954)[0m   from websockets.server import WebSocketServerProtocol
[36m(vLLMHttpServerForPartial pid=553954)[0m /home/ma-user/work/verl/verl/workers/rollout/vllm_rollout/vllm_async_server.py:428: ResourceWarning: unclosed <socket.socket fd=76, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('172.16.0.134', 44053)>
[36m(vLLMHttpServerForPartial pid=553954)[0m   self._server_port, self._server_task = await run_unvicorn(app, args, self._server_address)
[36m(pid=555843)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=555843)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=555843)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=555843)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(vLLMHttpServerForPartial pid=553954)[0m [1;36m(EngineCore_DP0 pid=554962)[0;0m /home/ma-user/.conda/envs/test01/lib/python3.10/contextlib.py:142: ResourceWarning: Unclosed context <zmq.Context() at 0xffff041a0450>
[36m(vLLMHttpServerForPartial pid=553954)[0m [1;36m(EngineCore_DP0 pid=554962)[0;0m   next(self.gen)
[36m(vLLMHttpServerForPartial pid=553955)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/websockets/legacy/__init__.py:6: DeprecationWarning: websockets.legacy is deprecated; see https://websockets.readthedocs.io/en/stable/howto/upgrade.html for upgrade instructions
[36m(vLLMHttpServerForPartial pid=553955)[0m   warnings.warn(  # deprecated in 14.0 - 2024-11-09
[36m(vLLMHttpServerForPartial pid=553955)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/uvicorn/protocols/websockets/websockets_impl.py:17: DeprecationWarning: websockets.server.WebSocketServerProtocol is deprecated
[36m(vLLMHttpServerForPartial pid=553955)[0m   from websockets.server import WebSocketServerProtocol
[36m(vLLMHttpServerForPartial pid=553955)[0m /home/ma-user/work/verl/verl/workers/rollout/vllm_rollout/vllm_async_server.py:428: ResourceWarning: unclosed <socket.socket fd=76, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('172.16.0.134', 44825)>
[36m(vLLMHttpServerForPartial pid=553955)[0m   self._server_port, self._server_task = await run_unvicorn(app, args, self._server_address)
[36m(pid=555845)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
[36m(pid=555845)[0m     *************************************************************************************************************
[36m(pid=555845)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(pid=555845)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(pid=555845)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(pid=555845)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(pid=555845)[0m     The device parameters have been replaced with npu in the function below:
[36m(pid=555845)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(pid=555845)[0m     *************************************************************************************************************
[36m(pid=555845)[0m     
[36m(pid=555845)[0m   warnings.warn(msg, ImportWarning)
[36m(pid=555845)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(pid=555845)[0m   warnings.warn(msg, RuntimeWarning)
[36m(pid=555857)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.[32m [repeated 17x across cluster][0m
[36m(pid=555857)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")[32m [repeated 34x across cluster][0m
[36m(pid=555857)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.[32m [repeated 17x across cluster][0m
[36m(pid=555845)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(pid=555845)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(pid=555845)[0m   import pkg_resources
[36m(pid=555843)[0m     
[36m(pid=555847)[0m     
[36m(pid=555832)[0m     
[36m(pid=555849)[0m     
[36m(pid=555842)[0m     
[36m(pid=555853)[0m     
[36m(pid=555848)[0m     
[36m(pid=555857)[0m     
[36m(FullyAsyncTrainer pid=555857)[0m /home/ma-user/work/verl/verl/workers/megatron_workers.py:54: UserWarning: NPU not support router replay for now.
[36m(FullyAsyncTrainer pid=555857)[0m   from verl.utils.megatron.router_replay_patch import RouterReplay, RouterReplayAction, apply_router_replay_patch
[36m(FullyAsyncTrainer pid=555857)[0m /home/ma-user/work/verl/verl/workers/actor/megatron_actor.py:44: UserWarning: NPU not support router replay for now.
[36m(FullyAsyncTrainer pid=555857)[0m   from verl.utils.megatron.router_replay_utils import (
[36m(FullyAsyncTrainer pid=555857)[0m /home/ma-user/work/verl/recipe/fully_async_policy/fully_async_trainer.py:78: UserWarning: Disabled critic as algorithm.adv_estimator != gae. If it is not intended, please set critic.enable=True
[36m(FullyAsyncTrainer pid=555857)[0m   self.use_critic = need_critic(self.config)
[36m(pid=555845)[0m <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute
[36m(pid=555845)[0m <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute
[36m(pid=555857)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: [32m [repeated 8x across cluster][0m
[36m(pid=555857)[0m     *************************************************************************************************************[32m [repeated 16x across cluster][0m
[36m(pid=555857)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..[32m [repeated 8x across cluster][0m
[36m(pid=555857)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..[32m [repeated 8x across cluster][0m
[36m(pid=555857)[0m     The backend in torch.distributed.init_process_group set to hccl now..[32m [repeated 8x across cluster][0m
[36m(pid=555857)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..[32m [repeated 8x across cluster][0m
[36m(pid=555857)[0m     The device parameters have been replaced with npu in the function below:[32m [repeated 8x across cluster][0m
[36m(pid=555857)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty[32m [repeated 8x across cluster][0m
[36m(pid=555857)[0m   warnings.warn(msg, ImportWarning)[32m [repeated 8x across cluster][0m
[36m(pid=555857)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.[32m [repeated 8x across cluster][0m
[36m(pid=555857)[0m   warnings.warn(msg, RuntimeWarning)[32m [repeated 8x across cluster][0m
[36m(pid=555857)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...[32m [repeated 8x across cluster][0m
[36m(pid=555857)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.[32m [repeated 8x across cluster][0m
[36m(pid=555857)[0m   import pkg_resources[32m [repeated 8x across cluster][0m
[36m(pid=558093)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=558093)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=558093)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=558093)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=555848)[0m <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute[32m [repeated 7x across cluster][0m
[36m(pid=555848)[0m <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute[32m [repeated 7x across cluster][0m
[36m(pid=558304)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.[32m [repeated 13x across cluster][0m
[36m(pid=558304)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")[32m [repeated 26x across cluster][0m
[36m(pid=558304)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.[32m [repeated 13x across cluster][0m
[36m(pid=558093)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:345: ImportWarning: 
[36m(pid=558093)[0m     *************************************************************************************************************
[36m(pid=558093)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(pid=558093)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(pid=558093)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(pid=558093)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(pid=558093)[0m     The device parameters have been replaced with npu in the function below:
[36m(pid=558093)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(pid=558093)[0m     *************************************************************************************************************
[36m(pid=558093)[0m     
[36m(pid=558093)[0m   warnings.warn(msg, ImportWarning)
[36m(pid=558093)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(pid=558093)[0m   warnings.warn(msg, RuntimeWarning)
[36m(pid=558093)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(pid=558093)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(pid=558093)[0m   import pkg_resources
[36m(pid=558301)[0m     
[36m(pid=558402)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.[32m [repeated 6x across cluster][0m
[36m(pid=558402)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")[32m [repeated 12x across cluster][0m
[36m(pid=558402)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.[32m [repeated 6x across cluster][0m
[36m(pid=558093)[0m /home/ma-user/work/verl/verl/workers/megatron_workers.py:54: UserWarning: NPU not support router replay for now.
[36m(pid=558093)[0m   from verl.utils.megatron.router_replay_patch import RouterReplay, RouterReplayAction, apply_router_replay_patch
[36m(pid=558093)[0m /home/ma-user/work/verl/verl/workers/actor/megatron_actor.py:44: UserWarning: NPU not support router replay for now.
[36m(pid=558093)[0m   from verl.utils.megatron.router_replay_utils import (
[36m(pid=558304)[0m     
[36m(pid=558309)[0m     
[36m(pid=558093)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/ray/util/state/util.py:55: DeprecationWarning: Ray state API is no longer experimental. Please import from `ray.util.state`. instead. Importing from `ray.experimental` will be deprecated in future releases. 
[36m(pid=558093)[0m   warnings.warn(
[36m(pid=558312)[0m     
[36m(pid=558329)[0m     
[36m(pid=558307)[0m     
[36m(pid=558400)[0m     
[36m(pid=558400)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: [32m [repeated 7x across cluster][0m
[36m(pid=558400)[0m     *************************************************************************************************************[32m [repeated 14x across cluster][0m
[36m(pid=558400)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..[32m [repeated 7x across cluster][0m
[36m(pid=558400)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..[32m [repeated 7x across cluster][0m
[36m(pid=558400)[0m     The backend in torch.distributed.init_process_group set to hccl now..[32m [repeated 7x across cluster][0m
[36m(pid=558400)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..[32m [repeated 7x across cluster][0m
[36m(pid=558400)[0m     The device parameters have been replaced with npu in the function below:[32m [repeated 7x across cluster][0m
[36m(pid=558400)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty[32m [repeated 7x across cluster][0m
[36m(pid=558400)[0m   warnings.warn(msg, ImportWarning)[32m [repeated 7x across cluster][0m
[36m(pid=558400)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.[32m [repeated 7x across cluster][0m
[36m(pid=558400)[0m   warnings.warn(msg, RuntimeWarning)[32m [repeated 7x across cluster][0m
[36m(pid=558402)[0m     
[36m(WorkerDict pid=558093)[0m [W106 00:19:52.696789337 compiler_depend.ts:1060] Warning: The watchdog timeout 600000ms(which is set by init_process_group) is less than or equal to HCCL execution timeout 1836000ms! The plog may not be recorded. (function ProcessGroupHCCL)
[36m(pid=558402)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...[32m [repeated 9x across cluster][0m
[36m(pid=558402)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.[32m [repeated 8x across cluster][0m
[36m(pid=558402)[0m   import pkg_resources[32m [repeated 8x across cluster][0m
[36m(WorkerDict pid=558093)[0m /home/ma-user/work/verl/verl/models/mcore/config_converter.py:182: UserWarning: The following keys are not supported in the current Megatron version and will be removed: ['use_flash_attn']
[36m(WorkerDict pid=558093)[0m   return check_and_construct_configs(args, TransformerConfig)
[36m(pid=558094)[0m /home/ma-user/work/verl/verl/workers/actor/megatron_actor.py:44: UserWarning: NPU not support router replay for now.[32m [repeated 2x across cluster][0m
[36m(pid=558094)[0m   from verl.utils.megatron.router_replay_patch import RouterReplay, RouterReplayAction, apply_router_replay_patch
[36m(pid=558094)[0m   from verl.utils.megatron.router_replay_utils import (
[36m(pid=558094)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/ray/util/state/util.py:55: DeprecationWarning: Ray state API is no longer experimental. Please import from `ray.util.state`. instead. Importing from `ray.experimental` will be deprecated in future releases. 
[36m(pid=558094)[0m   warnings.warn(
[36m(pid=558402)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
[36m(pid=558402)[0m     *************************************************************************************************************[32m [repeated 2x across cluster][0m
[36m(pid=558402)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(pid=558402)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(pid=558402)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(pid=558402)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(pid=558402)[0m     The device parameters have been replaced with npu in the function below:
[36m(pid=558402)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(pid=558402)[0m   warnings.warn(msg, ImportWarning)
[36m(pid=558402)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(pid=558402)[0m   warnings.warn(msg, RuntimeWarning)
[36m(WorkerDict pid=552782)[0m WARNING 01-06 00:19:03 [cudagraph_dispatcher.py:106] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[36m(WorkerDict pid=552782)[0m WARNING 01-06 00:18:59 [api_server.py:1213] LoRA dynamic loading & unloading is enabled in the API server. This should ONLY be used for local development![32m [repeated 3x across cluster][0m
[36m(vLLMHttpServerForPartial pid=553955)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:18:57,660 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(vLLMHttpServerForPartial pid=553955)[0m [1;36m(EngineCore_DP0 pid=554978)[0;0m WARNING 01-06 00:19:07 [platform.py:270] If chunked prefill or prefix caching is enabled, block size must be set to 128.
[36m(vLLMHttpServerForPartial pid=553954)[0m WARNING 01-06 00:19:07 [model.py:1389] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
[36m(vLLMHttpServerForPartial pid=553954)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:19:07,916 INFO [/home/ma-user/work/verl/verl/workers/rollout/vllm_rollout/vllm_async_server.py:425] => Initializing a V1 LLM engine with config: model='/home/ma-user/work/models/Qwen2.5-0.5B-Instruct', speculative_config=None, tokenizer='/home/ma-user/work/models/Qwen2.5-0.5B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=5120, download_dir=None, load_format=dummy, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=npu, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/home/ma-user/work/models/Qwen2.5-0.5B-Instruct, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":["all"],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[36m(FullyAsyncRollouter pid=551476)[0m AgentLoopManager: ['172.16.0.134:44053', '172.16.0.134:44825']
[36m(vLLMHttpServerForPartial pid=553954)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:19:08,491 INFO [/home/ma-user/work/verl/verl/workers/rollout/utils.py:67] => HTTP server started on port 44053
[36m(FullyAsyncTaskRunner pid=545998)[0m [ASYNC MAIN] Rollouter created and initialized successfully
[36m(FullyAsyncTaskRunner pid=545998)[0m [ASYNC MAIN] Creating FullyAsyncTrainer...
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter] required_samples : 64 max_required_samples: 307 max_queue_size: 307 total_train_steps: 29 total_rollout_steps: 7473 max_concurrent_samples: 256 
[36m(pid=555845)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:19:24,365 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(WorkerDict pid=552781)[0m WARNING 01-06 00:19:04 [cudagraph_dispatcher.py:106] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[36m(vLLMHttpServerForPartial pid=553954)[0m [1;36m(EngineCore_DP0 pid=554962)[0;0m WARNING 01-06 00:19:07 [platform.py:270] If chunked prefill or prefix caching is enabled, block size must be set to 128.
[36m(vLLMHttpServerForPartial pid=553955)[0m WARNING 01-06 00:19:07 [model.py:1389] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
[36m(vLLMHttpServerForPartial pid=553955)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:19:08,489 INFO [/home/ma-user/work/verl/verl/workers/rollout/utils.py:67] => HTTP server started on port 44825
[36m(FullyAsyncTrainer pid=555857)[0m colocated worker base class <class 'verl.workers.megatron_workers.MegatronWorker'>
[36m(pid=555845)[0m WARNING 01-06 00:19:29 [_custom_ops.py:20] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
[36m(pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:19:25,769 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.[32m [repeated 8x across cluster][0m
[36m(pid=555845)[0m WARNING 01-06 00:19:30 [api_server.py:1213] LoRA dynamic loading & unloading is enabled in the API server. This should ONLY be used for local development!
[36m(pid=555848)[0m WARNING 01-06 00:19:31 [_custom_ops.py:20] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")[32m [repeated 7x across cluster][0m
[36m(pid=558093)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:19:44,481 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(pid=555848)[0m WARNING 01-06 00:19:32 [api_server.py:1213] LoRA dynamic loading & unloading is enabled in the API server. This should ONLY be used for local development![32m [repeated 7x across cluster][0m
[36m(pid=558094)[0m [Rank 1 | Local Rank 0] 2026-01-06 00:19:44,750 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(WorkerDict pid=558093)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=558093)[0m   "architectures": [
[36m(WorkerDict pid=558093)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=558093)[0m   ],
[36m(WorkerDict pid=558093)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=558093)[0m   "dtype": "bfloat16",
[36m(WorkerDict pid=558093)[0m   "eos_token_id": 151645,
[36m(WorkerDict pid=558093)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=558093)[0m   "hidden_size": 896,
[36m(WorkerDict pid=558093)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=558093)[0m   "intermediate_size": 4864,
[36m(WorkerDict pid=558093)[0m   "layer_types": [
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention"
[36m(WorkerDict pid=558093)[0m   ],
[36m(WorkerDict pid=558093)[0m   "max_position_embeddings": 5120,
[36m(WorkerDict pid=558093)[0m   "max_window_layers": 21,
[36m(WorkerDict pid=558093)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=558093)[0m   "num_attention_heads": 14,
[36m(WorkerDict pid=558093)[0m   "num_hidden_layers": 24,
[36m(WorkerDict pid=558093)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=558093)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=558093)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=558093)[0m   "rope_scaling": null,
[36m(WorkerDict pid=558093)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=558093)[0m   "sliding_window": null,
[36m(WorkerDict pid=558093)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=558093)[0m   "transformers_version": "4.57.3",
[36m(WorkerDict pid=558093)[0m   "use_cache": true,
[36m(WorkerDict pid=558093)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=558093)[0m   "vocab_size": 151936
[36m(WorkerDict pid=558093)[0m }
[36m(WorkerDict pid=558093)[0m 
[36m(WorkerDict pid=558093)[0m Overridden TransformerConfig init config: {'num_layers': 24, 'hidden_size': 896, 'num_attention_heads': 14, 'num_query_groups': 2, 'ffn_hidden_size': 4864, 'attention_dropout': 0.0, 'hidden_dropout': 0.0, 'kv_channels': None, 'layernorm_epsilon': 1e-06, 'add_bias_linear': False, 'activation_func': <function silu at 0xffff99489090>, 'normalization': 'RMSNorm', 'gated_linear_unit': True, 'pipeline_dtype': torch.bfloat16, 'params_dtype': torch.bfloat16, 'bf16': True, 'tensor_model_parallel_size': 1, 'pipeline_model_parallel_size': 1, 'expert_model_parallel_size': 1, 'expert_tensor_parallel_size': 1, 'virtual_pipeline_model_parallel_size': None, 'context_parallel_size': 1, 'overlap_p2p_comm': False, 'batch_p2p_comm': False, 'sequence_parallel': False, 'variable_seq_lengths': True, 'masked_softmax_fusion': True, 'moe_token_dispatcher_type': 'alltoall', 'use_cpu_initialization': False, 'add_qkv_bias': True, 'qk_layernorm': False, 'recompute_granularity': None, 'recompute_modules': ['core_attn'], 'recompute_method': None, 'recompute_num_layers': None, 'attention_backend': <AttnBackend.flash: 1>, 'apply_rope_fusion': True, 'bias_activation_fusion': True, 'bias_dropout_fusion': True, 'gradient_accumulation_fusion': True, 'deallocate_pipeline_outputs': True, 'persist_layer_norm': True}
[36m(WorkerDict pid=558093)[0m TF config: TransformerConfig(tensor_model_parallel_size=1, pipeline_model_parallel_comm_backend=None, pipeline_model_parallel_size=1, virtual_pipeline_model_parallel_size=None, sequence_parallel=False, context_parallel_size=1, hierarchical_context_parallel_sizes=None, expert_model_parallel_size=1, expert_tensor_parallel_size=1, moe_extended_tp=False, perform_initialization=True, use_cpu_initialization=False, fp16=False, bf16=True, params_dtype=torch.bfloat16, timers=None, finalize_model_grads_func=None, grad_scale_func=None, no_sync_func=None, grad_sync_func=None, param_sync_func=None, deterministic_mode=False, enable_autocast=False, autocast_dtype=torch.bfloat16, num_microbatches_with_partial_activation_checkpoints=None, gradient_accumulation_fusion=True, async_tensor_model_parallel_allreduce=False, use_te_rng_tracker=False, tp_comm_overlap=False, tp_comm_bulk_wgrad=True, tp_comm_bulk_dgrad=True, tp_comm_overlap_ag=True, tp_comm_overlap_rs=True, tp_comm_overlap_rs_dgrad=False, tp_comm_split_ag=True, tp_comm_atomic_ag=False, tp_comm_split_rs=True, tp_comm_atomic_rs=False, cross_entropy_loss_fusion=False, cross_entropy_fusion_impl='native', tp_comm_overlap_disable_qkv=False, tp_comm_overlap_disable_fc1=False, tp_comm_bootstrap_backend='nccl', pipeline_dtype=torch.bfloat16, variable_seq_lengths=True, overlap_p2p_comm=False, batch_p2p_comm=False, batch_p2p_sync=True, use_ring_exchange_p2p=False, deallocate_pipeline_outputs=True, defer_embedding_wgrad_compute=False, wgrad_deferral_limit=0, pipeline_model_parallel_split_rank=None, overlap_p2p_comm_warmup_flush=False, microbatch_group_size_per_vp_stage=1, cpu_offloading=False, cpu_offloading_num_layers=0, _cpu_offloading_context=None, cpu_offloading_activations=True, cpu_offloading_weights=True, barrier_with_L1_time=True, num_layers=24, mtp_num_layers=None, mtp_loss_scaling_factor=None, num_layers_in_first_pipeline_stage=None, num_layers_in_last_pipeline_stage=None, account_for_embedding_in_pipeline_split=False, account_for_loss_in_pipeline_split=False, hidden_size=896, num_attention_heads=14, attention_backend=<AttnBackend.flash: 1>, softmax_scale=None, num_query_groups=2, ffn_hidden_size=4864, kv_channels=64, hidden_dropout=0.0, attention_dropout=0.0, fp32_residual_connection=False, apply_residual_connection_post_layernorm=False, layernorm_epsilon=1e-06, layernorm_zero_centered_gamma=False, add_bias_linear=False, add_qkv_bias=True, gated_linear_unit=True, activation_func=<function silu at 0xffff99489090>, activation_func_fp8_input_store=False, num_moe_experts=None, rotary_interleaved=False, window_size=None, normalization='RMSNorm', qk_layernorm=False, test_mode=False, calculate_per_token_loss=False, multi_latent_attention=False, init_method=functools.partial(<function normal_ at 0xffff20391cf0>, mean=0.0, std=0.02), output_layer_init_method=functools.partial(<function normal_ at 0xffff20391cf0>, mean=0.0, std=0.002886751345948129), init_method_std=0.02, init_model_with_meta_device=False, apply_query_key_layer_scaling=False, attention_softmax_in_fp32=True, disable_bf16_reduced_precision_matmul=False, bias_activation_fusion=True, masked_softmax_fusion=True, persist_layer_norm=True, memory_efficient_layer_norm=False, bias_dropout_fusion=True, apply_rope_fusion=True, recompute_granularity=None, recompute_method=None, recompute_num_layers=None, distribute_saved_activations=None, recompute_modules=['core_attn'], fp8=None, fp8_recipe='delayed', fp8_param=False, fp8_margin=0, fp8_interval=1, fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', fp8_wgrad=True, fp8_dot_product_attention=False, fp8_multi_head_attention=False, tp_only_amax_red=False, first_last_layers_bf16=False, num_layers_at_start_in_bf16=1, num_layers_at_end_in_bf16=1, moe_shared_expert_intermediate_size=None, moe_shared_expert_overlap=False, moe_layer_freq=1, moe_ffn_hidden_size=4864, moe_router_load_balancing_type='aux_loss', moe_router_topk=2, moe_router_topk_limited_devices=None, moe_router_num_groups=None, moe_router_group_topk=None, moe_router_pre_softmax=False, moe_router_topk_scaling_factor=None, moe_router_score_function='softmax', moe_router_dtype=None, moe_router_enable_expert_bias=False, moe_router_bias_update_rate=0.001, moe_grouped_gemm=False, moe_use_legacy_grouped_gemm=False, moe_aux_loss_coeff=0, moe_z_loss_coeff=None, moe_input_jitter_eps=None, moe_token_dropping=False, moe_token_dispatcher_type='alltoall', moe_enable_deepep=False, moe_per_layer_logging=False, moe_expert_capacity_factor=None, moe_pad_expert_input_to_capacity=False, moe_token_drop_policy='probs', moe_layer_recompute=False, moe_permute_fusion=False, moe_apply_probs_on_input=False, cp_comm_type=None, enable_cuda_graph=False, cuda_graph_use_single_mempool=False, cuda_graph_retain_backward_graph=False, cuda_graph_warmup_steps=3, external_cuda_graph=False, cuda_graph_scope='full', clone_scatter_output_in_embedding=True, disable_parameter_transpose_cache=False, config_logger_dir='', flash_decode=False, inference_rng_tracker=False, mrope_section=None, is_hybrid_model=False, mamba_state_dim=128, mamba_head_dim=64, mamba_num_groups=8, heterogeneous_block_specs=False, optimizer_selection='fused_adamw', optimization_level=2, use_fused_rmsnorm=False, use_fused_swiglu=False, use_gmm_fp8=True, te_comparison_with_cpu=False, te_comparison_with_bf16=False, context_parallel_algo='megatron_cp_algo', cp_window_size=1, attention_mask_type='causal', use_cp_send_recv_overlap=False, use_fused_ring_attention_update=False, megatron_cp_in_bnsd=False, ulysses_degree_in_cp=None, context_parallel_kv_cache_policy=None, context_parallel_cache_interval=0, use_ulysses_allgather_kv=False, attention_mask_on_cpu=False, adaptive_cp_without_coarse=False, adaptive_cp_dynamic_attn_mask=False, adaptive_cp_only_reschedule=False, adaptive_cp_manually_set_mask_list=False, async_log_allreduce=False, use_fused_rotary_pos_emb=False, use_fused_moe_token_permute_and_unpermute=False, npu_deterministic=False, op_cal_tflops=False, profile_level='level0', profile_with_cpu=False, profile_with_stack=False, profile_with_memory=False, profile_record_shapes=False, profile_save_path='./profile_dir', recompute_activation_function=False, recompute_activation_function_num_layers=None, recompute_norm=False, recompute_norm_num_layers=None, enable_recompute_layers_per_pp_rank=False, unaligned_linear=False, use_ascend_mc2=False, use_ascend_coc=False, coc_mode=-1, coc_parallel_num=1, coc_fused_kernel=False, tp_2d=False, tp_x=1, tp_y=1, enable_overlap_ag_with_matmul=False, enable_overlap_matmul_with_rs=False, enable_backward_overlap_ag_with_matmul=False, recompute_in_bubble=False, recompute_in_advance=False, noop_layers=None, use_multiparameter_pipeline_model_parallel=False, optimize_send_recv_comm=False, pipeline_num_transformer_layers=None, schedules_method=None, dualpipev_dw_detach=False, gemm_gradient_accumulation_fusion=False, moe_tp_extend_ep=False, moe_permutation_async_comm=False, n_shared_experts=None, moe_allgather_overlap_comm=False, moe_alltoall_overlap_comm=False, moe_zero_memory='disable', moe_zero_memory_num_layers=None, moe_fb_overlap=False, moe_unperm2_mem_optim_swap=False, balanced_moe_experts=False, balanced_moe_hot_expert_num=3, trans_hot_expert_group_num=4, enable_expert_placement=False, expert_placement_freq=50, enable_fine_grained_expert_placement=False, print_expert_load=False, fine_grained_expert_placement_thre=0.08, hccl_group_buffer=None, hccl_group_buffer_adaptive=False, hccl_ep_group_buffer_adaptive_factor=-1.0, ema_decay=0.9999, virtual_optimizer=None, quant_states=None, quant_grads=False, dist_train=False, tokenizer_name_or_path=None, tokenizer_not_use_fast=True, param_and_grad_buffer_pad=None, layerzero=False, layerzero_config=None, fsdp2_config_path=None, reset_bucket_group_order=False, reuse_fp32_param=False, smart_swap=False, swap_attention=False, swap_modules='input_norm,self_attention,post_attention_norm', compress_dense='disable', disable_gloo_group=False, hccl_slice_size=10485760, swap_optimizer=False, swap_optimizer_times=16, pre_tockens=65536, next_tockens=0, sparse_mode=0, use_fusion_attn_v2=False, square_alibi_mask=False, fill_neg_inf=False, alibi_fusion_attn_type=None, alibi_diagonal_opposite=False, multi_head_latent_attention=False, qk_rope_head_dim=None, qk_nope_head_dim=None, ai_framework='pytorch', auto_settings=False, auto_settings_work_dir='/home/ma-user/work/verl', auto_settings_ranks=8, auto_settings_log_level='info', target_nnodes=1, nnodes=1, nproc_per_node=1, node_rank=0, auto_settings_type='white', prof_file=None, master_addr='127.0.0.1', master_port=29500, automated_pipeline=False, automated_pipeline_perf=False, recompute_module_list=None, jit_compile=False, node_ip_address='172.16.0.134', node_manager_port='37775', object_store_name='/tmp/ray/session_2026-01-06_00-16-38_348629_537872/sockets/plasma_store', raylet_name='/tmp/ray/session_2026-01-06_00-16-38_348629_537872/sockets/raylet', redis_address='None', metrics_agent_port='40808', logging_rotate_bytes='536870912', logging_rotate_backup_count='5', runtime_env_agent_port='60354', gcs_address='172.16.0.134:63965', session_name='session_2026-01-06_00-16-38_348629_537872', temp_dir='/tmp/ray', webui='127.0.0.1:8265', cluster_id='8bb71ebab51e5be621315fd2401efe6354f0b4a381c0513ce2d8f9a4', startup_token='113', worker_launch_time_ms='1767629969316', node_id='508e57c33c8c9d9025124c7d81a774571b7e4fdcb57d8007605d5d43', runtime_env_hash='1276635623', quant_states_enabled=False, quant_grads_dtype=None, use_quant_optimizer=False, use_flash_attn=True)[36m(WorkerDict pid=558093)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=558094)[0m Some weights of Qwen2ForCausalLM were not initialized from the model checkpoint at /home/ma-user/work/models/Qwen2.5-0.5B-Instruct and are newly initialized: ['lm_head.weight']
[36m(WorkerDict pid=558094)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=558094)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=558094)[0m   warnings.warn(  # warn only once

[36m(pid=558402)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:19:49,211 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.[32m [repeated 8x across cluster][0m
[36m(WorkerDict pid=558093)[0m  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 494032768
[36m(WorkerDict pid=558094)[0m load ref weight start
[36m(WorkerDict pid=558093)[0m load from local dir /home/ma-user/work/models/Qwen2.5-0.5B-Instruct
[36m(WorkerDict pid=558093)[0m loading embeddings...
[36m(WorkerDict pid=558093)[0m loading layer #0, with layer_name model.layers.0...
[36m(WorkerDict pid=558093)[0m loading layer #1, with layer_name model.layers.1...
[36m(WorkerDict pid=558093)[0m loading layer #2, with layer_name model.layers.2...
[36m(WorkerDict pid=558093)[0m loading layer #3, with layer_name model.layers.3...
[36m(WorkerDict pid=558093)[0m loading layer #4, with layer_name model.layers.4...
[36m(WorkerDict pid=558093)[0m loading layer #5, with layer_name model.layers.5...
[36m(WorkerDict pid=558093)[0m loading layer #6, with layer_name model.layers.6...
[36m(WorkerDict pid=558093)[0m loading layer #7, with layer_name model.layers.7...
[36m(WorkerDict pid=558093)[0m loading layer #8, with layer_name model.layers.8...
[36m(WorkerDict pid=558093)[0m loading layer #9, with layer_name model.layers.9...
[36m(WorkerDict pid=558093)[0m loading layer #10, with layer_name model.layers.10...
[36m(WorkerDict pid=558093)[0m loading layer #11, with layer_name model.layers.11...
[36m(WorkerDict pid=558093)[0m loading layer #12, with layer_name model.layers.12...
[36m(WorkerDict pid=558093)[0m loading layer #13, with layer_name model.layers.13...
[36m(WorkerDict pid=558093)[0m loading layer #14, with layer_name model.layers.14...
[36m(WorkerDict pid=558093)[0m loading layer #15, with layer_name model.layers.15...
[36m(WorkerDict pid=558093)[0m loading layer #16, with layer_name model.layers.16...
[36m(WorkerDict pid=558093)[0m loading layer #17, with layer_name model.layers.17...
[36m(WorkerDict pid=558093)[0m loading layer #18, with layer_name model.layers.18...
[36m(WorkerDict pid=558093)[0m loading layer #19, with layer_name model.layers.19...
[36m(WorkerDict pid=558093)[0m loading layer #20, with layer_name model.layers.20...
[36m(WorkerDict pid=558093)[0m loading layer #21, with layer_name model.layers.21...
[36m(WorkerDict pid=558093)[0m loading layer #22, with layer_name model.layers.22...
[36m(WorkerDict pid=558093)[0m loading layer #23, with layer_name model.layers.23...
[36m(WorkerDict pid=558093)[0m loading final layernorm...
[36m(WorkerDict pid=558093)[0m loading lm_head...
[36m(WorkerDict pid=558093)[0m loading megatron ckpt done, time elapsed 4.494704723358154s
[36m(WorkerDict pid=558093)[0m load ref weight start
[36m(WorkerDict pid=558094)[0m [Warining] Because actor tp size == 1, set sp to False
[36m(WorkerDict pid=558094)[0m TransformerConfig(tensor_model_parallel_size=1, pipeline_model_parallel_comm_backend=None, pipeline_model_parallel_size=1, virtual_pipeline_model_parallel_size=None, sequence_parallel=False, context_parallel_size=1, hierarchical_context_parallel_sizes=None, expert_model_parallel_size=1, expert_tensor_parallel_size=1, moe_extended_tp=False, perform_initialization=True, use_cpu_initialization=False, fp16=False, bf16=True, params_dtype=torch.bfloat16, timers=None, finalize_model_grads_func=None, grad_scale_func=None, no_sync_func=None, grad_sync_func=None, param_sync_func=None, deterministic_mode=False, enable_autocast=False, autocast_dtype=torch.bfloat16, num_microbatches_with_partial_activation_checkpoints=None, gradient_accumulation_fusion=True, async_tensor_model_parallel_allreduce=False, use_te_rng_tracker=False, tp_comm_overlap=False, tp_comm_bulk_wgrad=True, tp_comm_bulk_dgrad=True, tp_comm_overlap_ag=True, tp_comm_overlap_rs=True, tp_comm_overlap_rs_dgrad=False, tp_comm_split_ag=True, tp_comm_atomic_ag=False, tp_comm_split_rs=True, tp_comm_atomic_rs=False, cross_entropy_loss_fusion=False, cross_entropy_fusion_impl='native', tp_comm_overlap_disable_qkv=False, tp_comm_overlap_disable_fc1=False, tp_comm_bootstrap_backend='nccl', pipeline_dtype=torch.bfloat16, variable_seq_lengths=True, overlap_p2p_comm=False, batch_p2p_comm=False, batch_p2p_sync=True, use_ring_exchange_p2p=False, deallocate_pipeline_outputs=True, defer_embedding_wgrad_compute=False, wgrad_deferral_limit=0, pipeline_model_parallel_split_rank=None, overlap_p2p_comm_warmup_flush=False, microbatch_group_size_per_vp_stage=1, cpu_offloading=False, cpu_offloading_num_layers=0, _cpu_offloading_context=None, cpu_offloading_activations=True, cpu_offloading_weights=True, barrier_with_L1_time=True, num_layers=24, mtp_num_layers=None, mtp_loss_scaling_factor=None, num_layers_in_first_pipeline_stage=None, num_layers_in_last_pipeline_stage=None, account_for_embedding_in_pipeline_split=False, account_for_loss_in_pipeline_split=False, hidden_size=896, num_attention_heads=14, attention_backend=<AttnBackend.flash: 1>, softmax_scale=None, num_query_groups=2, ffn_hidden_size=4864, kv_channels=64, hidden_dropout=0.0, attention_dropout=0.0, fp32_residual_connection=False, apply_residual_connection_post_layernorm=False, layernorm_epsilon=1e-06, layernorm_zero_centered_gamma=False, add_bias_linear=False, add_qkv_bias=True, gated_linear_unit=True, activation_func=<function silu at 0xffff2c115090>, activation_func_fp8_input_store=False, num_moe_experts=None, rotary_interleaved=False, window_size=None, normalization='RMSNorm', qk_layernorm=False, test_mode=False, calculate_per_token_loss=False, multi_latent_attention=False, init_method=functools.partial(<function normal_ at 0xffff2c19dcf0>, mean=0.0, std=0.02), output_layer_init_method=functools.partial(<function normal_ at 0xffff2c19dcf0>, mean=0.0, std=0.002886751345948129), init_method_std=0.02, init_model_with_meta_device=False, apply_query_key_layer_scaling=False, attention_softmax_in_fp32=True, disable_bf16_reduced_precision_matmul=False, bias_activation_fusion=True, masked_softmax_fusion=True, persist_layer_norm=True, memory_efficient_layer_norm=False, bias_dropout_fusion=True, apply_rope_fusion=True, recompute_granularity=None, recompute_method=None, recompute_num_layers=None, distribute_saved_activations=None, recompute_modules=['core_attn'], fp8=None, fp8_recipe='delayed', fp8_param=False, fp8_margin=0, fp8_interval=1, fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', fp8_wgrad=True, fp8_dot_product_attention=False, fp8_multi_head_attention=False, tp_only_amax_red=False, first_last_layers_bf16=False, num_layers_at_start_in_bf16=1, num_layers_at_end_in_bf16=1, moe_shared_expert_intermediate_size=None, moe_shared_expert_overlap=False, moe_layer_freq=1, moe_ffn_hidden_size=4864, moe_router_load_balancing_type='aux_loss', moe_router_topk=2, moe_router_topk_limited_devices=None, moe_router_num_groups=None, moe_router_group_topk=None, moe_router_pre_softmax=False, moe_router_topk_scaling_factor=None, moe_router_score_function='softmax', moe_router_dtype=None, moe_router_enable_expert_bias=False, moe_router_bias_update_rate=0.001, moe_grouped_gemm=False, moe_use_legacy_grouped_gemm=False, moe_aux_loss_coeff=0, moe_z_loss_coeff=None, moe_input_jitter_eps=None, moe_token_dropping=False, moe_token_dispatcher_type='alltoall', moe_enable_deepep=False, moe_per_layer_logging=False, moe_expert_capacity_factor=None, moe_pad_expert_input_to_capacity=False, moe_token_drop_policy='probs', moe_layer_recompute=False, moe_permute_fusion=False, moe_apply_probs_on_input=False, cp_comm_type=None, enable_cuda_graph=False, cuda_graph_use_single_mempool=False, cuda_graph_retain_backward_graph=False, cuda_graph_warmup_steps=3, external_cuda_graph=False, cuda_graph_scope='full', clone_scatter_output_in_embedding=True, disable_parameter_transpose_cache=False, config_logger_dir='', flash_decode=False, inference_rng_tracker=False, mrope_section=None, is_hybrid_model=False, mamba_state_dim=128, mamba_head_dim=64, mamba_num_groups=8, heterogeneous_block_specs=False, optimizer_selection='fused_adamw', optimization_level=2, use_fused_rmsnorm=True, use_fused_swiglu=False, use_gmm_fp8=True, te_comparison_with_cpu=False, te_comparison_with_bf16=False, context_parallel_algo='megatron_cp_algo', cp_window_size=1, attention_mask_type='causal', use_cp_send_recv_overlap=False, use_fused_ring_attention_update=False, megatron_cp_in_bnsd=False, ulysses_degree_in_cp=None, context_parallel_kv_cache_policy=None, context_parallel_cache_interval=0, use_ulysses_allgather_kv=False, attention_mask_on_cpu=False, adaptive_cp_without_coarse=False, adaptive_cp_dynamic_attn_mask=False, adaptive_cp_only_reschedule=False, adaptive_cp_manually_set_mask_list=False, async_log_allreduce=False, use_fused_rotary_pos_emb=False, use_fused_moe_token_permute_and_unpermute=False, npu_deterministic=False, op_cal_tflops=False, profile_level='level0', profile_with_cpu=False, profile_with_stack=False, profile_with_memory=False, profile_record_shapes=False, profile_save_path='./profile_dir', recompute_activation_function=False, recompute_activation_function_num_layers=None, recompute_norm=False, recompute_norm_num_layers=None, enable_recompute_layers_per_pp_rank=False, unaligned_linear=False, use_ascend_mc2=False, use_ascend_coc=False, coc_mode=-1, coc_parallel_num=1, coc_fused_kernel=False, tp_2d=False, tp_x=1, tp_y=1, enable_overlap_ag_with_matmul=False, enable_overlap_matmul_with_rs=False, enable_backward_overlap_ag_with_matmul=False, recompute_in_bubble=False, recompute_in_advance=False, noop_layers=None, use_multiparameter_pipeline_model_parallel=False, optimize_send_recv_comm=False, pipeline_num_transformer_layers=None, schedules_method=None, dualpipev_dw_detach=False, gemm_gradient_accumulation_fusion=False, moe_tp_extend_ep=False, moe_permutation_async_comm=False, n_shared_experts=None, moe_allgather_overlap_comm=False, moe_alltoall_overlap_comm=False, moe_zero_memory='disable', moe_zero_memory_num_layers=None, moe_fb_overlap=False, moe_unperm2_mem_optim_swap=False, balanced_moe_experts=False, balanced_moe_hot_expert_num=3, trans_hot_expert_group_num=4, enable_expert_placement=False, expert_placement_freq=50, enable_fine_grained_expert_placement=False, print_expert_load=False, fine_grained_expert_placement_thre=0.08, hccl_group_buffer=None, hccl_group_buffer_adaptive=False, hccl_ep_group_buffer_adaptive_factor=-1.0, ema_decay=0.9999, virtual_optimizer=None, quant_states=None, quant_grads=False, dist_train=False, tokenizer_name_or_path=None, tokenizer_not_use_fast=True, param_and_grad_buffer_pad=None, layerzero=False, layerzero_config=None, fsdp2_config_path=None, reset_bucket_group_order=False, reuse_fp32_param=False, smart_swap=False, swap_attention=False, swap_modules='input_norm,self_attention,post_attention_norm', compress_dense='disable', disable_gloo_group=False, hccl_slice_size=10485760, swap_optimizer=False, swap_optimizer_times=16, pre_tockens=65536, next_tockens=0, sparse_mode=0, use_fusion_attn_v2=False, square_alibi_mask=False, fill_neg_inf=False, alibi_fusion_attn_type=None, alibi_diagonal_opposite=False, multi_head_latent_attention=False, qk_rope_head_dim=None, qk_nope_head_dim=None, ai_framework='pytorch', auto_settings=False, auto_settings_work_dir='/home/ma-user/work/verl', auto_settings_ranks=8, auto_settings_log_level='info', target_nnodes=1, nnodes=1, nproc_per_node=1, node_rank=0, auto_settings_type='white', prof_file=None, master_addr='127.0.0.1', master_port=29500, automated_pipeline=False, automated_pipeline_perf=False, recompute_module_list=None, jit_compile=False, node_ip_address='172.16.0.134', node_manager_port='37775', object_store_name='/tmp/ray/session_2026-01-06_00-16-38_348629_537872/sockets/plasma_store', raylet_name='/tmp/ray/session_2026-01-06_00-16-38_348629_537872/sockets/raylet', redis_address='None', metrics_agent_port='40808', logging_rotate_bytes='536870912', logging_rotate_backup_count='5', runtime_env_agent_port='60354', gcs_address='172.16.0.134:63965', session_name='session_2026-01-06_00-16-38_348629_537872', temp_dir='/tmp/ray', webui='127.0.0.1:8265', cluster_id='8bb71ebab51e5be621315fd2401efe6354f0b4a381c0513ce2d8f9a4', startup_token='114', worker_launch_time_ms='1767629969428', node_id='508e57c33c8c9d9025124c7d81a774571b7e4fdcb57d8007605d5d43', runtime_env_hash='485946460', quant_states_enabled=False, quant_grads_dtype=None, use_quant_optimizer=False, use_flash_attn=True)[36m(WorkerDict pid=558093)[0m [rank0]:[W106 00:20:04.685450049 compiler_depend.ts:117] Warning: Driver Version: 9 is invalid or not supported yet. (function operator())
[36m(WorkerDict pid=558094)[0m /home/ma-user/work/verl/verl/models/mcore/config_converter.py:182: UserWarning: The following keys are not supported in the current Megatron version and will be removed: ['use_flash_attn']
[36m(WorkerDict pid=558094)[0m   return check_and_construct_configs(args, TransformerConfig)
[36m(WorkerDict pid=558093)[0m /home/ma-user/work/verl/verl/models/mcore/config_converter.py:182: UserWarning: The following keys are not supported in the current Megatron version and will be removed: ['use_flash_attn']
[36m(WorkerDict pid=558093)[0m   return check_and_construct_configs(args, TransformerConfig)
[36m(WorkerDict pid=558094)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(WorkerDict pid=558093)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=558093)[0m   warnings.warn(  # warn only once

[36m(WorkerDict pid=558093)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=558093)[0m   "architectures": [
[36m(WorkerDict pid=558093)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=558093)[0m   ],
[36m(WorkerDict pid=558093)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=558093)[0m   "dtype": "bfloat16",
[36m(WorkerDict pid=558093)[0m   "eos_token_id": 151645,
[36m(WorkerDict pid=558093)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=558093)[0m   "hidden_size": 896,
[36m(WorkerDict pid=558093)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=558093)[0m   "intermediate_size": 4864,
[36m(WorkerDict pid=558093)[0m   "layer_types": [
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention",
[36m(WorkerDict pid=558093)[0m     "full_attention"
[36m(WorkerDict pid=558093)[0m   ],
[36m(WorkerDict pid=558093)[0m   "max_position_embeddings": 5120,
[36m(WorkerDict pid=558093)[0m   "max_window_layers": 21,
[36m(WorkerDict pid=558093)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=558093)[0m   "num_attention_heads": 14,
[36m(WorkerDict pid=558093)[0m   "num_hidden_layers": 24,
[36m(WorkerDict pid=558093)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=558093)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=558093)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=558093)[0m   "rope_scaling": null,
[36m(WorkerDict pid=558093)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=558093)[0m   "sliding_window": null,
[36m(WorkerDict pid=558093)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=558093)[0m   "transformers_version": "4.57.3",
[36m(WorkerDict pid=558093)[0m   "use_cache": true,
[36m(WorkerDict pid=558093)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=558093)[0m   "vocab_size": 151936
[36m(WorkerDict pid=558093)[0m }
[36m(WorkerDict pid=558093)[0m 
[36m(WorkerDict pid=558093)[0m Overridden TransformerConfig init config: {'num_layers': 24, 'hidden_size': 896, 'num_attention_heads': 14, 'num_query_groups': 2, 'ffn_hidden_size': 4864, 'attention_dropout': 0.0, 'hidden_dropout': 0.0, 'kv_channels': None, 'layernorm_epsilon': 1e-06, 'add_bias_linear': False, 'activation_func': <function silu at 0xffff99489090>, 'normalization': 'RMSNorm', 'gated_linear_unit': True, 'pipeline_dtype': torch.bfloat16, 'params_dtype': torch.bfloat16, 'bf16': True, 'tensor_model_parallel_size': 1, 'pipeline_model_parallel_size': 1, 'expert_model_parallel_size': 1, 'expert_tensor_parallel_size': 1, 'virtual_pipeline_model_parallel_size': None, 'context_parallel_size': 1, 'overlap_p2p_comm': False, 'batch_p2p_comm': False, 'sequence_parallel': False, 'variable_seq_lengths': True, 'masked_softmax_fusion': True, 'moe_token_dispatcher_type': 'alltoall', 'use_cpu_initialization': False, 'add_qkv_bias': True, 'qk_layernorm': False, 'recompute_granularity': None, 'recompute_modules': ['core_attn'], 'recompute_method': None, 'recompute_num_layers': None, 'attention_backend': <AttnBackend.flash: 1>, 'apply_rope_fusion': True, 'bias_activation_fusion': True, 'bias_dropout_fusion': True, 'gradient_accumulation_fusion': True, 'deallocate_pipeline_outputs': True, 'persist_layer_norm': True}
[36m(WorkerDict pid=558093)[0m TF config: TransformerConfig(tensor_model_parallel_size=1, pipeline_model_parallel_comm_backend=None, pipeline_model_parallel_size=1, virtual_pipeline_model_parallel_size=None, sequence_parallel=False, context_parallel_size=1, hierarchical_context_parallel_sizes=None, expert_model_parallel_size=1, expert_tensor_parallel_size=1, moe_extended_tp=False, perform_initialization=True, use_cpu_initialization=False, fp16=False, bf16=True, params_dtype=torch.bfloat16, timers=None, finalize_model_grads_func=None, grad_scale_func=None, no_sync_func=None, grad_sync_func=None, param_sync_func=None, deterministic_mode=False, enable_autocast=False, autocast_dtype=torch.bfloat16, num_microbatches_with_partial_activation_checkpoints=None, gradient_accumulation_fusion=True, async_tensor_model_parallel_allreduce=False, use_te_rng_tracker=False, tp_comm_overlap=False, tp_comm_bulk_wgrad=True, tp_comm_bulk_dgrad=True, tp_comm_overlap_ag=True, tp_comm_overlap_rs=True, tp_comm_overlap_rs_dgrad=False, tp_comm_split_ag=True, tp_comm_atomic_ag=False, tp_comm_split_rs=True, tp_comm_atomic_rs=False, cross_entropy_loss_fusion=False, cross_entropy_fusion_impl='native', tp_comm_overlap_disable_qkv=False, tp_comm_overlap_disable_fc1=False, tp_comm_bootstrap_backend='nccl', pipeline_dtype=torch.bfloat16, variable_seq_lengths=True, overlap_p2p_comm=False, batch_p2p_comm=False, batch_p2p_sync=True, use_ring_exchange_p2p=False, deallocate_pipeline_outputs=True, defer_embedding_wgrad_compute=False, wgrad_deferral_limit=0, pipeline_model_parallel_split_rank=None, overlap_p2p_comm_warmup_flush=False, microbatch_group_size_per_vp_stage=1, cpu_offloading=False, cpu_offloading_num_layers=0, _cpu_offloading_context=None, cpu_offloading_activations=True, cpu_offloading_weights=True, barrier_with_L1_time=True, num_layers=24, mtp_num_layers=None, mtp_loss_scaling_factor=None, num_layers_in_first_pipeline_stage=None, num_layers_in_last_pipeline_stage=None, account_for_embedding_in_pipeline_split=False, account_for_loss_in_pipeline_split=False, hidden_size=896, num_attention_heads=14, attention_backend=<AttnBackend.flash: 1>, softmax_scale=None, num_query_groups=2, ffn_hidden_size=4864, kv_channels=64, hidden_dropout=0.0, attention_dropout=0.0, fp32_residual_connection=False, apply_residual_connection_post_layernorm=False, layernorm_epsilon=1e-06, layernorm_zero_centered_gamma=False, add_bias_linear=False, add_qkv_bias=True, gated_linear_unit=True, activation_func=<function silu at 0xffff99489090>, activation_func_fp8_input_store=False, num_moe_experts=None, rotary_interleaved=False, window_size=None, normalization='RMSNorm', qk_layernorm=False, test_mode=False, calculate_per_token_loss=False, multi_latent_attention=False, init_method=functools.partial(<function normal_ at 0xffff20391cf0>, mean=0.0, std=0.02), output_layer_init_method=functools.partial(<function normal_ at 0xffff20391cf0>, mean=0.0, std=0.002886751345948129), init_method_std=0.02, init_model_with_meta_device=False, apply_query_key_layer_scaling=False, attention_softmax_in_fp32=True, disable_bf16_reduced_precision_matmul=False, bias_activation_fusion=True, masked_softmax_fusion=True, persist_layer_norm=True, memory_efficient_layer_norm=False, bias_dropout_fusion=True, apply_rope_fusion=True, recompute_granularity=None, recompute_method=None, recompute_num_layers=None, distribute_saved_activations=None, recompute_modules=['core_attn'], fp8=None, fp8_recipe='delayed', fp8_param=False, fp8_margin=0, fp8_interval=1, fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', fp8_wgrad=True, fp8_dot_product_attention=False, fp8_multi_head_attention=False, tp_only_amax_red=False, first_last_layers_bf16=False, num_layers_at_start_in_bf16=1, num_layers_at_end_in_bf16=1, moe_shared_expert_intermediate_size=None, moe_shared_expert_overlap=False, moe_layer_freq=1, moe_ffn_hidden_size=4864, moe_router_load_balancing_type='aux_loss', moe_router_topk=2, moe_router_topk_limited_devices=None, moe_router_num_groups=None, moe_router_group_topk=None, moe_router_pre_softmax=False, moe_router_topk_scaling_factor=None, moe_router_score_function='softmax', moe_router_dtype=None, moe_router_enable_expert_bias=False, moe_router_bias_update_rate=0.001, moe_grouped_gemm=False, moe_use_legacy_grouped_gemm=False, moe_aux_loss_coeff=0, moe_z_loss_coeff=None, moe_input_jitter_eps=None, moe_token_dropping=False, moe_token_dispatcher_type='alltoall', moe_enable_deepep=False, moe_per_layer_logging=False, moe_expert_capacity_factor=None, moe_pad_expert_input_to_capacity=False, moe_token_drop_policy='probs', moe_layer_recompute=False, moe_permute_fusion=False, moe_apply_probs_on_input=False, cp_comm_type=None, enable_cuda_graph=False, cuda_graph_use_single_mempool=False, cuda_graph_retain_backward_graph=False, cuda_graph_warmup_steps=3, external_cuda_graph=False, cuda_graph_scope='full', clone_scatter_output_in_embedding=True, disable_parameter_transpose_cache=False, config_logger_dir='', flash_decode=False, inference_rng_tracker=False, mrope_section=None, is_hybrid_model=False, mamba_state_dim=128, mamba_head_dim=64, mamba_num_groups=8, heterogeneous_block_specs=False, optimizer_selection='fused_adamw', optimization_level=2, use_fused_rmsnorm=False, use_fused_swiglu=False, use_gmm_fp8=True, te_comparison_with_cpu=False, te_comparison_with_bf16=False, context_parallel_algo='megatron_cp_algo', cp_window_size=1, attention_mask_type='causal', use_cp_send_recv_overlap=False, use_fused_ring_attention_update=False, megatron_cp_in_bnsd=False, ulysses_degree_in_cp=None, context_parallel_kv_cache_policy=None, context_parallel_cache_interval=0, use_ulysses_allgather_kv=False, attention_mask_on_cpu=False, adaptive_cp_without_coarse=False, adaptive_cp_dynamic_attn_mask=False, adaptive_cp_only_reschedule=False, adaptive_cp_manually_set_mask_list=False, async_log_allreduce=False, use_fused_rotary_pos_emb=False, use_fused_moe_token_permute_and_unpermute=False, npu_deterministic=False, op_cal_tflops=False, profile_level='level0', profile_with_cpu=False, profile_with_stack=False, profile_with_memory=False, profile_record_shapes=False, profile_save_path='./profile_dir', recompute_activation_function=False, recompute_activation_function_num_layers=None, recompute_norm=False, recompute_norm_num_layers=None, enable_recompute_layers_per_pp_rank=False, unaligned_linear=False, use_ascend_mc2=False, use_ascend_coc=False, coc_mode=-1, coc_parallel_num=1, coc_fused_kernel=False, tp_2d=False, tp_x=1, tp_y=1, enable_overlap_ag_with_matmul=False, enable_overlap_matmul_with_rs=False, enable_backward_overlap_ag_with_matmul=False, recompute_in_bubble=False, recompute_in_advance=False, noop_layers=None, use_multiparameter_pipeline_model_parallel=False, optimize_send_recv_comm=False, pipeline_num_transformer_layers=None, schedules_method=None, dualpipev_dw_detach=False, gemm_gradient_accumulation_fusion=False, moe_tp_extend_ep=False, moe_permutation_async_comm=False, n_shared_experts=None, moe_allgather_overlap_comm=False, moe_alltoall_overlap_comm=False, moe_zero_memory='disable', moe_zero_memory_num_layers=None, moe_fb_overlap=False, moe_unperm2_mem_optim_swap=False, balanced_moe_experts=False, balanced_moe_hot_expert_num=3, trans_hot_expert_group_num=4, enable_expert_placement=False, expert_placement_freq=50, enable_fine_grained_expert_placement=False, print_expert_load=False, fine_grained_expert_placement_thre=0.08, hccl_group_buffer=None, hccl_group_buffer_adaptive=False, hccl_ep_group_buffer_adaptive_factor=-1.0, ema_decay=0.9999, virtual_optimizer=None, quant_states=None, quant_grads=False, dist_train=False, tokenizer_name_or_path=None, tokenizer_not_use_fast=True, param_and_grad_buffer_pad=None, layerzero=False, layerzero_config=None, fsdp2_config_path=None, reset_bucket_group_order=False, reuse_fp32_param=False, smart_swap=False, swap_attention=False, swap_modules='input_norm,self_attention,post_attention_norm', compress_dense='disable', disable_gloo_group=False, hccl_slice_size=10485760, swap_optimizer=False, swap_optimizer_times=16, pre_tockens=65536, next_tockens=0, sparse_mode=0, use_fusion_attn_v2=False, square_alibi_mask=False, fill_neg_inf=False, alibi_fusion_attn_type=None, alibi_diagonal_opposite=False, multi_head_latent_attention=False, qk_rope_head_dim=None, qk_nope_head_dim=None, ai_framework='pytorch', auto_settings=False, auto_settings_work_dir='/home/ma-user/work/verl', auto_settings_ranks=8, auto_settings_log_level='info', target_nnodes=1, nnodes=1, nproc_per_node=1, node_rank=0, auto_settings_type='white', prof_file=None, master_addr='127.0.0.1', master_port=29500, automated_pipeline=False, automated_pipeline_perf=False, recompute_module_list=None, jit_compile=False, node_ip_address='172.16.0.134', node_manager_port='37775', object_store_name='/tmp/ray/session_2026-01-06_00-16-38_348629_537872/sockets/plasma_store', raylet_name='/tmp/ray/session_2026-01-06_00-16-38_348629_537872/sockets/raylet', redis_address='None', metrics_agent_port='40808', logging_rotate_bytes='536870912', logging_rotate_backup_count='5', runtime_env_agent_port='60354', gcs_address='172.16.0.134:63965', session_name='session_2026-01-06_00-16-38_348629_537872', temp_dir='/tmp/ray', webui='127.0.0.1:8265', cluster_id='8bb71ebab51e5be621315fd2401efe6354f0b4a381c0513ce2d8f9a4', startup_token='113', worker_launch_time_ms='1767629969316', node_id='508e57c33c8c9d9025124c7d81a774571b7e4fdcb57d8007605d5d43', runtime_env_hash='1276635623', quant_states_enabled=False, quant_grads_dtype=None, use_quant_optimizer=False, use_flash_attn=True)
[36m(WorkerDict pid=558094)[0m load from local dir /home/ma-user/work/models/Qwen2.5-0.5B-Instruct
[36m(WorkerDict pid=558093)[0m  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 494032768
[36m(WorkerDict pid=558093)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:20:06,411 INFO [megatron.core.distributed.distributed_data_parallel:532] => Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=True, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=False, check_for_large_grads=False, bucket_size=None, pad_buckets_for_high_nccl_busbw=False, average_in_collective=False, fp8_param_gather=False, use_custom_fsdp=False, data_parallel_sharding_strategy='no_shard', gradient_reduce_div_fusion=True, suggested_communication_unit_size=None, preserve_fp32_weights=True, keep_fp8_transpose_cache_when_using_custom_fsdp=False)
[36m(WorkerDict pid=558093)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:20:06,442 INFO [megatron.core.distributed.param_and_grad_buffer:553] => Number of buckets for gradient all-reduce / reduce-scatter: 1
[36m(WorkerDict pid=558093)[0m Params for bucket 1 (494032768 elements, 494032768 padded size):
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.15.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.11.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.5.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.3.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.3.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.22.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.16.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.10.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.9.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.2.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.17.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.16.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.14.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.6.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.22.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.19.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.12.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.0.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.20.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.13.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.8.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.7.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.21.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.18.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.7.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.22.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.17.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.13.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.10.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.9.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.4.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.21.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.14.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.6.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.0.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.19.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.12.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.0.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.23.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.20.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.16.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.16.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.14.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.12.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.0.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.21.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.18.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.2.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.23.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.20.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.16.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.10.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.6.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.0.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.18.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.17.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.12.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.22.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.19.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.14.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.11.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.10.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.1.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.final_layernorm.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.23.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.20.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.15.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.9.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.6.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.4.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.3.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.2.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.0.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.21.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.19.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.8.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.7.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.23.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.14.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.9.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.6.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.18.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.18.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.7.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.7.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.5.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.3.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.2.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.embedding.word_embeddings.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.22.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.17.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.16.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.13.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.10.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.1.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.23.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.20.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.12.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.4.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.3.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.2.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.15.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.9.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.8.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.1.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.20.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.15.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.13.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.8.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.21.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.15.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.11.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.6.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.5.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.19.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.10.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.4.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.15.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.12.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.5.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.22.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.15.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.13.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.9.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.8.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.1.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.1.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.23.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.11.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.4.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.1.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.21.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.18.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.18.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.17.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.11.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.5.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.22.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.19.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.17.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.13.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.11.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.5.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.21.self_attention.linear_proj.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.14.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.12.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.2.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.13.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.14.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.19.self_attention.linear_qkv.bias
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.23.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.20.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.16.self_attention.linear_qkv.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.11.self_attention.linear_qkv.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.8.mlp.linear_fc2.weight
[36m(WorkerDict pid=558094)[0m Some weights of Qwen2ForCausalLM were not initialized from the model checkpoint at /home/ma-user/work/models/Qwen2.5-0.5B-Instruct and are newly initialized: ['lm_head.weight']
[36m(WorkerDict pid=558094)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=558094)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=558094)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=558093)[0m /home/ma-user/work/verl/verl/utils/megatron_utils.py:419: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
[36m(WorkerDict pid=558093)[0m   if buffer.param_data.storage().size() > 0:
[36m(WorkerDict pid=558094)[0m <string>:35: UserWarning: set sequence parallel to false as TP size is 1
[36m(WorkerDict pid=558094)[0m /home/ma-user/work/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.
[36m(WorkerDict pid=558094)[0m   warnings.warn("Torch profiler tool config is not fully supported now.", stacklevel=1)
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.7.mlp.linear_fc1.layer_norm_weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.4.mlp.linear_fc2.weight
[36m(WorkerDict pid=558093)[0m 	module.decoder.layers.3.mlp.linear_fc1.weight
[36m(WorkerDict pid=558093)[0m actor_module: 1
[36m(WorkerDict pid=558093)[0m load from local dir /home/ma-user/work/models/Qwen2.5-0.5B-Instruct
[36m(WorkerDict pid=558093)[0m loading embeddings...
[36m(WorkerDict pid=558093)[0m loading layer #0, with layer_name model.layers.0...
[36m(WorkerDict pid=558093)[0m loading layer #1, with layer_name model.layers.1...
[36m(WorkerDict pid=558093)[0m loading layer #2, with layer_name model.layers.2...
[36m(WorkerDict pid=558093)[0m loading layer #3, with layer_name model.layers.3...
[36m(WorkerDict pid=558093)[0m loading layer #4, with layer_name model.layers.4...
[36m(WorkerDict pid=558093)[0m loading layer #5, with layer_name model.layers.5...
[36m(WorkerDict pid=558093)[0m loading layer #6, with layer_name model.layers.6...
[36m(WorkerDict pid=558093)[0m loading layer #7, with layer_name model.layers.7...
[36m(WorkerDict pid=558093)[0m loading layer #8, with layer_name model.layers.8...
[36m(WorkerDict pid=558093)[0m loading layer #9, with layer_name model.layers.9...
[36m(WorkerDict pid=558093)[0m loading layer #10, with layer_name model.layers.10...
[36m(WorkerDict pid=558093)[0m loading layer #11, with layer_name model.layers.11...
[36m(WorkerDict pid=558093)[0m loading layer #12, with layer_name model.layers.12...
[36m(WorkerDict pid=558093)[0m loading layer #13, with layer_name model.layers.13...
[36m(WorkerDict pid=558093)[0m loading layer #14, with layer_name model.layers.14...
[36m(WorkerDict pid=558093)[0m loading layer #15, with layer_name model.layers.15...
[36m(WorkerDict pid=558093)[0m loading layer #16, with layer_name model.layers.16...
[36m(WorkerDict pid=558093)[0m loading layer #17, with layer_name model.layers.17...
[36m(WorkerDict pid=558093)[0m loading layer #18, with layer_name model.layers.18...
[36m(WorkerDict pid=558093)[0m loading layer #19, with layer_name model.layers.19...
[36m(WorkerDict pid=558093)[0m loading layer #20, with layer_name model.layers.20...
[36m(WorkerDict pid=558093)[0m loading layer #21, with layer_name model.layers.21...
[36m(WorkerDict pid=558093)[0m loading layer #22, with layer_name model.layers.22...
[36m(WorkerDict pid=558093)[0m loading layer #23, with layer_name model.layers.23...
[36m(WorkerDict pid=558093)[0m loading final layernorm...
[36m(WorkerDict pid=558093)[0m loading lm_head...
[36m(WorkerDict pid=558093)[0m loading megatron ckpt done, time elapsed 0.6167943477630615s
[36m(WorkerDict pid=558093)[0m DistributedDataParallel contains 494.03M parameters
[36m(WorkerDict pid=558093)[0m optimizer config after override: {'optimizer': 'adam', 'lr': 5e-07, 'min_lr': 0.0, 'clip_grad': 1.0, 'weight_decay': 0.01, 'use_distributed_optimizer': True, 'bf16': True, 'params_dtype': torch.bfloat16, 'optimizer_offload_fraction': 0, 'overlap_cpu_optimizer_d2h_h2d': True, 'use_precision_aware_optimizer': True, 'optimizer_cpu_offload': True}
[36m(WorkerDict pid=558093)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:20:07,451 INFO [megatron.core.optimizer:532] => Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=5e-07, min_lr=0.0, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=True, params_dtype=torch.bfloat16, use_precision_aware_optimizer=True, main_grads_dtype=torch.float32, main_params_dtype=torch.float32, exp_avg_dtype=torch.float32, exp_avg_sq_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, optimizer_cpu_offload=True, optimizer_offload_fraction=0, use_torch_optimizer_for_cpu_offload=False, overlap_cpu_optimizer_d2h_h2d=True, pin_cpu_grads=True, pin_cpu_params=True, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')
[36m(WorkerDict pid=558093)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:20:07,502 INFO [megatron.core.optimizer_param_scheduler:532] => > learning rate decay style: constant
[36m(WorkerDict pid=558094)[0m TransformerConfig(tensor_model_parallel_size=1, pipeline_model_parallel_comm_backend=None, pipeline_model_parallel_size=1, virtual_pipeline_model_parallel_size=None, sequence_parallel=False, context_parallel_size=1, hierarchical_context_parallel_sizes=None, expert_model_parallel_size=1, expert_tensor_parallel_size=1, moe_extended_tp=False, perform_initialization=True, use_cpu_initialization=False, fp16=False, bf16=True, params_dtype=torch.bfloat16, timers=None, finalize_model_grads_func=<function finalize_model_grads at 0xffcf3fcef9a0>, grad_scale_func=<bound method MegatronOptimizer.scale_loss of <megatron.core.optimizer.optimizer.ChainedOptimizer object at 0xffcf38254580>>, no_sync_func=None, grad_sync_func=None, param_sync_func=None, deterministic_mode=False, enable_autocast=False, autocast_dtype=torch.bfloat16, num_microbatches_with_partial_activation_checkpoints=None, gradient_accumulation_fusion=True, async_tensor_model_parallel_allreduce=False, use_te_rng_tracker=False, tp_comm_overlap=False, tp_comm_bulk_wgrad=True, tp_comm_bulk_dgrad=True, tp_comm_overlap_ag=True, tp_comm_overlap_rs=True, tp_comm_overlap_rs_dgrad=False, tp_comm_split_ag=True, tp_comm_atomic_ag=False, tp_comm_split_rs=True, tp_comm_atomic_rs=False, cross_entropy_loss_fusion=False, cross_entropy_fusion_impl='native', tp_comm_overlap_disable_qkv=False, tp_comm_overlap_disable_fc1=False, tp_comm_bootstrap_backend='nccl', pipeline_dtype=torch.bfloat16, variable_seq_lengths=True, overlap_p2p_comm=False, batch_p2p_comm=False, batch_p2p_sync=True, use_ring_exchange_p2p=False, deallocate_pipeline_outputs=True, defer_embedding_wgrad_compute=False, wgrad_deferral_limit=0, pipeline_model_parallel_split_rank=None, overlap_p2p_comm_warmup_flush=False, microbatch_group_size_per_vp_stage=1, cpu_offloading=False, cpu_offloading_num_layers=0, _cpu_offloading_context=None, cpu_offloading_activations=True, cpu_offloading_weights=True, barrier_with_L1_time=True, num_layers=24, mtp_num_layers=None, mtp_loss_scaling_factor=None, num_layers_in_first_pipeline_stage=None, num_layers_in_last_pipeline_stage=None, account_for_embedding_in_pipeline_split=False, account_for_loss_in_pipeline_split=False, hidden_size=896, num_attention_heads=14, attention_backend=<AttnBackend.flash: 1>, softmax_scale=None, num_query_groups=2, ffn_hidden_size=4864, kv_channels=64, hidden_dropout=0.0, attention_dropout=0.0, fp32_residual_connection=False, apply_residual_connection_post_layernorm=False, layernorm_epsilon=1e-06, layernorm_zero_centered_gamma=False, add_bias_linear=False, add_qkv_bias=True, gated_linear_unit=True, activation_func=<function silu at 0xffff2c115090>, activation_func_fp8_input_store=False, num_moe_experts=None, rotary_interleaved=False, window_size=None, normalization='RMSNorm', qk_layernorm=False, test_mode=False, calculate_per_token_loss=False, multi_latent_attention=False, init_method=functools.partial(<function normal_ at 0xffff2c19dcf0>, mean=0.0, std=0.02), output_layer_init_method=functools.partial(<function normal_ at 0xffff2c19dcf0>, mean=0.0, std=0.002886751345948129), init_method_std=0.02, init_model_with_meta_device=False, apply_query_key_layer_scaling=False, attention_softmax_in_fp32=True, disable_bf16_reduced_precision_matmul=False, bias_activation_fusion=True, masked_softmax_fusion=True, persist_layer_norm=True, memory_efficient_layer_norm=False, bias_dropout_fusion=True, apply_rope_fusion=True, recompute_granularity=None, recompute_method=None, recompute_num_layers=None, distribute_saved_activations=None, recompute_modules=['core_attn'], fp8=None, fp8_recipe='delayed', fp8_param=False, fp8_margin=0, fp8_interval=1, fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', fp8_wgrad=True, fp8_dot_product_attention=False, fp8_multi_head_attention=False, tp_only_amax_red=False, first_last_layers_bf16=False, num_layers_at_start_in_bf16=1, num_layers_at_end_in_bf16=1, moe_shared_expert_intermediate_size=None, moe_shared_expert_overlap=False, moe_layer_freq=1, moe_ffn_hidden_size=4864, moe_router_load_balancing_type='aux_loss', moe_router_topk=2, moe_router_topk_limited_devices=None, moe_router_num_groups=None, moe_router_group_topk=None, moe_router_pre_softmax=False, moe_router_topk_scaling_factor=None, moe_router_score_function='softmax', moe_router_dtype=None, moe_router_enable_expert_bias=False, moe_router_bias_update_rate=0.001, moe_grouped_gemm=False, moe_use_legacy_grouped_gemm=False, moe_aux_loss_coeff=0, moe_z_loss_coeff=None, moe_input_jitter_eps=None, moe_token_dropping=False, moe_token_dispatcher_type='alltoall', moe_enable_deepep=False, moe_per_layer_logging=False, moe_expert_capacity_factor=None, moe_pad_expert_input_to_capacity=False, moe_token_drop_policy='probs', moe_layer_recompute=False, moe_permute_fusion=False, moe_apply_probs_on_input=False, cp_comm_type=None, enable_cuda_graph=False, cuda_graph_use_single_mempool=False, cuda_graph_retain_backward_graph=False, cuda_graph_warmup_steps=3, external_cuda_graph=False, cuda_graph_scope='full', clone_scatter_output_in_embedding=True, disable_parameter_transpose_cache=False, config_logger_dir='', flash_decode=False, inference_rng_tracker=False, mrope_section=None, is_hybrid_model=False, mamba_state_dim=128, mamba_head_dim=64, mamba_num_groups=8, heterogeneous_block_specs=False, optimizer_selection='fused_adamw', optimization_level=2, use_fused_rmsnorm=True, use_fused_swiglu=False, use_gmm_fp8=True, te_comparison_with_cpu=False, te_comparison_with_bf16=False, context_parallel_algo='megatron_cp_algo', cp_window_size=1, attention_mask_type='causal', use_cp_send_recv_overlap=False, use_fused_ring_attention_update=False, megatron_cp_in_bnsd=False, ulysses_degree_in_cp=None, context_parallel_kv_cache_policy=None, context_parallel_cache_interval=0, use_ulysses_allgather_kv=False, attention_mask_on_cpu=False, adaptive_cp_without_coarse=False, adaptive_cp_dynamic_attn_mask=False, adaptive_cp_only_reschedule=False, adaptive_cp_manually_set_mask_list=False, async_log_allreduce=False, use_fused_rotary_pos_emb=False, use_fused_moe_token_permute_and_unpermute=False, npu_deterministic=False, op_cal_tflops=False, profile_level='level0', profile_with_cpu=False, profile_with_stack=False, profile_with_memory=False, profile_record_shapes=False, profile_save_path='./profile_dir', recompute_activation_function=False, recompute_activation_function_num_layers=None, recompute_norm=False, recompute_norm_num_layers=None, enable_recompute_layers_per_pp_rank=False, unaligned_linear=False, use_ascend_mc2=False, use_ascend_coc=False, coc_mode=-1, coc_parallel_num=1, coc_fused_kernel=False, tp_2d=False, tp_x=1, tp_y=1, enable_overlap_ag_with_matmul=False, enable_overlap_matmul_with_rs=False, enable_backward_overlap_ag_with_matmul=False, recompute_in_bubble=False, recompute_in_advance=False, noop_layers=None, use_multiparameter_pipeline_model_parallel=False, optimize_send_recv_comm=False, pipeline_num_transformer_layers=None, schedules_method=None, dualpipev_dw_detach=False, gemm_gradient_accumulation_fusion=False, moe_tp_extend_ep=False, moe_permutation_async_comm=False, n_shared_experts=None, moe_allgather_overlap_comm=False, moe_alltoall_overlap_comm=False, moe_zero_memory='disable', moe_zero_memory_num_layers=None, moe_fb_overlap=False, moe_unperm2_mem_optim_swap=False, balanced_moe_experts=False, balanced_moe_hot_expert_num=3, trans_hot_expert_group_num=4, enable_expert_placement=False, expert_placement_freq=50, enable_fine_grained_expert_placement=False, print_expert_load=False, fine_grained_expert_placement_thre=0.08, hccl_group_buffer=None, hccl_group_buffer_adaptive=False, hccl_ep_group_buffer_adaptive_factor=-1.0, ema_decay=0.9999, virtual_optimizer=None, quant_states=None, quant_grads=False, dist_train=False, tokenizer_name_or_path=None, tokenizer_not_use_fast=True, param_and_grad_buffer_pad=None, layerzero=False, layerzero_config=None, fsdp2_config_path=None, reset_bucket_group_order=False, reuse_fp32_param=False, smart_swap=False, swap_attention=False, swap_modules='input_norm,self_attention,post_attention_norm', compress_dense='disable', disable_gloo_group=False, hccl_slice_size=10485760, swap_optimizer=False, swap_optimizer_times=16, pre_tockens=65536, next_tockens=0, sparse_mode=0, use_fusion_attn_v2=False, square_alibi_mask=False, fill_neg_inf=False, alibi_fusion_attn_type=None, alibi_diagonal_opposite=False, multi_head_latent_attention=False, qk_rope_head_dim=None, qk_nope_head_dim=None, ai_framework='pytorch', auto_settings=False, auto_settings_work_dir='/home/ma-user/work/verl', auto_settings_ranks=8, auto_settings_log_level='info', target_nnodes=1, nnodes=1, nproc_per_node=1, node_rank=0, auto_settings_type='white', prof_file=None, master_addr='127.0.0.1', master_port=29500, automated_pipeline=False, automated_pipeline_perf=False, recompute_module_list=None, jit_compile=False, node_ip_address='172.16.0.134', node_manager_port='37775', object_store_name='/tmp/ray/session_2026-01-06_00-16-38_348629_537872/sockets/plasma_store', raylet_name='/tmp/ray/session_2026-01-06_00-16-38_348629_537872/sockets/raylet', redis_address='None', metrics_agent_port='40808', logging_rotate_bytes='536870912', logging_rotate_backup_count='5', runtime_env_agent_port='60354', gcs_address='172.16.0.134:63965', session_name='session_2026-01-06_00-16-38_348629_537872', temp_dir='/tmp/ray', webui='127.0.0.1:8265', cluster_id='8bb71ebab51e5be621315fd2401efe6354f0b4a381c0513ce2d8f9a4', startup_token='114', worker_launch_time_ms='1767629969428', node_id='508e57c33c8c9d9025124c7d81a774571b7e4fdcb57d8007605d5d43', runtime_env_hash='485946460', quant_states_enabled=False, quant_grads_dtype=None, use_quant_optimizer=False, use_flash_attn=True)
[36m(WorkerDict pid=558094)[0m routing replay layers: 0
[36m(WorkerDict pid=558094)[0m [Warining] Because actor tp size == 1, set sp to False[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=558093)[0m TransformerConfig(tensor_model_parallel_size=1, pipeline_model_parallel_comm_backend=None, pipeline_model_parallel_size=1, virtual_pipeline_model_parallel_size=None, sequence_parallel=False, context_parallel_size=1, hierarchical_context_parallel_sizes=None, expert_model_parallel_size=1, expert_tensor_parallel_size=1, moe_extended_tp=False, perform_initialization=True, use_cpu_initialization=False, fp16=False, bf16=True, params_dtype=torch.bfloat16, timers=None, finalize_model_grads_func=None, grad_scale_func=None, no_sync_func=None, grad_sync_func=None, param_sync_func=None, deterministic_mode=False, enable_autocast=False, autocast_dtype=torch.bfloat16, num_microbatches_with_partial_activation_checkpoints=None, gradient_accumulation_fusion=True, async_tensor_model_parallel_allreduce=False, use_te_rng_tracker=False, tp_comm_overlap=False, tp_comm_bulk_wgrad=True, tp_comm_bulk_dgrad=True, tp_comm_overlap_ag=True, tp_comm_overlap_rs=True, tp_comm_overlap_rs_dgrad=False, tp_comm_split_ag=True, tp_comm_atomic_ag=False, tp_comm_split_rs=True, tp_comm_atomic_rs=False, cross_entropy_loss_fusion=False, cross_entropy_fusion_impl='native', tp_comm_overlap_disable_qkv=False, tp_comm_overlap_disable_fc1=False, tp_comm_bootstrap_backend='nccl', pipeline_dtype=torch.bfloat16, variable_seq_lengths=True, overlap_p2p_comm=False, batch_p2p_comm=False, batch_p2p_sync=True, use_ring_exchange_p2p=False, deallocate_pipeline_outputs=True, defer_embedding_wgrad_compute=False, wgrad_deferral_limit=0, pipeline_model_parallel_split_rank=None, overlap_p2p_comm_warmup_flush=False, microbatch_group_size_per_vp_stage=1, cpu_offloading=False, cpu_offloading_num_layers=0, _cpu_offloading_context=None, cpu_offloading_activations=True, cpu_offloading_weights=True, barrier_with_L1_time=True, num_layers=24, mtp_num_layers=None, mtp_loss_scaling_factor=None, num_layers_in_first_pipeline_stage=None, num_layers_in_last_pipeline_stage=None, account_for_embedding_in_pipeline_split=False, account_for_loss_in_pipeline_split=False, hidden_size=896, num_attention_heads=14, attention_backend=<AttnBackend.flash: 1>, softmax_scale=None, num_query_groups=2, ffn_hidden_size=4864, kv_channels=64, hidden_dropout=0.0, attention_dropout=0.0, fp32_residual_connection=False, apply_residual_connection_post_layernorm=False, layernorm_epsilon=1e-06, layernorm_zero_centered_gamma=False, add_bias_linear=False, add_qkv_bias=True, gated_linear_unit=True, activation_func=<function silu at 0xffff99489090>, activation_func_fp8_input_store=False, num_moe_experts=None, rotary_interleaved=False, window_size=None, normalization='RMSNorm', qk_layernorm=False, test_mode=False, calculate_per_token_loss=False, multi_latent_attention=False, init_method=functools.partial(<function normal_ at 0xffff20391cf0>, mean=0.0, std=0.02), output_layer_init_method=functools.partial(<function normal_ at 0xffff20391cf0>, mean=0.0, std=0.002886751345948129), init_method_std=0.02, init_model_with_meta_device=False, apply_query_key_layer_scaling=False, attention_softmax_in_fp32=True, disable_bf16_reduced_precision_matmul=False, bias_activation_fusion=True, masked_softmax_fusion=True, persist_layer_norm=True, memory_efficient_layer_norm=False, bias_dropout_fusion=True, apply_rope_fusion=True, recompute_granularity=None, recompute_method=None, recompute_num_layers=None, distribute_saved_activations=None, recompute_modules=['core_attn'], fp8=None, fp8_recipe='delayed', fp8_param=False, fp8_margin=0, fp8_interval=1, fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', fp8_wgrad=True, fp8_dot_product_attention=False, fp8_multi_head_attention=False, tp_only_amax_red=False, first_last_layers_bf16=False, num_layers_at_start_in_bf16=1, num_layers_at_end_in_bf16=1, moe_shared_expert_intermediate_size=None, moe_shared_expert_overlap=False, moe_layer_freq=1, moe_ffn_hidden_size=4864, moe_router_load_balancing_type='aux_loss', moe_router_topk=2, moe_router_topk_limited_devices=None, moe_router_num_groups=None, moe_router_group_topk=None, moe_router_pre_softmax=False, moe_router_topk_scaling_factor=None, moe_router_score_function='softmax', moe_router_dtype=None, moe_router_enable_expert_bias=False, moe_router_bias_update_rate=0.001, moe_grouped_gemm=False, moe_use_legacy_grouped_gemm=False, moe_aux_loss_coeff=0, moe_z_loss_coeff=None, moe_input_jitter_eps=None, moe_token_dropping=False, moe_token_dispatcher_type='alltoall', moe_enable_deepep=False, moe_per_layer_logging=False, moe_expert_capacity_factor=None, moe_pad_expert_input_to_capacity=False, moe_token_drop_policy='probs', moe_layer_recompute=False, moe_permute_fusion=False, moe_apply_probs_on_input=False, cp_comm_type=None, enable_cuda_graph=False, cuda_graph_use_single_mempool=False, cuda_graph_retain_backward_graph=False, cuda_graph_warmup_steps=3, external_cuda_graph=False, cuda_graph_scope='full', clone_scatter_output_in_embedding=True, disable_parameter_transpose_cache=False, config_logger_dir='', flash_decode=False, inference_rng_tracker=False, mrope_section=None, is_hybrid_model=False, mamba_state_dim=128, mamba_head_dim=64, mamba_num_groups=8, heterogeneous_block_specs=False, optimizer_selection='fused_adamw', optimization_level=2, use_fused_rmsnorm=True, use_fused_swiglu=False, use_gmm_fp8=True, te_comparison_with_cpu=False, te_comparison_with_bf16=False, context_parallel_algo='megatron_cp_algo', cp_window_size=1, attention_mask_type='causal', use_cp_send_recv_overlap=False, use_fused_ring_attention_update=False, megatron_cp_in_bnsd=False, ulysses_degree_in_cp=None, context_parallel_kv_cache_policy=None, context_parallel_cache_interval=0, use_ulysses_allgather_kv=False, attention_mask_on_cpu=False, adaptive_cp_without_coarse=False, adaptive_cp_dynamic_attn_mask=False, adaptive_cp_only_reschedule=False, adaptive_cp_manually_set_mask_list=False, async_log_allreduce=False, use_fused_rotary_pos_emb=False, use_fused_moe_token_permute_and_unpermute=False, npu_deterministic=False, op_cal_tflops=False, profile_level='level0', profile_with_cpu=False, profile_with_stack=False, profile_with_memory=False, profile_record_shapes=False, profile_save_path='./profile_dir', recompute_activation_function=False, recompute_activation_function_num_layers=None, recompute_norm=False, recompute_norm_num_layers=None, enable_recompute_layers_per_pp_rank=False, unaligned_linear=False, use_ascend_mc2=False, use_ascend_coc=False, coc_mode=-1, coc_parallel_num=1, coc_fused_kernel=False, tp_2d=False, tp_x=1, tp_y=1, enable_overlap_ag_with_matmul=False, enable_overlap_matmul_with_rs=False, enable_backward_overlap_ag_with_matmul=False, recompute_in_bubble=False, recompute_in_advance=False, noop_layers=None, use_multiparameter_pipeline_model_parallel=False, optimize_send_recv_comm=False, pipeline_num_transformer_layers=None, schedules_method=None, dualpipev_dw_detach=False, gemm_gradient_accumulation_fusion=False, moe_tp_extend_ep=False, moe_permutation_async_comm=False, n_shared_experts=None, moe_allgather_overlap_comm=False, moe_alltoall_overlap_comm=False, moe_zero_memory='disable', moe_zero_memory_num_layers=None, moe_fb_overlap=False, moe_unperm2_mem_optim_swap=False, balanced_moe_experts=False, balanced_moe_hot_expert_num=3, trans_hot_expert_group_num=4, enable_expert_placement=False, expert_placement_freq=50, enable_fine_grained_expert_placement=False, print_expert_load=False, fine_grained_expert_placement_thre=0.08, hccl_group_buffer=None, hccl_group_buffer_adaptive=False, hccl_ep_group_buffer_adaptive_factor=-1.0, ema_decay=0.9999, virtual_optimizer=None, quant_states=None, quant_grads=False, dist_train=False, tokenizer_name_or_path=None, tokenizer_not_use_fast=True, param_and_grad_buffer_pad=None, layerzero=False, layerzero_config=None, fsdp2_config_path=None, reset_bucket_group_order=False, reuse_fp32_param=False, smart_swap=False, swap_attention=False, swap_modules='input_norm,self_attention,post_attention_norm', compress_dense='disable', disable_gloo_group=False, hccl_slice_size=10485760, swap_optimizer=False, swap_optimizer_times=16, pre_tockens=65536, next_tockens=0, sparse_mode=0, use_fusion_attn_v2=False, square_alibi_mask=False, fill_neg_inf=False, alibi_fusion_attn_type=None, alibi_diagonal_opposite=False, multi_head_latent_attention=False, qk_rope_head_dim=None, qk_nope_head_dim=None, ai_framework='pytorch', auto_settings=False, auto_settings_work_dir='/home/ma-user/work/verl', auto_settings_ranks=8, auto_settings_log_level='info', target_nnodes=1, nnodes=1, nproc_per_node=1, node_rank=0, auto_settings_type='white', prof_file=None, master_addr='127.0.0.1', master_port=29500, automated_pipeline=False, automated_pipeline_perf=False, recompute_module_list=None, jit_compile=False, node_ip_address='172.16.0.134', node_manager_port='37775', object_store_name='/tmp/ray/session_2026-01-06_00-16-38_348629_537872/sockets/plasma_store', raylet_name='/tmp/ray/session_2026-01-06_00-16-38_348629_537872/sockets/raylet', redis_address='None', metrics_agent_port='40808', logging_rotate_bytes='536870912', logging_rotate_backup_count='5', runtime_env_agent_port='60354', gcs_address='172.16.0.134:63965', session_name='session_2026-01-06_00-16-38_348629_537872', temp_dir='/tmp/ray', webui='127.0.0.1:8265', cluster_id='8bb71ebab51e5be621315fd2401efe6354f0b4a381c0513ce2d8f9a4', startup_token='113', worker_launch_time_ms='1767629969316', node_id='508e57c33c8c9d9025124c7d81a774571b7e4fdcb57d8007605d5d43', runtime_env_hash='1276635623', quant_states_enabled=False, quant_grads_dtype=None, use_quant_optimizer=False, use_flash_attn=True)[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:   0%|                                                                                                                                                           | 0/29 [00:00<?, ?it/s]
[36m(pid=560802)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=560802)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=560802)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=560802)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(WorkerDict pid=558094)[0m /home/ma-user/work/verl/verl/models/mcore/config_converter.py:182: UserWarning: The following keys are not supported in the current Megatron version and will be removed: ['use_flash_attn']
[36m(WorkerDict pid=558094)[0m   return check_and_construct_configs(args, TransformerConfig)
[36m(WorkerDict pid=558093)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
[36m(WorkerDict pid=558093)[0m   warnings.warn(  # warn only once
[36m(WorkerDict pid=558094)[0m /home/ma-user/work/verl/verl/utils/megatron_utils.py:419: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
[36m(WorkerDict pid=558094)[0m   if buffer.param_data.storage().size() > 0:
[36m(WorkerDict pid=558093)[0m <string>:35: UserWarning: set sequence parallel to false as TP size is 1
[36m(WorkerDict pid=558093)[0m /home/ma-user/work/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.
[36m(WorkerDict pid=558093)[0m   warnings.warn("Torch profiler tool config is not fully supported now.", stacklevel=1)
[36m(pid=560802)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/latest owner does not match the current owner.
[36m(pid=560802)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(pid=560802)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/utils/collect_env.py:58: UserWarning: Warning: The /usr/local/Ascend/ascend-toolkit/8.3.RC1.alpha003/aarch64-linux/ascend_toolkit_install.info owner does not match the current owner.
[36m(pid=560802)[0m   warnings.warn(f"Warning: The {path} owner does not match the current owner.")
[36m(ParameterSynchronizer pid=560802)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
[36m(ParameterSynchronizer pid=560802)[0m     *************************************************************************************************************
[36m(ParameterSynchronizer pid=560802)[0m     The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
[36m(ParameterSynchronizer pid=560802)[0m     The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
[36m(ParameterSynchronizer pid=560802)[0m     The backend in torch.distributed.init_process_group set to hccl now..
[36m(ParameterSynchronizer pid=560802)[0m     The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
[36m(ParameterSynchronizer pid=560802)[0m     The device parameters have been replaced with npu in the function below:
[36m(ParameterSynchronizer pid=560802)[0m     torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
[36m(ParameterSynchronizer pid=560802)[0m     *************************************************************************************************************
[36m(ParameterSynchronizer pid=560802)[0m     
[36m(ParameterSynchronizer pid=560802)[0m   warnings.warn(msg, ImportWarning)
[36m(ParameterSynchronizer pid=560802)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
[36m(ParameterSynchronizer pid=560802)[0m   warnings.warn(msg, RuntimeWarning)
[36m(ParameterSynchronizer pid=560802)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(ParameterSynchronizer pid=560802)[0m /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/dynamo/torchair/__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(ParameterSynchronizer pid=560802)[0m   import pkg_resources

[36m(FullyAsyncTaskRunner pid=545998)[0m [ASYNC MAIN] FullyAsyncTrainer created and initialized successfully
[36m(FullyAsyncTaskRunner pid=545998)[0m total_train_steps 29
[36m(FullyAsyncTaskRunner pid=545998)[0m [ASYNC MAIN] Creating MessageQueue... max_queue_size 307
[36m(WorkerDict pid=558093)[0m Overridden TransformerConfig init config: {'num_layers': 24, 'hidden_size': 896, 'num_attention_heads': 14, 'num_query_groups': 2, 'ffn_hidden_size': 4864, 'attention_dropout': 0.0, 'hidden_dropout': 0.0, 'kv_channels': None, 'layernorm_epsilon': 1e-06, 'add_bias_linear': False, 'activation_func': <function silu at 0xffff99489090>, 'normalization': 'RMSNorm', 'gated_linear_unit': True, 'pipeline_dtype': torch.bfloat16, 'params_dtype': torch.bfloat16, 'bf16': True, 'tensor_model_parallel_size': 1, 'pipeline_model_parallel_size': 1, 'expert_model_parallel_size': 1, 'expert_tensor_parallel_size': 1, 'virtual_pipeline_model_parallel_size': None, 'context_parallel_size': 1, 'overlap_p2p_comm': False, 'batch_p2p_comm': False, 'sequence_parallel': False, 'variable_seq_lengths': True, 'masked_softmax_fusion': True, 'moe_token_dispatcher_type': 'alltoall', 'use_cpu_initialization': False, 'add_qkv_bias': True, 'qk_layernorm': False}
[36m(FullyAsyncTaskRunner pid=545998)[0m [ASYNC MAIN] Setting up parameter synchronization...
[36m(FullyAsyncTrainer pid=555857)[0m Checkpoint tracker file does not exist: /home/ma-user/work/verl/checkpoints/GRPO-Qwen2.5-0.5b-Base-MATH/GRPO-Qwen2.5-0.5b-Base-MATH-2gpu-async/latest_checkpointed_iteration.txt
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Training from scratch
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter] Training from scratch (no checkpoint found)
[36m(MessageQueue pid=560789)[0m [MessageQueue] initialized with max_queue_size=307,staleness_threshold=0.2
[36m(WorkerDict pid=558094)[0m actor_module: 1
[36m(WorkerDict pid=558094)[0m load from local dir /home/ma-user/work/models/Qwen2.5-0.5B-Instruct
[36m(ParameterSynchronizer pid=560802)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:20:26,843 INFO [mindspeed.megatron_adaptor:33] => start to patch features in megatron adaptor.
[36m(WorkerDict pid=558093)[0m TransformerConfig(tensor_model_parallel_size=1, pipeline_model_parallel_comm_backend=None, pipeline_model_parallel_size=1, virtual_pipeline_model_parallel_size=None, sequence_parallel=False, context_parallel_size=1, hierarchical_context_parallel_sizes=None, expert_model_parallel_size=1, expert_tensor_parallel_size=1, moe_extended_tp=False, perform_initialization=True, use_cpu_initialization=False, fp16=False, bf16=True, params_dtype=torch.bfloat16, timers=None, finalize_model_grads_func=<function finalize_model_grads at 0xffcf3cf2ca60>, grad_scale_func=<bound method MegatronOptimizer.scale_loss of <megatron.core.optimizer.optimizer.ChainedOptimizer object at 0xffcf2ce1c580>>, no_sync_func=None, grad_sync_func=None, param_sync_func=None, deterministic_mode=False, enable_autocast=False, autocast_dtype=torch.bfloat16, num_microbatches_with_partial_activation_checkpoints=None, gradient_accumulation_fusion=True, async_tensor_model_parallel_allreduce=False, use_te_rng_tracker=False, tp_comm_overlap=False, tp_comm_bulk_wgrad=True, tp_comm_bulk_dgrad=True, tp_comm_overlap_ag=True, tp_comm_overlap_rs=True, tp_comm_overlap_rs_dgrad=False, tp_comm_split_ag=True, tp_comm_atomic_ag=False, tp_comm_split_rs=True, tp_comm_atomic_rs=False, cross_entropy_loss_fusion=False, cross_entropy_fusion_impl='native', tp_comm_overlap_disable_qkv=False, tp_comm_overlap_disable_fc1=False, tp_comm_bootstrap_backend='nccl', pipeline_dtype=torch.bfloat16, variable_seq_lengths=True, overlap_p2p_comm=False, batch_p2p_comm=False, batch_p2p_sync=True, use_ring_exchange_p2p=False, deallocate_pipeline_outputs=True, defer_embedding_wgrad_compute=False, wgrad_deferral_limit=0, pipeline_model_parallel_split_rank=None, overlap_p2p_comm_warmup_flush=False, microbatch_group_size_per_vp_stage=1, cpu_offloading=False, cpu_offloading_num_layers=0, _cpu_offloading_context=None, cpu_offloading_activations=True, cpu_offloading_weights=True, barrier_with_L1_time=True, num_layers=24, mtp_num_layers=None, mtp_loss_scaling_factor=None, num_layers_in_first_pipeline_stage=None, num_layers_in_last_pipeline_stage=None, account_for_embedding_in_pipeline_split=False, account_for_loss_in_pipeline_split=False, hidden_size=896, num_attention_heads=14, attention_backend=<AttnBackend.flash: 1>, softmax_scale=None, num_query_groups=2, ffn_hidden_size=4864, kv_channels=64, hidden_dropout=0.0, attention_dropout=0.0, fp32_residual_connection=False, apply_residual_connection_post_layernorm=False, layernorm_epsilon=1e-06, layernorm_zero_centered_gamma=False, add_bias_linear=False, add_qkv_bias=True, gated_linear_unit=True, activation_func=<function silu at 0xffff99489090>, activation_func_fp8_input_store=False, num_moe_experts=None, rotary_interleaved=False, window_size=None, normalization='RMSNorm', qk_layernorm=False, test_mode=False, calculate_per_token_loss=False, multi_latent_attention=False, init_method=functools.partial(<function normal_ at 0xffff20391cf0>, mean=0.0, std=0.02), output_layer_init_method=functools.partial(<function normal_ at 0xffff20391cf0>, mean=0.0, std=0.002886751345948129), init_method_std=0.02, init_model_with_meta_device=False, apply_query_key_layer_scaling=False, attention_softmax_in_fp32=True, disable_bf16_reduced_precision_matmul=False, bias_activation_fusion=True, masked_softmax_fusion=True, persist_layer_norm=True, memory_efficient_layer_norm=False, bias_dropout_fusion=True, apply_rope_fusion=True, recompute_granularity=None, recompute_method=None, recompute_num_layers=None, distribute_saved_activations=None, recompute_modules=['core_attn'], fp8=None, fp8_recipe='delayed', fp8_param=False, fp8_margin=0, fp8_interval=1, fp8_amax_history_len=1, fp8_amax_compute_algo='most_recent', fp8_wgrad=True, fp8_dot_product_attention=False, fp8_multi_head_attention=False, tp_only_amax_red=False, first_last_layers_bf16=False, num_layers_at_start_in_bf16=1, num_layers_at_end_in_bf16=1, moe_shared_expert_intermediate_size=None, moe_shared_expert_overlap=False, moe_layer_freq=1, moe_ffn_hidden_size=4864, moe_router_load_balancing_type='aux_loss', moe_router_topk=2, moe_router_topk_limited_devices=None, moe_router_num_groups=None, moe_router_group_topk=None, moe_router_pre_softmax=False, moe_router_topk_scaling_factor=None, moe_router_score_function='softmax', moe_router_dtype=None, moe_router_enable_expert_bias=False, moe_router_bias_update_rate=0.001, moe_grouped_gemm=False, moe_use_legacy_grouped_gemm=False, moe_aux_loss_coeff=0, moe_z_loss_coeff=None, moe_input_jitter_eps=None, moe_token_dropping=False, moe_token_dispatcher_type='alltoall', moe_enable_deepep=False, moe_per_layer_logging=False, moe_expert_capacity_factor=None, moe_pad_expert_input_to_capacity=False, moe_token_drop_policy='probs', moe_layer_recompute=False, moe_permute_fusion=False, moe_apply_probs_on_input=False, cp_comm_type=None, enable_cuda_graph=False, cuda_graph_use_single_mempool=False, cuda_graph_retain_backward_graph=False, cuda_graph_warmup_steps=3, external_cuda_graph=False, cuda_graph_scope='full', clone_scatter_output_in_embedding=True, disable_parameter_transpose_cache=False, config_logger_dir='', flash_decode=False, inference_rng_tracker=False, mrope_section=None, is_hybrid_model=False, mamba_state_dim=128, mamba_head_dim=64, mamba_num_groups=8, heterogeneous_block_specs=False, optimizer_selection='fused_adamw', optimization_level=2, use_fused_rmsnorm=True, use_fused_swiglu=False, use_gmm_fp8=True, te_comparison_with_cpu=False, te_comparison_with_bf16=False, context_parallel_algo='megatron_cp_algo', cp_window_size=1, attention_mask_type='causal', use_cp_send_recv_overlap=False, use_fused_ring_attention_update=False, megatron_cp_in_bnsd=False, ulysses_degree_in_cp=None, context_parallel_kv_cache_policy=None, context_parallel_cache_interval=0, use_ulysses_allgather_kv=False, attention_mask_on_cpu=False, adaptive_cp_without_coarse=False, adaptive_cp_dynamic_attn_mask=False, adaptive_cp_only_reschedule=False, adaptive_cp_manually_set_mask_list=False, async_log_allreduce=False, use_fused_rotary_pos_emb=False, use_fused_moe_token_permute_and_unpermute=False, npu_deterministic=False, op_cal_tflops=False, profile_level='level0', profile_with_cpu=False, profile_with_stack=False, profile_with_memory=False, profile_record_shapes=False, profile_save_path='./profile_dir', recompute_activation_function=False, recompute_activation_function_num_layers=None, recompute_norm=False, recompute_norm_num_layers=None, enable_recompute_layers_per_pp_rank=False, unaligned_linear=False, use_ascend_mc2=False, use_ascend_coc=False, coc_mode=-1, coc_parallel_num=1, coc_fused_kernel=False, tp_2d=False, tp_x=1, tp_y=1, enable_overlap_ag_with_matmul=False, enable_overlap_matmul_with_rs=False, enable_backward_overlap_ag_with_matmul=False, recompute_in_bubble=False, recompute_in_advance=False, noop_layers=None, use_multiparameter_pipeline_model_parallel=False, optimize_send_recv_comm=False, pipeline_num_transformer_layers=None, schedules_method=None, dualpipev_dw_detach=False, gemm_gradient_accumulation_fusion=False, moe_tp_extend_ep=False, moe_permutation_async_comm=False, n_shared_experts=None, moe_allgather_overlap_comm=False, moe_alltoall_overlap_comm=False, moe_zero_memory='disable', moe_zero_memory_num_layers=None, moe_fb_overlap=False, moe_unperm2_mem_optim_swap=False, balanced_moe_experts=False, balanced_moe_hot_expert_num=3, trans_hot_expert_group_num=4, enable_expert_placement=False, expert_placement_freq=50, enable_fine_grained_expert_placement=False, print_expert_load=False, fine_grained_expert_placement_thre=0.08, hccl_group_buffer=None, hccl_group_buffer_adaptive=False, hccl_ep_group_buffer_adaptive_factor=-1.0, ema_decay=0.9999, virtual_optimizer=None, quant_states=None, quant_grads=False, dist_train=False, tokenizer_name_or_path=None, tokenizer_not_use_fast=True, param_and_grad_buffer_pad=None, layerzero=False, layerzero_config=None, fsdp2_config_path=None, reset_bucket_group_order=False, reuse_fp32_param=False, smart_swap=False, swap_attention=False, swap_modules='input_norm,self_attention,post_attention_norm', compress_dense='disable', disable_gloo_group=False, hccl_slice_size=10485760, swap_optimizer=False, swap_optimizer_times=16, pre_tockens=65536, next_tockens=0, sparse_mode=0, use_fusion_attn_v2=False, square_alibi_mask=False, fill_neg_inf=False, alibi_fusion_attn_type=None, alibi_diagonal_opposite=False, multi_head_latent_attention=False, qk_rope_head_dim=None, qk_nope_head_dim=None, ai_framework='pytorch', auto_settings=False, auto_settings_work_dir='/home/ma-user/work/verl', auto_settings_ranks=8, auto_settings_log_level='info', target_nnodes=1, nnodes=1, nproc_per_node=1, node_rank=0, auto_settings_type='white', prof_file=None, master_addr='127.0.0.1', master_port=29500, automated_pipeline=False, automated_pipeline_perf=False, recompute_module_list=None, jit_compile=False, node_ip_address='172.16.0.134', node_manager_port='37775', object_store_name='/tmp/ray/session_2026-01-06_00-16-38_348629_537872/sockets/plasma_store', raylet_name='/tmp/ray/session_2026-01-06_00-16-38_348629_537872/sockets/raylet', redis_address='None', metrics_agent_port='40808', logging_rotate_bytes='536870912', logging_rotate_backup_count='5', runtime_env_agent_port='60354', gcs_address='172.16.0.134:63965', session_name='session_2026-01-06_00-16-38_348629_537872', temp_dir='/tmp/ray', webui='127.0.0.1:8265', cluster_id='8bb71ebab51e5be621315fd2401efe6354f0b4a381c0513ce2d8f9a4', startup_token='113', worker_launch_time_ms='1767629969316', node_id='508e57c33c8c9d9025124c7d81a774571b7e4fdcb57d8007605d5d43', runtime_env_hash='1276635623', quant_states_enabled=False, quant_grads_dtype=None, use_quant_optimizer=False, use_flash_attn=True)[36m(ParameterSynchronizer pid=560802)[0m /home/ma-user/work/verl/verl/workers/megatron_workers.py:54: UserWarning: NPU not support router replay for now.
[36m(ParameterSynchronizer pid=560802)[0m   from verl.utils.megatron.router_replay_patch import RouterReplay, RouterReplayAction, apply_router_replay_patch
[36m(ParameterSynchronizer pid=560802)[0m /home/ma-user/work/verl/verl/workers/actor/megatron_actor.py:44: UserWarning: NPU not support router replay for now.
[36m(ParameterSynchronizer pid=560802)[0m   from verl.utils.megatron.router_replay_utils import (
[36m(WorkerDict pid=552781)[0m Using blocking ray.get inside async actor. This blocks the event loop. Please use `await` on object ref with asyncio.gather if you want to yield execution to the event loop instead.
[36m(HCCLRootInfoStore pid=561960)[0m The HcclRootInfo has not been set yet for store e84586912c94c03609371070bb3c047ffe9ec615.
[36m(FullyAsyncRollouter pid=551476)[0m /home/ma-user/work/verl/verl/experimental/agent_loop/agent_loop.py:809: RuntimeWarning: coroutine 'FullyAsyncAgentLoopManager.wake_up' was never awaited
[36m(FullyAsyncRollouter pid=551476)[0m   self.wake_up()
[36m(WorkerDict pid=558093)[0m Using blocking ray.get inside async actor. This blocks the event loop. Please use `await` on object ref with asyncio.gather if you want to yield execution to the event loop instead.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=552781)[0m [rank0]:[W106 00:20:47.321483322 compiler_depend.ts:117] Warning: Driver Version: 9 is invalid or not supported yet. (function operator())
[36m(FullyAsyncAgentLoopWorker pid=555842)[0m You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[36m(FullyAsyncAgentLoopWorker pid=555848)[0m You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[36m(FullyAsyncAgentLoopWorker pid=555832)[0m You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
[36m(FullyAsyncAgentLoopWorker pid=555853)[0m You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.[32m [repeated 5x across cluster][0m
[36m(FullyAsyncRollouter pid=551476)[0m /home/ma-user/work/verl/verl/experimental/agent_loop/agent_loop.py:822: RuntimeWarning: coroutine 'FullyAsyncAgentLoopManager.sleep' was never awaited
[36m(FullyAsyncRollouter pid=551476)[0m   self.sleep()

[36m(WorkerDict pid=558093)[0m routing replay layers: 0
[36m(WorkerDict pid=558093)[0m [Warining] Because actor tp size == 1, set sp to False
[36m(FullyAsyncRollouter pid=551476)[0m Checkpoint tracker file does not exist: /home/ma-user/work/verl/checkpoints/GRPO-Qwen2.5-0.5b-Base-MATH/GRPO-Qwen2.5-0.5b-Base-MATH-2gpu-async/latest_checkpointed_iteration.txt
[33m(raylet)[0m It looks like you're creating a detached actor in an anonymous namespace. In order to access this actor in the future, you will need to explicitly connect to this namespace with ray.init(namespace="9400cf97-ff2c-412a-acf1-6510da499c8b", ...)
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Initializing parameter synchronization group...
[36m(WorkerDict pid=558093)[0m 
[36m(WorkerDict pid=558093)[0m [DEBUG_UUID] 开始查找: Container PID=558093, Searching in 4 NPUs...
[36m(WorkerDict pid=558094)[0m 
[36m(WorkerDict pid=558093)[0m --- [DEBUG_UUID] Checking NPU ID: 0 ---
[36m(WorkerDict pid=558093)[0m Is PID 558093 in output? -> NO
[36m(WorkerDict pid=558093)[0m Is PID 558093 in output? -> YES
[36m(WorkerDict pid=558093)[0m [DEBUG_UUID] Found strict match! Returning UUID: 172.16.0.134-2
[36m(WorkerDict pid=552781)[0m 
[36m(WorkerDict pid=552782)[0m 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 0.02 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 0 to 0
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[33m(raylet)[0m It looks like you're creating a detached actor in an anonymous namespace. In order to access this actor in the future, you will need to explicitly connect to this namespace with ray.init(namespace="9400cf97-ff2c-412a-acf1-6510da499c8b", ...)
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 0 to 0 ,reset staleness_samples to: 0,idle_ratio: None
[36m(FullyAsyncRollouter pid=551476)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:20:42,558 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'green'}
[36m(WorkerDict pid=552782)[0m [DEBUG_UUID] 开始查找: Container PID=552782, Searching in 4 NPUs...[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=552782)[0m --- [DEBUG_UUID] Checking NPU ID: 1 ---[32m [repeated 9x across cluster][0m
[36m(WorkerDict pid=552782)[0m Is PID 552782 in output? -> NO[32m [repeated 5x across cluster][0m
[36m(WorkerDict pid=552782)[0m Is PID 552782 in output? -> YES[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=552782)[0m [DEBUG_UUID] Found strict match! Returning UUID: 172.16.0.134-1[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:6.027923107147217 seconds, while cache cost 3.814697265625e-06 seconds,  register cost 0.0031783580780029297 seconds, update cost 0.2765316963195801 seconds
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 6.06 seconds, pause:0.03s, sync:6.03s
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:5.369895696640015 seconds, while cache cost 0.8572690486907959 seconds,  register cost 0.13798260688781738 seconds, update cost 0.2765052318572998 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.6582136154174805 seconds, offload model to cpu cost 1.7799808979034424 seconds
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': True, 'validate': True, 'global_steps': 1}
[36m(RewardLoopWorker pid=558402)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:6.028066158294678 seconds, while cache cost 2.86102294921875e-06 seconds,  register cost 0.003177165985107422 seconds, update cost 0.2765634059906006 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:5.433363437652588 seconds, while cache cost 0.7737891674041748 seconds,  register cost 0.05555891990661621 seconds, update cost 0.27653932571411133 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.5949001312255859 seconds, offload model to cpu cost 2.5762202739715576 seconds
[36m(RewardLoopWorker pid=558312)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')[32m [repeated 5x across cluster][0m
[36m(FullyAsyncRollouter pid=551476)[0m validation generation end
[36m(FullyAsyncTaskRunner pid=545998)[0m [ASYNC MAIN] All components initialized successfully
[36m(FullyAsyncTaskRunner pid=545998)[0m [ASYNC MAIN] Starting Rollouter and Trainer...
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter] Starting FullyAsyncRollouter...
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter] Start streaming mode, maximum concurrent samples: 256
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Starting FullyAsyncTrainer...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 367.14 seconds
[36m(FullyAsyncTrainer pid=555857)[0m Saving tensorboard log to tensorboard_log/GRPO-Qwen2.5-0.5b-Base-MATH/GRPO-Qwen2.5-0.5b-Base-MATH-2gpu-async.
[36m(FullyAsyncTrainer pid=555857)[0m step:0 - val-aux/openai/gsm8k/reward/mean@1:-0.004548900682335102 - val-core/openai/gsm8k/acc/mean@1:0.001516300227445034 - val-aux/num_turns/min:2 - val-aux/num_turns/max:2 - val-aux/num_turns/mean:2.0
[36m(FullyAsyncTrainer pid=555857)[0m ('[FullyAsyncTrainer] parameter version: 0 Validation metrics: '
[36m(FullyAsyncTrainer pid=555857)[0m  "{'val-aux/openai/gsm8k/reward/mean@1': -0.004548900682335102, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-core/openai/gsm8k/acc/mean@1': 0.001516300227445034, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-aux/num_turns/min': 2, 'val-aux/num_turns/max': 2, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-aux/num_turns/mean': 2.0}")
[36m(FullyAsyncTrainer pid=555857)[0m step:0 - rollouter/validate_time:367.11671452596784
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:26:49,782 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(WorkerDict pid=558093)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(WorkerDict pid=558093)[0m Creating extension directory /home/ma-user/.cache/torch_extensions/py310_cpu/npu_matmul_add_fp32...
[36m(WorkerDict pid=558094)[0m Emitting ninja build file /home/ma-user/.cache/torch_extensions/py310_cpu/npu_matmul_add_fp32/build.ninja...
[36m(WorkerDict pid=558094)[0m Building extension module npu_matmul_add_fp32...
[36m(WorkerDict pid=558094)[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[36m(WorkerDict pid=558094)[0m Loading extension module npu_matmul_add_fp32...
[36m(WorkerDict pid=558094)[0m Using /home/ma-user/.cache/torch_extensions/py310_cpu as PyTorch extensions root...
[36m(WorkerDict pid=558094)[0m Creating extension directory /home/ma-user/.cache/torch_extensions/py310_cpu/npu_matmul_add_fp32...
[36m(WorkerDict pid=558093)[0m [rank0]:[W106 00:28:38.992644763 compiler_depend.ts:67] Warning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (function operator())
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 59.14 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.33s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 70,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 237,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 6,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558093)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:27:52,455 WARNING [mindspeed.core.fusions.fused_rope:107] => Setting apply_rope_fusion to false because its implementation is not included in Apex. Try upgrading to the latest version
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=100, queue_size=36
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=200, queue_size=136
[36m(WorkerDict pid=558094)[0m [Rank 1 | Local Rank 0] 2026-01-06 00:27:52,455 WARNING [mindspeed.core.fusions.fused_rope:107] => Setting apply_rope_fusion to false because its implementation is not included in Apex. Try upgrading to the latest version
[36m(WorkerDict pid=558094)[0m [1/4] c++ -MMD -MF flop_counter.o.d -DTORCH_EXTENSION_NAME=npu_matmul_add_fp32 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -I/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/include -I/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/include/third_party/hccl/inc -I/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/include/third_party/acl/inc -I/usr/local/Ascend/ascend-toolkit/latest/include -I/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/include/third_party/acl/inc -I/home/ma-user/work/MindSpeed/mindspeed/ops/csrc/atb/extensions/inc -I/usr/local/Ascend/nnal/atb/latest/atb/cxx_abi_1/include -isystem /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch/include -isystem /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/ma-user/.conda/envs/test01/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -fstack-protector-all -Wl,-z,relro,-z,now,-z,noexecstack -fPIC -pie -s -fvisibility=hidden -D_FORTIFY_SOURCE=2 -O2 -Wno-sign-compare -Wno-deprecated-declarations -Wno-return-type -D__FILENAME__='"$(notdir $(abspath $<))"' -D ENABLE_ATB -fstack-protector-all -Wl,-z,relro,-z,now,-z,noexecstack -fPIC -pie -s -c /home/ma-user/work/MindSpeed/mindspeed/ops/csrc/flop_counter/flop_counter.cpp -o flop_counter.o 
[36m(WorkerDict pid=558094)[0m [2/4] c++ -MMD -MF atb_adapter.o.d -DTORCH_EXTENSION_NAME=npu_matmul_add_fp32 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -I/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/include -I/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/include/third_party/hccl/inc -I/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/include/third_party/acl/inc -I/usr/local/Ascend/ascend-toolkit/latest/include -I/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/include/third_party/acl/inc -I/home/ma-user/work/MindSpeed/mindspeed/ops/csrc/atb/extensions/inc -I/usr/local/Ascend/nnal/atb/latest/atb/cxx_abi_1/include -isystem /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch/include -isystem /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/ma-user/.conda/envs/test01/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -fstack-protector-all -Wl,-z,relro,-z,now,-z,noexecstack -fPIC -pie -s -fvisibility=hidden -D_FORTIFY_SOURCE=2 -O2 -Wno-sign-compare -Wno-deprecated-declarations -Wno-return-type -D__FILENAME__='"$(notdir $(abspath $<))"' -D ENABLE_ATB -fstack-protector-all -Wl,-z,relro,-z,now,-z,noexecstack -fPIC -pie -s -c /home/ma-user/work/MindSpeed/mindspeed/ops/csrc/atb/utils/atb_adapter.cpp -o atb_adapter.o 
[36m(WorkerDict pid=558094)[0m [3/4] c++ -MMD -MF matmul_add.o.d -DTORCH_EXTENSION_NAME=npu_matmul_add_fp32 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -I/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/include -I/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/include/third_party/hccl/inc -I/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/include/third_party/acl/inc -I/usr/local/Ascend/ascend-toolkit/latest/include -I/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/include/third_party/acl/inc -I/home/ma-user/work/MindSpeed/mindspeed/ops/csrc/atb/extensions/inc -I/usr/local/Ascend/nnal/atb/latest/atb/cxx_abi_1/include -isystem /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch/include -isystem /home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/ma-user/.conda/envs/test01/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -fstack-protector-all -Wl,-z,relro,-z,now,-z,noexecstack -fPIC -pie -s -fvisibility=hidden -D_FORTIFY_SOURCE=2 -O2 -Wno-sign-compare -Wno-deprecated-declarations -Wno-return-type -D__FILENAME__='"$(notdir $(abspath $<))"' -D ENABLE_ATB -fstack-protector-all -Wl,-z,relro,-z,now,-z,noexecstack -fPIC -pie -s -c /home/ma-user/work/MindSpeed/mindspeed/ops/csrc/atb/matmul_add.cpp -o matmul_add.o 
[36m(WorkerDict pid=558094)[0m [4/4] c++ matmul_add.o atb_adapter.o flop_counter.o -shared -L/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch_npu/lib -ltorch_npu -L/usr/local/Ascend/nnal/atb/latest/atb/cxx_abi_1/lib -lasdops -L/usr/local/Ascend/nnal/atb/latest/atb/cxx_abi_1/lib -llcal -L/usr/local/Ascend/nnal/atb/latest/atb/cxx_abi_1/lib -latb -L/home/ma-user/.conda/envs/test01/lib/python3.10/site-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o npu_matmul_add_fp32.so
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 294,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 13,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 230,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:   3%|████▉                                                                                                                                           | 1/29 [10:56<5:06:23, 656.55s/it]
[36m(WorkerDict pid=558093)[0m Loading extension module npu_matmul_add_fp32...
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 1 local_trigger_step: 1 trigger_parameter_sync_step: 4 00:28:57.138
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:28:57,141 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 166
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.56 seconds.mq_len: 166
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.35s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=300, queue_size=172
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 2 local_trigger_step: 2 trigger_parameter_sync_step: 4 00:29:33.134
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:29:33,137 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 112
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.44 seconds.mq_len: 112
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.31s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 3 local_trigger_step: 3 trigger_parameter_sync_step: 4 00:30:18.022
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:30:18,029 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 50
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.62 seconds.mq_len: 50
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.39s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 4 local_trigger_step: 4 trigger_parameter_sync_step: 4 00:31:06.069
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.000675201416015625
[36m(FullyAsyncTrainer pid=555857)[0m step:1 - fully_async/count/stale_samples_processed:0.0 - fully_async/count/stale_trajectory_processed:0.0 - fully_async/count/current_param_version:0.0 - fully_async/processing_time/avg:46.81093356974816 - fully_async/processing_time/max:94.31500108912587 - fully_async/processing_time/min:1.3653254471719265 - fully_async/processing_time/tp50:47.536953129805624 - fully_async/processing_time/tp99:74.18143415722996 - fully_async/processing_time/tp95:70.15807324294 - fully_async/monitor/active_tasks_size:198.25 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:48.0 - fully_async/count/total_generated_samples:192.0 - fully_async/count/staleness_samples:294.5 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:60.749863147735596 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:1.8695686662543591 - rollout_corr/training_log_ppl:0.4613218520308838 - rollout_corr/kl:0.0006023158563844778 - rollout_corr/k3_kl:0.0005867070620173432 - rollout_corr/rollout_ppl:1.8675867999728015 - rollout_corr/rollout_log_ppl:0.4607009549087916 - rollout_corr/log_ppl_diff:0.0006208976027012993 - rollout_corr/log_ppl_abs_diff:0.001752371347207703 - rollout_corr/log_ppl_diff_max:0.04000496864318848 - rollout_corr/log_ppl_diff_min:-0.008958399295806885 - rollout_corr/ppl_ratio:1.0006240397164192 - rollout_corr/chi2_token:0.0011522333534968484 - rollout_corr/chi2_seq:0.42323935844225585 - actor/kl_loss:0.0004007654240718897 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.00014180252355132082 - actor/ppo_kl:0.0006023158563844778 - actor/pg_clipfrac_lower:0.0 - actor/pg_loss:0.004078141867058593 - actor/grad_norm:0.20769229813887533 - perf/mfu/actor:0.04454259896194194 - perf/max_memory_allocated_gb:22.06147003173828 - perf/max_memory_reserved_gb:56.908203125 - perf/cpu_memory_used_gb:87.49483633041382 - actor/lr:5e-07 - training/global_step:4.0 - training/epoch:0.0 - critic/score/mean:0.01513671875 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.01513671875 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-0.004230920720146969 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-0.5400605201721191 - critic/returns/mean:-0.004230920720146969 - critic/returns/max:2.4748666286468506 - critic/returns/min:-0.5400605201721191 - response_length/mean:306.2919921875 - response_length/max:823.0 - response_length/min:4.0 - response_length/clip_ratio:0.0 - response_length_non_aborted/mean:306.2919921875 - response_length_non_aborted/max:823.0 - response_length_non_aborted/min:4.0 - response_length_non_aborted/clip_ratio:0.0 - response/aborted_ratio:0.0 - prompt_length/mean:103.26953125 - prompt_length/max:222.0 - prompt_length/min:73.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:62.97156383469701 - timing_s/reward:0.0010971613228321075 - timing_s/old_log_prob:0.001154884696006775 - timing_s/ref:56.748057931661606 - timing_s/adv:0.307494442909956 - timing_s/update_actor:136.12313191220164 - timing_s/step:256.15915723517537 - timing_per_token_ms/update_actor:0.11570159625574733 - timing_per_token_ms/adv:0.00031634065505476246 - timing_per_token_ms/ref:0.05703282105089684 - timing_per_token_ms/gen:0.005370155658702121 - perf/total_num_tokens:838782.0 - perf/time_per_step:256.15915723517537 - perf/throughput:818.6141079761678 - trainer/idle_ratio:0.24582983686538243
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(RewardLoopWorker pid=558329)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 3.83 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 0 to 1
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 0 to 1 ,reset staleness_samples to: 51,idle_ratio: 0.006097374913715092
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.5804846286773682 seconds, while cache cost 6.4373016357421875e-06 seconds,  register cost 0.0005240440368652344 seconds, update cost 0.12393450736999512 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:1 - timing_s/wait_last_valid:0.004427503794431686 - timing_s/param_sync:5.419926889240742
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:31:11,515 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 5.42 seconds, pause:3.83s, sync:1.59s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1248540878295898 seconds, while cache cost 0.8622579574584961 seconds,  register cost 0.13545513153076172 seconds, update cost 0.12399435043334961 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4571266174316406 seconds, offload model to cpu cost 1.648850679397583 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 1,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.5807127952575684 seconds, while cache cost 5.4836273193359375e-06 seconds,  register cost 0.0005843639373779297 seconds, update cost 0.12375664710998535 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.1313316822052002 seconds, while cache cost 0.7614097595214844 seconds,  register cost 0.05225801467895508 seconds, update cost 0.12393498420715332 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.45049595832824707 seconds, offload model to cpu cost 1.7401714324951172 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 45.16 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=400, queue_size=80
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 1,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 498,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 65,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 179,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=500, queue_size=180
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 5 local_trigger_step: 1 trigger_parameter_sync_step: 4 00:33:00.760
[36m(FullyAsyncTrainer pid=555857)[0m step:1 - rollouter/active_time:260.2375931739807 - rollouter/version_time:261.8340938091278 - rollouter/idle_ratio:0.006097374913715092
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:33:00,764 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 169
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.48 seconds.mq_len: 169
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.34s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 1,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 558,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 5,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 174,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:   7%|█████████▉                                                                                                                                      | 2/29 [15:07<3:07:57, 417.69s/it]
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 6 local_trigger_step: 2 trigger_parameter_sync_step: 4 00:33:42.522
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:33:42,525 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 110
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.49 seconds.mq_len: 110
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 7 local_trigger_step: 3 trigger_parameter_sync_step: 4 00:34:28.284
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:34:28,287 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 48
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.42 seconds.mq_len: 48
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 1,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 562,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 1,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 50,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 8 local_trigger_step: 4 trigger_parameter_sync_step: 4 00:35:16.567
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.00064849853515625
[36m(FullyAsyncTrainer pid=555857)[0m step:2 - fully_async/count/stale_samples_processed:51.0 - fully_async/count/stale_trajectory_processed:408.0 - fully_async/count/current_param_version:1.0 - fully_async/processing_time/avg:46.61738216239428 - fully_async/processing_time/max:258.5780410952866 - fully_async/processing_time/min:0.4823877029120922 - fully_async/processing_time/tp50:45.71448667161167 - fully_async/processing_time/tp99:82.27265368606894 - fully_async/processing_time/tp95:72.25904521578923 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:448.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:46.55531930923462 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:2.4846010774280094 - rollout_corr/training_log_ppl:0.6916108846248769 - rollout_corr/kl:0.029712484814058006 - rollout_corr/k3_kl:0.023308789442050986 - rollout_corr/rollout_ppl:2.3647943359353008 - rollout_corr/rollout_log_ppl:0.6553200594144603 - rollout_corr/log_ppl_diff:0.036290822308599174 - rollout_corr/log_ppl_abs_diff:0.03671512717521141 - rollout_corr/log_ppl_diff_max:1.0366917848587036 - rollout_corr/log_ppl_diff_min:-0.022650808095932007 - rollout_corr/ppl_ratio:1.039644841224748 - rollout_corr/chi2_token:0.1343054353215155 - rollout_corr/chi2_seq:0.1837241762238586 - actor/kl_loss:0.0008183835335533473 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.0060163152141472645 - actor/ppo_kl:0.02960263653770131 - actor/pg_clipfrac_lower:3.21921320866131e-05 - actor/pg_loss:0.013662541895682058 - actor/grad_norm:0.25880595281352003 - perf/mfu/actor:0.04331203536148587 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.443359375 - perf/cpu_memory_used_gb:93.7592830657959 - actor/lr:5e-07 - training/global_step:8.0 - training/epoch:0.0 - critic/score/mean:0.021484375 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.021484375 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.01320629334077239 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.01320629334077239 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:331.712890625 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.00048828125 - response_length_non_aborted/mean:331.712890625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.00048828125 - response/aborted_ratio:0.0 - prompt_length/mean:104.87109375 - prompt_length/max:179.0 - prompt_length/min:65.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:48.38747991248965 - timing_s/reward:0.0008445717394351959 - timing_s/old_log_prob:0.001027040183544159 - timing_s/ref:64.28654493764043 - timing_s/adv:0.24692774936556816 - timing_s/update_actor:132.03066787868738 - timing_s/step:244.95956009626389 - timing_per_token_ms/update_actor:0.12811760637709987 - timing_per_token_ms/adv:0.00023060142855368945 - timing_per_token_ms/ref:0.065702774123745 - timing_per_token_ms/gen:0.004532855562969179 - perf/total_num_tokens:894124.0 - perf/time_per_step:244.95956009626389 - perf/throughput:912.5220502198692 - trainer/idle_ratio:0.1975325228926538
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 113.05 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 1 to 2
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 1 to 2 ,reset staleness_samples to: 51,idle_ratio: 0.004502772421820511
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.6036629676818848 seconds, while cache cost 8.821487426757812e-06 seconds,  register cost 0.0005259513854980469 seconds, update cost 0.12489008903503418 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:2 - timing_s/wait_last_valid:0.0030975602567195892 - timing_s/param_sync:114.66398626193404
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:37:11,255 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 114.66 seconds, pause:113.05s, sync:1.61s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1281123161315918 seconds, while cache cost 0.7874801158905029 seconds,  register cost 0.21295452117919922 seconds, update cost 0.12497568130493164 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.47612643241882324 seconds, offload model to cpu cost 1.6307528018951416 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 2,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 563,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558094)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.6033246517181396 seconds, while cache cost 6.9141387939453125e-06 seconds,  register cost 0.00054168701171875 seconds, update cost 0.12478280067443848 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.0967166423797607 seconds, while cache cost 0.7579424381256104 seconds,  register cost 0.04161691665649414 seconds, update cost 0.12489032745361328 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.5068635940551758 seconds, offload model to cpu cost 1.5983383655548096 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 41.19 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=600, queue_size=24
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=700, queue_size=124
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 2,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 747,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 72,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 171,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=800, queue_size=224
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 9 local_trigger_step: 1 trigger_parameter_sync_step: 4 00:38:51.663
[36m(FullyAsyncTrainer pid=555857)[0m step:2 - rollouter/active_time:358.1084530353546 - rollouter/version_time:359.72822737693787 - rollouter/idle_ratio:0.004502772421820511
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:38:51,667 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 162
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.41 seconds.mq_len: 162
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.36s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 2,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 813,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 6,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 173,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 10 local_trigger_step: 2 trigger_parameter_sync_step: 4 00:39:35.898
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  10%|██████████████▉                                                                                                                                 | 3/29 [21:03<2:48:48, 389.56s/it]
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:39:35,902 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 109
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.40 seconds.mq_len: 109
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.34s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 11 local_trigger_step: 3 trigger_parameter_sync_step: 4 00:40:23.146
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:40:23,149 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 49
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.44 seconds.mq_len: 49
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.34s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 12 local_trigger_step: 4 trigger_parameter_sync_step: 4 00:41:12.637
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006458759307861328
[36m(FullyAsyncTrainer pid=555857)[0m step:3 - fully_async/count/stale_samples_processed:102.0 - fully_async/count/stale_trajectory_processed:816.0 - fully_async/count/current_param_version:2.0 - fully_async/processing_time/avg:46.23232754752826 - fully_async/processing_time/max:356.52716486901045 - fully_async/processing_time/min:0.6149268075823784 - fully_async/processing_time/tp50:46.61164515512064 - fully_async/processing_time/tp99:82.55883538585154 - fully_async/processing_time/tp95:70.79270135546103 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:704.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:42.44399333000183 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:3.8063108836040667 - rollout_corr/training_log_ppl:0.8860529924789544 - rollout_corr/kl:0.06854788972330039 - rollout_corr/k3_kl:0.05398355811509546 - rollout_corr/rollout_ppl:2.978504489649318 - rollout_corr/rollout_log_ppl:0.7894963522421685 - rollout_corr/log_ppl_diff:0.09655664076543767 - rollout_corr/log_ppl_abs_diff:0.09673000178612531 - rollout_corr/log_ppl_diff_max:3.3345513343811035 - rollout_corr/log_ppl_diff_min:-0.035868287086486816 - rollout_corr/ppl_ratio:1.155986545770929 - rollout_corr/chi2_token:0.5014198173496639 - rollout_corr/chi2_seq:-0.8707151329623105 - actor/kl_loss:0.0017147777942234906 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.010179077711959408 - actor/ppo_kl:0.06817456468341908 - actor/pg_clipfrac_lower:9.347272951125982e-05 - actor/pg_loss:0.026333739216128606 - actor/grad_norm:0.30898225962462883 - perf/mfu/actor:0.043110565152548005 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.501953125 - perf/cpu_memory_used_gb:93.89944410324097 - actor/lr:5e-07 - training/global_step:12.0 - training/epoch:0.0 - critic/score/mean:0.02171802520751953 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.02171802520751953 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.02637281670467928 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.02637281670467928 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:330.18212890625 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.00048828125 - response_length_non_aborted/mean:330.18212890625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.00048828125 - response/aborted_ratio:0.0 - prompt_length/mean:104.3203125 - prompt_length/max:201.0 - prompt_length/min:69.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:44.57173169404268 - timing_s/reward:0.0011564455926418304 - timing_s/old_log_prob:0.0011053383350372314 - timing_s/ref:66.22213450446725 - timing_s/adv:0.24585317820310593 - timing_s/update_actor:130.20716320723295 - timing_s/step:241.2555327489972 - timing_per_token_ms/update_actor:0.12994167010408766 - timing_per_token_ms/adv:0.0002348560653679694 - timing_per_token_ms/ref:0.06743052375266602 - timing_per_token_ms/gen:0.005263052619066536 - perf/total_num_tokens:889861.0 - perf/time_per_step:241.2555327489972 - perf/throughput:922.1146038190691 - trainer/idle_ratio:0.18474905502132136
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(RewardLoopWorker pid=558400)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 127.50 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 2 to 3
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 2 to 3 ,reset staleness_samples to: 51,idle_ratio: 0.004309728996654605
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.5832743644714355 seconds, while cache cost 7.152557373046875e-06 seconds,  register cost 0.0005161762237548828 seconds, update cost 0.12528133392333984 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:3 - timing_s/wait_last_valid:0.00311848521232605 - timing_s/param_sync:129.092908449471
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:43:21,756 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 129.09 seconds, pause:127.50s, sync:1.59s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.081261157989502 seconds, while cache cost 0.7405359745025635 seconds,  register cost 0.0363459587097168 seconds, update cost 0.12531304359436035 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.5013935565948486 seconds, offload model to cpu cost 1.5824735164642334 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 3,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 819,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558094)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.5825130939483643 seconds, while cache cost 7.867813110351562e-06 seconds,  register cost 0.0005123615264892578 seconds, update cost 0.1252307891845703 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1197316646575928 seconds, while cache cost 0.776911735534668 seconds,  register cost 0.2146167755126953 seconds, update cost 0.12530159950256348 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.46434926986694336 seconds, offload model to cpu cost 1.6315226554870605 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 43.30 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=900, queue_size=68
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 3,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 999,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 76,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 167,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=1000, queue_size=168
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 13 local_trigger_step: 1 trigger_parameter_sync_step: 4 00:45:04.117
[36m(FullyAsyncTrainer pid=555857)[0m step:3 - rollouter/active_time:368.8952486515045 - rollouter/version_time:370.4919686317444 - rollouter/idle_ratio:0.004309728996654605
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:45:04,121 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 162
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.38 seconds.mq_len: 162
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 3,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 1067,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 8,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 171,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 14 local_trigger_step: 2 trigger_parameter_sync_step: 4 00:45:47.246
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:45:47,249 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 109
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.38 seconds.mq_len: 109
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 15 local_trigger_step: 3 trigger_parameter_sync_step: 4 00:46:34.850
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:46:34,853 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 47
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  14%|███████████████████▊                                                                                                                            | 4/29 [27:15<2:39:27, 382.69s/it]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.47 seconds.mq_len: 47
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 16 local_trigger_step: 4 trigger_parameter_sync_step: 4 00:47:24.798
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006389617919921875
[36m(FullyAsyncTrainer pid=555857)[0m step:4 - fully_async/count/stale_samples_processed:153.0 - fully_async/count/stale_trajectory_processed:1224.0 - fully_async/count/current_param_version:3.0 - fully_async/processing_time/avg:46.60536976919684 - fully_async/processing_time/max:367.74070059508085 - fully_async/processing_time/min:0.5841963440179825 - fully_async/processing_time/tp50:46.59791876282543 - fully_async/processing_time/tp99:84.55939457946452 - fully_async/processing_time/tp95:69.02105041299947 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:960.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:44.520137310028076 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:2.6201038493625086 - rollout_corr/training_log_ppl:0.6296666288877429 - rollout_corr/kl:0.017083138484741512 - rollout_corr/k3_kl:0.012965636497830219 - rollout_corr/rollout_ppl:2.496499577934056 - rollout_corr/rollout_log_ppl:0.6114949639400463 - rollout_corr/log_ppl_diff:0.018171662842508107 - rollout_corr/log_ppl_abs_diff:0.019736422821207907 - rollout_corr/log_ppl_diff_max:1.8730586767196655 - rollout_corr/log_ppl_diff_min:-0.11702585220336914 - rollout_corr/ppl_ratio:1.021986483186808 - rollout_corr/chi2_token:0.044534851456454645 - rollout_corr/chi2_seq:0.3826217211765077 - actor/kl_loss:0.003145941993773789 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.001897408166256109 - actor/ppo_kl:0.017072075579825083 - actor/pg_clipfrac_lower:9.298717621412059e-06 - actor/pg_loss:0.024095196022396577 - actor/grad_norm:0.33839165803794713 - perf/mfu/actor:0.04244696658544704 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.501953125 - perf/cpu_memory_used_gb:94.173330783844 - actor/lr:5e-07 - training/global_step:16.0 - training/epoch:0.0 - critic/score/mean:0.0439453125 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.0439453125 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.025011143181473017 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.025011143181473017 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:324.48486328125 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.0009765625 - response_length_non_aborted/mean:324.48486328125 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.0009765625 - response/aborted_ratio:0.0 - prompt_length/mean:105.31640625 - prompt_length/max:182.0 - prompt_length/min:68.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:46.82598775997758 - timing_s/reward:0.0008502453565597534 - timing_s/old_log_prob:0.0009973607957363129 - timing_s/ref:65.64270920678973 - timing_s/adv:0.23771706596016884 - timing_s/update_actor:130.24105952307582 - timing_s/step:242.95533269643784 - timing_per_token_ms/update_actor:0.12949357189322713 - timing_per_token_ms/adv:0.00021314955242488122 - timing_per_token_ms/ref:0.06715395347635876 - timing_per_token_ms/gen:0.005018001366545684 - perf/total_num_tokens:880233.0 - perf/time_per_step:242.95533269643784 - perf/throughput:905.7559986754983 - trainer/idle_ratio:0.1927349658897367
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 3,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 1073,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 2,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 49,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 18.95 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 3 to 4
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 3 to 4 ,reset staleness_samples to: 51,idle_ratio: 0.006006900457694364
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.570389986038208 seconds, while cache cost 6.4373016357421875e-06 seconds,  register cost 0.0004954338073730469 seconds, update cost 0.12394547462463379 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:4 - timing_s/wait_last_valid:0.0030152611434459686 - timing_s/param_sync:20.52591548487544
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:47:45,349 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 20.52 seconds, pause:18.95s, sync:1.58s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1122329235076904 seconds, while cache cost 0.7693700790405273 seconds,  register cost 0.21614575386047363 seconds, update cost 0.12397551536560059 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.45908355712890625 seconds, offload model to cpu cost 1.5987255573272705 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 34.90 seconds.mq_len: 0
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.5701992511749268 seconds, while cache cost 5.7220458984375e-06 seconds,  register cost 0.0004906654357910156 seconds, update cost 0.12393641471862793 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.1241092681884766 seconds, while cache cost 0.7175655364990234 seconds,  register cost 0.042144060134887695 seconds, update cost 0.12387800216674805 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4471547603607178 seconds, offload model to cpu cost 1.5992364883422852 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.37s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=1100, queue_size=12
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 4,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 1123,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 208,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 35,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=1200, queue_size=112
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=1300, queue_size=212
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 17 local_trigger_step: 1 trigger_parameter_sync_step: 4 00:49:20.021
[36m(FullyAsyncTrainer pid=555857)[0m step:4 - rollouter/active_time:262.00930285453796 - rollouter/version_time:263.5926778316498 - rollouter/idle_ratio:0.006006900457694364
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:49:20,025 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 172
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.44 seconds.mq_len: 172
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 4,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 1330,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 1,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 178,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 18 local_trigger_step: 2 trigger_parameter_sync_step: 4 00:50:03.372
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:50:03,375 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 115
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.43 seconds.mq_len: 115
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 4,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 1331,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 115,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 19 local_trigger_step: 3 trigger_parameter_sync_step: 4 00:50:46.626
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:50:46,629 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 51
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.47 seconds.mq_len: 51
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  17%|████████████████████████▊                                                                                                                       | 5/29 [31:24<2:13:50, 334.61s/it]
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.31s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 20 local_trigger_step: 4 trigger_parameter_sync_step: 4 00:51:34.159
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006799697875976562
[36m(FullyAsyncTrainer pid=555857)[0m step:5 - fully_async/count/stale_samples_processed:204.0 - fully_async/count/stale_trajectory_processed:1632.0 - fully_async/count/current_param_version:4.0 - fully_async/processing_time/avg:40.34020927385427 - fully_async/processing_time/max:260.5666801817715 - fully_async/processing_time/min:0.3352903611958027 - fully_async/processing_time/tp50:41.15657890122384 - fully_async/processing_time/tp99:79.82198479083365 - fully_async/processing_time/tp95:65.18684266372583 - fully_async/monitor/active_tasks_size:147.25 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:1216.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:36.2348895072937 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:2.7665112174420243 - rollout_corr/training_log_ppl:0.7319057750531318 - rollout_corr/kl:0.012974837874615428 - rollout_corr/k3_kl:0.010832597535060051 - rollout_corr/rollout_ppl:2.627833384827331 - rollout_corr/rollout_log_ppl:0.7070720655097303 - rollout_corr/log_ppl_diff:0.024833710364580333 - rollout_corr/log_ppl_abs_diff:0.02658637813598181 - rollout_corr/log_ppl_diff_max:0.7593088150024414 - rollout_corr/log_ppl_diff_min:-0.15361857414245605 - rollout_corr/ppl_ratio:1.0279582314920748 - rollout_corr/chi2_token:0.020870882784477386 - rollout_corr/chi2_seq:3.4575046016561863 - actor/kl_loss:0.006825057460133907 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.008427841130894504 - actor/ppo_kl:0.012841154621535775 - actor/pg_clipfrac_lower:4.454673882707113e-05 - actor/pg_loss:0.025988992037888566 - actor/grad_norm:0.49765550693877453 - perf/mfu/actor:0.04065543959306115 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.501953125 - perf/cpu_memory_used_gb:94.12705278396606 - actor/lr:5e-07 - training/global_step:20.0 - training/epoch:0.0 - critic/score/mean:0.057285308837890625 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.057285308837890625 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.026078187918756157 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.026078187918756157 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:296.09716796875 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.0009765625 - response_length_non_aborted/mean:296.09716796875 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.0009765625 - response/aborted_ratio:0.0 - prompt_length/mean:102.87890625 - prompt_length/max:256.0 - prompt_length/min:66.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:38.266142658889294 - timing_s/reward:0.0011259354650974274 - timing_s/old_log_prob:0.0012279897928237915 - timing_s/ref:63.24781718477607 - timing_s/adv:0.24068014696240425 - timing_s/update_actor:126.94768047332764 - timing_s/step:228.71101577579975 - timing_per_token_ms/update_actor:0.13971737521131755 - timing_per_token_ms/adv:0.00024459200813383515 - timing_per_token_ms/ref:0.06521240097308248 - timing_per_token_ms/gen:0.005901432395339261 - perf/total_num_tokens:817103.0 - perf/time_per_step:228.71101577579975 - perf/throughput:893.1609581947155 - trainer/idle_ratio:0.16731219757425558
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 0.03 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 4 to 5
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 4 to 5 ,reset staleness_samples to: 51,idle_ratio: 0.44476832786339326
[36m(FullyAsyncRollouter pid=551476)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:51:35,816 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'green'}
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.5945746898651123 seconds, while cache cost 6.9141387939453125e-06 seconds,  register cost 0.0005314350128173828 seconds, update cost 0.12389326095581055 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:5 - timing_s/wait_last_valid:0.003819618374109268 - timing_s/param_sync:1.6320835016667843
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:51:35,816 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 1.63 seconds, pause:0.03s, sync:1.60s
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1399462223052979 seconds, while cache cost 0.7971475124359131 seconds,  register cost 0.21658968925476074 seconds, update cost 0.1237342357635498 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.45575451850891113 seconds, offload model to cpu cost 1.597033977508545 seconds
[36m(FullyAsyncRollouter pid=551476)[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': True, 'validate': True, 'global_steps': 1460}
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(FullyAsyncRollouter pid=551476)[0m validation generation end
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.5939676761627197 seconds, while cache cost 7.62939453125e-06 seconds,  register cost 0.0005161762237548828 seconds, update cost 0.12352585792541504 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.146897554397583 seconds, while cache cost 0.7202744483947754 seconds,  register cost 0.046317338943481445 seconds, update cost 0.12360048294067383 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.44869351387023926 seconds, offload model to cpu cost 1.5970430374145508 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 5,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 51,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 1331,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 401.20 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.35s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=1400, queue_size=56
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=1500, queue_size=156
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 5,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 1516,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 71,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 172,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 21 local_trigger_step: 1 trigger_parameter_sync_step: 4 00:59:06.483
[36m(FullyAsyncTrainer pid=555857)[0m step:5 - val-aux/openai/gsm8k/reward/mean@1:0.0362757060272934 - val-core/openai/gsm8k/acc/mean@1:0.053828658074298714 - val-aux/num_turns/min:2 - val-aux/num_turns/max:2 - val-aux/num_turns/mean:2.0
[36m(FullyAsyncTrainer pid=555857)[0m ('[FullyAsyncTrainer] parameter version: 5 Validation metrics: '
[36m(FullyAsyncTrainer pid=555857)[0m  "{'val-aux/openai/gsm8k/reward/mean@1': 0.0362757060272934, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-core/openai/gsm8k/acc/mean@1': 0.053828658074298714, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-aux/num_turns/min': 2, 'val-aux/num_turns/max': 2, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-aux/num_turns/mean': 2.0}")
[36m(FullyAsyncTrainer pid=555857)[0m step:5 - rollouter/active_time:127.95866060256958 - rollouter/version_time:230.4599449634552 - rollouter/idle_ratio:0.44476832786339326 - rollouter/validate_time:367.8941406570375
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:59:06,487 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 145
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.44 seconds.mq_len: 145
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.31s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 22 local_trigger_step: 2 trigger_parameter_sync_step: 4 00:59:48.898
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 00:59:48,901 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 105
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.41 seconds.mq_len: 105
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.31s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 5,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 1580,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 7,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 108,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 23 local_trigger_step: 3 trigger_parameter_sync_step: 4 01:00:33.930
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:00:33,933 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 46
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.42 seconds.mq_len: 46
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  21%|█████████████████████████████▊                                                                                                                  | 6/29 [41:12<2:41:14, 420.62s/it]
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 5,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 1584,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 3,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 48,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 24 local_trigger_step: 4 trigger_parameter_sync_step: 4 01:01:21.738
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006856918334960938
[36m(FullyAsyncTrainer pid=555857)[0m step:6 - fully_async/count/stale_samples_processed:255.0 - fully_async/count/stale_trajectory_processed:2040.0 - fully_async/count/current_param_version:5.0 - fully_async/processing_time/avg:33.53373668393033 - fully_async/processing_time/max:126.5787930637598 - fully_async/processing_time/min:0.5306154265999794 - fully_async/processing_time/tp50:35.41535685118288 - fully_async/processing_time/tp99:67.6622492808476 - fully_async/processing_time/tp95:60.37825662791728 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:1472.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:402.46847462654114 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:4.769804802837595 - rollout_corr/training_log_ppl:1.0804812415786411 - rollout_corr/kl:0.10284297148746703 - rollout_corr/k3_kl:0.08229258899497566 - rollout_corr/rollout_ppl:3.3616874471630487 - rollout_corr/rollout_log_ppl:0.9256438143036119 - rollout_corr/log_ppl_diff:0.15483742261811748 - rollout_corr/log_ppl_abs_diff:0.15669181782053318 - rollout_corr/log_ppl_diff_max:3.15531587600708 - rollout_corr/log_ppl_diff_min:-0.24704742431640625 - rollout_corr/ppl_ratio:1.2332221274236312 - rollout_corr/chi2_token:4.601395205467082 - rollout_corr/chi2_seq:0.18073819025123686 - actor/kl_loss:0.019989034196132995 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.01758881671130608 - actor/ppo_kl:0.10242093178724264 - actor/pg_clipfrac_lower:0.00025447200424725803 - actor/pg_loss:0.011315841445429468 - actor/grad_norm:0.31795488626528046 - perf/mfu/actor:0.039980228363268575 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.501953125 - perf/cpu_memory_used_gb:94.49445343017578 - actor/lr:5e-07 - training/global_step:24.0 - training/epoch:0.0 - critic/score/mean:0.04052734375 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.04052734375 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-0.009380715899169445 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-0.935412585735321 - critic/returns/mean:-0.009380715899169445 - critic/returns/max:2.4748666286468506 - critic/returns/min:-0.935412585735321 - response_length/mean:263.65869140625 - response_length/max:1509.0 - response_length/min:2.0 - response_length/clip_ratio:0.0 - response_length_non_aborted/mean:263.65869140625 - response_length_non_aborted/max:1509.0 - response_length_non_aborted/min:2.0 - response_length_non_aborted/clip_ratio:0.0 - response/aborted_ratio:0.0 - prompt_length/mean:103.60546875 - prompt_length/max:178.0 - prompt_length/min:71.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:404.43368089944124 - timing_s/reward:0.0010901540517807007 - timing_s/old_log_prob:0.0010954700410366058 - timing_s/ref:62.73730373010039 - timing_s/adv:0.2762826271355152 - timing_s/update_actor:118.37608650326729 - timing_s/step:585.832067001611 - timing_per_token_ms/update_actor:0.14044679001557953 - timing_per_token_ms/adv:0.00027213480060692954 - timing_per_token_ms/ref:0.07424902129316449 - timing_per_token_ms/gen:0.0055500369891648684 - perf/total_num_tokens:752157.0 - perf/time_per_step:585.832067001611 - perf/throughput:320.97807646893955 - trainer/idle_ratio:0.6903577043322366
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 68.32 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 5 to 6
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 5 to 6 ,reset staleness_samples to: 51,idle_ratio: 0.005789766751579384
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.6535751819610596 seconds, while cache cost 6.67572021484375e-06 seconds,  register cost 0.0005118846893310547 seconds, update cost 0.12781047821044922 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:6 - timing_s/wait_last_valid:0.0033526308834552765 - timing_s/param_sync:69.98511147126555
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:02:31,748 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 69.98 seconds, pause:68.32s, sync:1.66s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1493134498596191 seconds, while cache cost 0.8018889427185059 seconds,  register cost 0.21705389022827148 seconds, update cost 0.12791800498962402 seconds
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  24%|██████████████████████████████████▊                                                                                                             | 7/29 [46:03<2:18:45, 378.42s/it]
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.5044896602630615 seconds, offload model to cpu cost 1.5998213291168213 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 6,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 1587,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.6532151699066162 seconds, while cache cost 7.867813110351562e-06 seconds,  register cost 0.0004830360412597656 seconds, update cost 0.12782907485961914 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.164133071899414 seconds, while cache cost 0.7151033878326416 seconds,  register cost 0.03664851188659668 seconds, update cost 0.12787103652954102 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.48999595642089844 seconds, offload model to cpu cost 1.6154513359069824 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 27.09 seconds.mq_len: 0
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=1600, queue_size=1
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=1700, queue_size=100
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=1800, queue_size=200
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 6,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 1818,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 25,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 218,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 25 local_trigger_step: 1 trigger_parameter_sync_step: 4 01:03:59.957
[36m(FullyAsyncTrainer pid=555857)[0m step:6 - rollouter/active_time:286.36034393310547 - rollouter/version_time:288.0279586315155 - rollouter/idle_ratio:0.005789766751579384
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:03:59,962 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 163
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.38 seconds.mq_len: 163
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.31s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 26 local_trigger_step: 2 trigger_parameter_sync_step: 4 01:04:42.917
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:04:42,920 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 111
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.36 seconds.mq_len: 111
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 6,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 1840,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 3,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 112,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 27 local_trigger_step: 3 trigger_parameter_sync_step: 4 01:05:27.590
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:05:27,594 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 48
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.37 seconds.mq_len: 48
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.31s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 28 local_trigger_step: 4 trigger_parameter_sync_step: 4 01:06:13.279
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006864070892333984
[36m(FullyAsyncTrainer pid=555857)[0m step:7 - fully_async/count/stale_samples_processed:306.0 - fully_async/count/stale_trajectory_processed:2448.0 - fully_async/count/current_param_version:6.0 - fully_async/processing_time/avg:30.63578077940292 - fully_async/processing_time/max:285.70601411536336 - fully_async/processing_time/min:0.4470333643257618 - fully_async/processing_time/tp50:31.844276305288076 - fully_async/processing_time/tp99:74.17433974500743 - fully_async/processing_time/tp95:58.58533489126711 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:1728.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:28.20572018623352 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:3.4681749458844755 - rollout_corr/training_log_ppl:0.8707959242128567 - rollout_corr/kl:0.03478308244244973 - rollout_corr/k3_kl:0.027288247509518533 - rollout_corr/rollout_ppl:3.0146706213699836 - rollout_corr/rollout_log_ppl:0.8319416746497155 - rollout_corr/log_ppl_diff:0.03885425746767021 - rollout_corr/log_ppl_abs_diff:0.04294738991547824 - rollout_corr/log_ppl_diff_max:2.3173227310180664 - rollout_corr/log_ppl_diff_min:-0.138718843460083 - rollout_corr/ppl_ratio:1.0598204760428738 - rollout_corr/chi2_token:0.28929820444946197 - rollout_corr/chi2_seq:3.8146931575026874 - actor/kl_loss:0.027949273075643634 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.006531644026240519 - actor/ppo_kl:0.034681061797556485 - actor/pg_clipfrac_lower:0.00018326310282824193 - actor/pg_loss:0.024526347433905304 - actor/grad_norm:0.6340117875155362 - perf/mfu/actor:0.03618699053890295 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.501953125 - perf/cpu_memory_used_gb:94.75621175765991 - actor/lr:5e-07 - training/global_step:28.0 - training/epoch:0.0 - critic/score/mean:0.0789480209350586 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.0789480209350586 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.02566722920164466 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.02566722920164466 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:252.21630859375 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.00146484375 - response_length_non_aborted/mean:252.21630859375 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.00146484375 - response/aborted_ratio:0.0 - prompt_length/mean:106.3125 - prompt_length/max:211.0 - prompt_length/min:63.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:30.09151091054082 - timing_s/reward:0.0010260269045829773 - timing_s/old_log_prob:0.0010742023587226868 - timing_s/ref:63.05211549624801 - timing_s/adv:0.27137987688183784 - timing_s/update_actor:128.0106128267944 - timing_s/step:221.4341220408678 - timing_per_token_ms/update_actor:0.14224253495710618 - timing_per_token_ms/adv:0.00027463774821186133 - timing_per_token_ms/ref:0.07233589569171074 - timing_per_token_ms/gen:0.005976200859174315 - perf/total_num_tokens:734267.0 - perf/time_per_step:221.4341220408678 - perf/throughput:828.9903484979653 - trainer/idle_ratio:0.13589373956100198
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncAgentLoopWorker pid=555845)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 0.52 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 6 to 7
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 6 to 7 ,reset staleness_samples to: 51,idle_ratio: 0.007104718969512369
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.5747671127319336 seconds, while cache cost 7.152557373046875e-06 seconds,  register cost 0.0004825592041015625 seconds, update cost 0.12672209739685059 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:7 - timing_s/wait_last_valid:0.0031750500202178955 - timing_s/param_sync:2.1011694818735123
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:06:15,405 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 2.10 seconds, pause:0.52s, sync:1.58s
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.117279291152954 seconds, while cache cost 0.7709696292877197 seconds,  register cost 0.2169482707977295 seconds, update cost 0.12676358222961426 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4585583209991455 seconds, offload model to cpu cost 1.5992212295532227 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 7,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 306,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 1841,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  28%|███████████████████████████████████████▋                                                                                                        | 8/29 [49:47<1:55:12, 329.18s/it]
[36m(FullyAsyncRollouter pid=551476)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.5741901397705078 seconds, while cache cost 8.821487426757812e-06 seconds,  register cost 0.0005121231079101562 seconds, update cost 0.12667608261108398 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.1201438903808594 seconds, while cache cost 0.713024377822876 seconds,  register cost 0.04319906234741211 seconds, update cost 0.12663769721984863 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.45553016662597656 seconds, offload model to cpu cost 1.579737663269043 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 35.47 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.32s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=1900, queue_size=44
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=2000, queue_size=144
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 7,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 2066,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 33,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 210,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 29 local_trigger_step: 1 trigger_parameter_sync_step: 4 01:07:41.970
[36m(FullyAsyncTrainer pid=555857)[0m step:7 - rollouter/active_time:222.06136631965637 - rollouter/version_time:223.6503391265869 - rollouter/idle_ratio:0.007104718969512369
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:07:41,978 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 165
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.36 seconds.mq_len: 165
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 30 local_trigger_step: 2 trigger_parameter_sync_step: 4 01:08:24.393
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:08:24,396 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 109
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.34 seconds.mq_len: 109
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 31 local_trigger_step: 3 trigger_parameter_sync_step: 4 01:09:09.560
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:09:09,564 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 47
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 47
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 7,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 2095,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 4,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 47,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 32 local_trigger_step: 4 trigger_parameter_sync_step: 4 01:09:57.032
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006678104400634766
[36m(FullyAsyncTrainer pid=555857)[0m step:8 - fully_async/count/stale_samples_processed:355.0 - fully_async/count/stale_trajectory_processed:2840.0 - fully_async/count/current_param_version:7.0 - fully_async/processing_time/avg:32.150083269078095 - fully_async/processing_time/max:220.56866907700896 - fully_async/processing_time/min:0.5411226637661457 - fully_async/processing_time/tp50:33.364183644764125 - fully_async/processing_time/tp99:68.78284925846383 - fully_async/processing_time/tp95:57.7472307879012 - fully_async/monitor/active_tasks_size:147.25 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:95.75 - fully_async/count/total_generated_samples:1983.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:36.517391204833984 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:2.7004674080581896 - rollout_corr/training_log_ppl:0.7692135037292563 - rollout_corr/kl:0.0011149260537457568 - rollout_corr/k3_kl:0.0009708830152198465 - rollout_corr/rollout_ppl:2.688404805840008 - rollout_corr/rollout_log_ppl:0.7653246466957387 - rollout_corr/log_ppl_diff:0.003888863117863943 - rollout_corr/log_ppl_abs_diff:0.006404499134597634 - rollout_corr/log_ppl_diff_max:0.16756153106689453 - rollout_corr/log_ppl_diff_min:-0.10527634620666504 - rollout_corr/ppl_ratio:1.0040319573193315 - rollout_corr/chi2_token:0.0016423841080968342 - rollout_corr/chi2_seq:0.48569984917366316 - actor/kl_loss:0.02523332939941495 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.0009781734767337128 - actor/ppo_kl:0.0011149260537457568 - actor/pg_clipfrac_lower:0.0 - actor/pg_loss:0.003912444104946824 - actor/grad_norm:0.5473036054066756 - perf/mfu/actor:0.03805493606186608 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.501953125 - perf/cpu_memory_used_gb:94.96883296966553 - actor/lr:5e-07 - training/global_step:32.0 - training/epoch:0.0 - critic/score/mean:0.08805370330810547 - critic/score/max:1.0 - critic/score/min:-0.666015625 - critic/rewards/mean:0.08805370330810547 - critic/rewards/max:1.0 - critic/rewards/min:-0.666015625 - critic/advantages/mean:-0.004632616997696459 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.474863290786743 - critic/returns/mean:-0.004632616997696459 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.474863290786743 - response_length/mean:253.30810546875 - response_length/max:2901.0 - response_length/min:3.0 - response_length/clip_ratio:0.0 - response_length_non_aborted/mean:253.30810546875 - response_length_non_aborted/max:2901.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.0 - response/aborted_ratio:0.0 - prompt_length/mean:102.92578125 - prompt_length/max:199.0 - prompt_length/min:66.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:38.363858081400394 - timing_s/reward:0.001149255782365799 - timing_s/old_log_prob:0.0013079941272735596 - timing_s/ref:62.74149811640382 - timing_s/adv:0.25896916165947914 - timing_s/update_actor:120.15541968867183 - timing_s/step:221.52925725281239 - timing_per_token_ms/update_actor:0.1480516476352641 - timing_per_token_ms/adv:0.00028473645580932155 - timing_per_token_ms/ref:0.0780940249993988 - timing_per_token_ms/gen:0.005398427920758349 - perf/total_num_tokens:729567.0 - perf/time_per_step:221.52925725281239 - perf/throughput:823.3303007550461 - trainer/idle_ratio:0.17317738775072497
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncAgentLoopWorker pid=555842)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 7.51 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 7 to 8
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 7 to 8 ,reset staleness_samples to: 51,idle_ratio: 0.006451907913587074
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.4742224216461182 seconds, while cache cost 7.3909759521484375e-06 seconds,  register cost 0.0005114078521728516 seconds, update cost 0.1309971809387207 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:8 - timing_s/wait_last_valid:0.002827811986207962 - timing_s/param_sync:8.998131267726421
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:10:06,050 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 8.99 seconds, pause:7.52s, sync:1.48s
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:0.9993464946746826 seconds, while cache cost 0.7707474231719971 seconds,  register cost 0.09403467178344727 seconds, update cost 0.1309359073638916 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4755103588104248 seconds, offload model to cpu cost 1.5967073440551758 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 8,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 306,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 2097,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  31%|████████████████████████████████████████████▋                                                                                                   | 9/29 [53:42<1:39:52, 299.62s/it]
[36m(FullyAsyncAgentLoopWorker pid=555847)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.4739983081817627 seconds, while cache cost 5.7220458984375e-06 seconds,  register cost 0.00046372413635253906 seconds, update cost 0.13085317611694336 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.0285134315490723 seconds, while cache cost 0.7093584537506104 seconds,  register cost 0.04080843925476074 seconds, update cost 0.13095760345458984 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4467754364013672 seconds, offload model to cpu cost 1.5803585052490234 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=2100, queue_size=1
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 35.52 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=2200, queue_size=88
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=2300, queue_size=188
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 8,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 2317,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 38,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 205,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 33 local_trigger_step: 1 trigger_parameter_sync_step: 4 01:11:37.314
[36m(FullyAsyncTrainer pid=555857)[0m step:8 - rollouter/active_time:229.14808654785156 - rollouter/version_time:230.63612961769104 - rollouter/idle_ratio:0.006451907913587074
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:11:37,318 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 165
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 165
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.31s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 34 local_trigger_step: 2 trigger_parameter_sync_step: 4 01:12:20.733
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:12:20,736 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 110
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.39 seconds.mq_len: 110
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.31s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 8,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 2350,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 5,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 110,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 35 local_trigger_step: 3 trigger_parameter_sync_step: 4 01:13:05.703
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:13:05,707 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 49
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.38 seconds.mq_len: 49
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 36 local_trigger_step: 4 trigger_parameter_sync_step: 4 01:13:51.666
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006358623504638672
[36m(FullyAsyncTrainer pid=555857)[0m step:9 - fully_async/count/stale_samples_processed:404.0 - fully_async/count/stale_trajectory_processed:3232.0 - fully_async/count/current_param_version:8.0 - fully_async/processing_time/avg:34.56296089231728 - fully_async/processing_time/max:389.8292698562145 - fully_async/processing_time/min:0.5778247825801373 - fully_async/processing_time/tp50:35.63942604092881 - fully_async/processing_time/tp99:68.96596271174027 - fully_async/processing_time/tp95:58.80484688635915 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:2240.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:2.0 - fully_async/partial/partial_ratio:0.0009765625 - fully_async/partial/max_partial_span:1.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:36.64034819602966 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:3.1138482737162754 - rollout_corr/training_log_ppl:0.7916143426521225 - rollout_corr/kl:0.0009815753097089973 - rollout_corr/k3_kl:0.0009389219082637217 - rollout_corr/rollout_ppl:3.0942964539209505 - rollout_corr/rollout_log_ppl:0.7868691514323937 - rollout_corr/log_ppl_diff:0.004745184402805488 - rollout_corr/log_ppl_abs_diff:0.006884785438698972 - rollout_corr/log_ppl_diff_max:0.24158692359924316 - rollout_corr/log_ppl_diff_min:-0.07043653726577759 - rollout_corr/ppl_ratio:1.0049556195468554 - rollout_corr/chi2_token:0.001799137020847401 - rollout_corr/chi2_seq:0.8163979045619958 - actor/kl_loss:0.022692884390251716 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.001181197017707786 - actor/ppo_kl:0.0009815753097089973 - actor/pg_clipfrac_lower:0.0 - actor/pg_loss:0.03355668811341354 - actor/grad_norm:0.549404644297277 - perf/mfu/actor:0.039149880476515346 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.501953125 - perf/cpu_memory_used_gb:94.96423578262329 - actor/lr:5e-07 - training/global_step:36.0 - training/epoch:0.0 - critic/score/mean:0.10509300231933594 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.10509300231933594 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.035138998413458467 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.035138998413458467 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:267.96044921875 - response_length/max:3072.0 - response_length/min:4.0 - response_length/clip_ratio:0.00146484375 - response_length_non_aborted/mean:267.96044921875 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:4.0 - response_length_non_aborted/clip_ratio:0.00146484375 - response/aborted_ratio:0.0 - prompt_length/mean:104.98046875 - prompt_length/max:167.0 - prompt_length/min:66.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:38.5115469135344 - timing_s/reward:0.0008243918418884277 - timing_s/old_log_prob:0.00099940225481987 - timing_s/ref:62.55755231156945 - timing_s/adv:0.2603447362780571 - timing_s/update_actor:124.17070131003857 - timing_s/step:225.50786888226867 - timing_per_token_ms/update_actor:0.13824045149614347 - timing_per_token_ms/adv:0.0002935812869930576 - timing_per_token_ms/ref:0.07403268493067472 - timing_per_token_ms/gen:0.005501499599849198 - perf/total_num_tokens:763783.0 - perf/time_per_step:225.50786888226867 - perf/throughput:846.7365282924447 - trainer/idle_ratio:0.170776953834991
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 8,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 2354,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 1,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 50,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 119.36 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 8 to 9
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 8 to 9 ,reset staleness_samples to: 51,idle_ratio: 0.004404039204739751
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.5123639106750488 seconds, while cache cost 6.4373016357421875e-06 seconds,  register cost 0.0005576610565185547 seconds, update cost 0.12357330322265625 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:9 - timing_s/wait_last_valid:0.0026847273111343384 - timing_s/param_sync:120.88662123680115
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:15:52,575 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 120.88 seconds, pause:119.37s, sync:1.52s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.0311369895935059 seconds, while cache cost 0.7129812240600586 seconds,  register cost 0.03879213333129883 seconds, update cost 0.12364506721496582 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.48210668563842773 seconds, offload model to cpu cost 1.5867877006530762 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 9,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 2355,
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  34%|█████████████████████████████████████████████████▎                                                                                             | 10/29 [59:24<1:39:04, 312.89s/it]
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.5126662254333496 seconds, while cache cost 4.76837158203125e-06 seconds,  register cost 0.0004527568817138672 seconds, update cost 0.12349605560302734 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.0019502639770508 seconds, while cache cost 0.7845213413238525 seconds,  register cost 0.09067726135253906 seconds, update cost 0.1236112117767334 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.51055908203125 seconds, offload model to cpu cost 1.6512248516082764 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 32.50 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=2400, queue_size=32
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=2500, queue_size=132
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 9,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 2565,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 46,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 197,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 37 local_trigger_step: 1 trigger_parameter_sync_step: 4 01:17:16.820
[36m(FullyAsyncTrainer pid=555857)[0m step:9 - rollouter/active_time:344.9929099082947 - rollouter/version_time:346.51899313926697 - rollouter/idle_ratio:0.004404039204739751
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:17:16,824 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 152
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 152
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=2600, queue_size=168
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 38 local_trigger_step: 2 trigger_parameter_sync_step: 4 01:17:59.712
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:17:59,716 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 106
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.34 seconds.mq_len: 106
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 9,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 2605,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 6,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 109,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 39 local_trigger_step: 3 trigger_parameter_sync_step: 4 01:18:44.764
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:18:44,767 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 46
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 46
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 40 local_trigger_step: 4 trigger_parameter_sync_step: 4 01:19:34.246
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006501674652099609
[36m(FullyAsyncTrainer pid=555857)[0m step:10 - fully_async/count/stale_samples_processed:455.0 - fully_async/count/stale_trajectory_processed:3640.0 - fully_async/count/current_param_version:9.0 - fully_async/processing_time/avg:36.73561998216428 - fully_async/processing_time/max:393.14307145029306 - fully_async/processing_time/min:0.4238480105996132 - fully_async/processing_time/tp50:37.120312792714685 - fully_async/processing_time/tp99:76.01754174144004 - fully_async/processing_time/tp95:62.000487453816454 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:2496.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:2.0 - fully_async/partial/partial_ratio:0.0009765625 - fully_async/partial/max_partial_span:1.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:33.53296256065369 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:2.8344401744358705 - rollout_corr/training_log_ppl:0.7620912746877888 - rollout_corr/kl:0.009188487515488706 - rollout_corr/k3_kl:0.006828113239773155 - rollout_corr/rollout_ppl:2.7746825999272797 - rollout_corr/rollout_log_ppl:0.747702449733593 - rollout_corr/log_ppl_diff:0.014388825425312696 - rollout_corr/log_ppl_abs_diff:0.01565908302258045 - rollout_corr/log_ppl_diff_max:0.9110069274902344 - rollout_corr/log_ppl_diff_min:-0.10604631900787354 - rollout_corr/ppl_ratio:1.01599821487119 - rollout_corr/chi2_token:0.005786719195290751 - rollout_corr/chi2_seq:-0.08899604316346144 - actor/kl_loss:0.021875732304308483 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.003714765426514869 - actor/ppo_kl:0.009144140805384778 - actor/pg_clipfrac_lower:2.5461465054120748e-05 - actor/pg_loss:0.05089640720672587 - actor/grad_norm:0.573097736982615 - perf/mfu/actor:0.04036719136562307 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.501953125 - perf/cpu_memory_used_gb:94.91710710525513 - actor/lr:5e-07 - training/global_step:40.0 - training/epoch:0.0 - critic/score/mean:0.12031745910644531 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.12031745910644531 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.05183818575460464 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.05183818575460464 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:276.6337890625 - response_length/max:3072.0 - response_length/min:4.0 - response_length/clip_ratio:0.00146484375 - response_length_non_aborted/mean:276.6337890625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:4.0 - response_length_non_aborted/clip_ratio:0.00146484375 - response/aborted_ratio:0.0 - prompt_length/mean:103.9765625 - prompt_length/max:196.0 - prompt_length/min:67.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:35.35284763202071 - timing_s/reward:0.0008470676839351654 - timing_s/old_log_prob:0.0009915046393871307 - timing_s/ref:63.25180055573583 - timing_s/adv:0.24704323336482048 - timing_s/update_actor:122.71568183600903 - timing_s/step:221.57512319087982 - timing_per_token_ms/update_actor:0.141508517191357 - timing_per_token_ms/adv:0.00027034779126365317 - timing_per_token_ms/ref:0.07288100375150605 - timing_per_token_ms/gen:0.004815326452509013 - perf/total_num_tokens:779490.0 - perf/time_per_step:221.57512319087982 - perf/throughput:879.4872691196639 - trainer/idle_ratio:0.1595524223247994
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncAgentLoopWorker pid=555843)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 3.92 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 9 to 10
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 9 to 10 ,reset staleness_samples to: 51,idle_ratio: 0.006787160764020306
[36m(FullyAsyncRollouter pid=551476)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:19:39,727 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'green'}
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.5269412994384766 seconds, while cache cost 8.821487426757812e-06 seconds,  register cost 0.0005071163177490234 seconds, update cost 0.1301581859588623 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:10 - timing_s/wait_last_valid:0.003981553018093109 - timing_s/param_sync:5.457459110766649
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:19:39,726 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 5.45 seconds, pause:3.92s, sync:1.53s
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.0541815757751465 seconds, while cache cost 0.8190600872039795 seconds,  register cost 0.10238218307495117 seconds, update cost 0.13019847869873047 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.47365689277648926 seconds, offload model to cpu cost 1.6438586711883545 seconds
[36m(FullyAsyncRollouter pid=551476)[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': True, 'validate': True, 'global_steps': 2740}
[36m(FullyAsyncAgentLoopWorker pid=555853)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(FullyAsyncRollouter pid=551476)[0m validation generation end
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.526881217956543 seconds, while cache cost 5.4836273193359375e-06 seconds,  register cost 0.0004773139953613281 seconds, update cost 0.1300506591796875 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.0753521919250488 seconds, while cache cost 0.71759033203125 seconds,  register cost 0.034957170486450195 seconds, update cost 0.13013315200805664 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.45247530937194824 seconds, offload model to cpu cost 1.5824549198150635 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 10,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 51,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 2607,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 4,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 390.92 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.32s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=2700, queue_size=76
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 10,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 2781,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 86,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 157,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 41 local_trigger_step: 1 trigger_parameter_sync_step: 4 01:27:04.638
[36m(FullyAsyncTrainer pid=555857)[0m step:10 - val-aux/openai/gsm8k/reward/mean@1:-0.001516300227445034 - val-core/openai/gsm8k/acc/mean@1:0.04624715693707354 - val-aux/num_turns/min:2 - val-aux/num_turns/max:2 - val-aux/num_turns/mean:2.0
[36m(FullyAsyncTrainer pid=555857)[0m ('[FullyAsyncTrainer] parameter version: 10 Validation metrics: '
[36m(FullyAsyncTrainer pid=555857)[0m  "{'val-aux/openai/gsm8k/reward/mean@1': -0.001516300227445034, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-core/openai/gsm8k/acc/mean@1': 0.04624715693707354, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-aux/num_turns/min': 2, 'val-aux/num_turns/max': 2, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-aux/num_turns/mean': 2.0}")
[36m(FullyAsyncTrainer pid=555857)[0m step:10 - rollouter/active_time:225.6043734550476 - rollouter/version_time:227.14605021476746 - rollouter/idle_ratio:0.006787160764020306 - rollouter/validate_time:377.5702666826546
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:27:04,643 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 105
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.27 seconds.mq_len: 105
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.31s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=2800, queue_size=112
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 42 local_trigger_step: 2 trigger_parameter_sync_step: 4 01:27:46.652
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:27:46,655 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 67
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 67
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 10,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 2826,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 41,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 74,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 43 local_trigger_step: 3 trigger_parameter_sync_step: 4 01:28:30.573
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:28:30,576 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 12
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.36 seconds.mq_len: 12
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  38%|█████████████████████████████████████████████████████▍                                                                                       | 11/29 [1:09:18<1:59:37, 398.74s/it]
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 10,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 2836,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 31,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 20,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 44 local_trigger_step: 4 trigger_parameter_sync_step: 4 01:29:27.658
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.000667572021484375
[36m(FullyAsyncTrainer pid=555857)[0m step:11 - fully_async/count/stale_samples_processed:502.0 - fully_async/count/stale_trajectory_processed:4016.0 - fully_async/count/current_param_version:10.0 - fully_async/processing_time/avg:23.889710446530444 - fully_async/processing_time/max:224.1226091235876 - fully_async/processing_time/min:0.3671647273004055 - fully_async/processing_time/tp50:22.40807115007192 - fully_async/processing_time/tp99:71.65612533712758 - fully_async/processing_time/tp95:57.09780306601897 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:2752.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:391.908563375473 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:134256644.3756462 - rollout_corr/training_log_ppl:1.9252943998880006 - rollout_corr/kl:0.24608459115631626 - rollout_corr/k3_kl:0.20115223176650363 - rollout_corr/rollout_ppl:11.960375693812965 - rollout_corr/rollout_log_ppl:1.311282809341157 - rollout_corr/log_ppl_diff:0.6140115715690295 - rollout_corr/log_ppl_abs_diff:0.6147951276422563 - rollout_corr/log_ppl_diff_max:22.461645126342773 - rollout_corr/log_ppl_diff_min:-0.389859676361084 - rollout_corr/ppl_ratio:2734683.620102539 - rollout_corr/chi2_token:0.681428837327456 - rollout_corr/chi2_seq:-0.8907787629826502 - actor/kl_loss:0.034281724991954185 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.03792608181670816 - actor/ppo_kl:0.24491225971512243 - actor/pg_clipfrac_lower:0.0008720211457784899 - actor/pg_loss:0.008543420898190974 - actor/grad_norm:0.4197298567999846 - perf/mfu/actor:0.031759350992612345 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.501953125 - perf/cpu_memory_used_gb:95.02543497085571 - actor/lr:5e-07 - training/global_step:44.0 - training/epoch:0.0 - critic/score/mean:0.03917694091796875 - critic/score/max:1.0 - critic/score/min:-0.765625 - critic/rewards/mean:0.03917694091796875 - critic/rewards/max:1.0 - critic/rewards/min:-0.765625 - critic/advantages/mean:-0.0041860635683406144 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-1.6735478639602661 - critic/returns/mean:-0.0041860635683406144 - critic/returns/max:2.4748666286468506 - critic/returns/min:-1.6735478639602661 - response_length/mean:221.62255859375 - response_length/max:2952.0 - response_length/min:1.0 - response_length/clip_ratio:0.0 - response_length_non_aborted/mean:221.62255859375 - response_length_non_aborted/max:2952.0 - response_length_non_aborted/min:1.0 - response_length_non_aborted/clip_ratio:0.0 - response/aborted_ratio:0.0 - prompt_length/mean:104.61328125 - prompt_length/max:206.0 - prompt_length/min:70.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:393.7942747436464 - timing_s/reward:0.0007933974266052246 - timing_s/old_log_prob:0.0009927712380886078 - timing_s/ref:62.85976630076766 - timing_s/adv:0.25007471814751625 - timing_s/update_actor:130.92994764447212 - timing_s/step:587.8417289741337 - timing_per_token_ms/update_actor:0.16465500276476547 - timing_per_token_ms/adv:0.00026225726608019564 - timing_per_token_ms/ref:0.0763315231351946 - timing_per_token_ms/gen:0.006084530869860886 - perf/total_num_tokens:668131.0 - perf/time_per_step:587.8417289741337 - perf/throughput:284.1457857908379 - trainer/idle_ratio:0.6698984698328113
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 51.22 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 10 to 11
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 10 to 11 ,reset staleness_samples to: 51,idle_ratio: 0.006115724003045386
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.594550609588623 seconds, while cache cost 8.344650268554688e-06 seconds,  register cost 0.0005445480346679688 seconds, update cost 0.12610268592834473 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:11 - timing_s/wait_last_valid:0.003659173846244812 - timing_s/param_sync:52.822610318660736
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:30:20,502 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 52.82 seconds, pause:51.22s, sync:1.60s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1134371757507324 seconds, while cache cost 0.7686605453491211 seconds,  register cost 0.21599888801574707 seconds, update cost 0.12624478340148926 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.48158907890319824 seconds, offload model to cpu cost 1.6157870292663574 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 11,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 2867,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558094)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.594775915145874 seconds, while cache cost 5.0067901611328125e-06 seconds,  register cost 0.0004723072052001953 seconds, update cost 0.12620782852172852 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.1396167278289795 seconds, while cache cost 0.729780912399292 seconds,  register cost 0.0444178581237793 seconds, update cost 0.12606525421142578 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.45611023902893066 seconds, offload model to cpu cost 1.6127948760986328 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 36.88 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.31s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=2900, queue_size=20
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=3000, queue_size=120
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 11,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 3076,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 47,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 196,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 45 local_trigger_step: 1 trigger_parameter_sync_step: 4 01:31:56.568
[36m(FullyAsyncTrainer pid=555857)[0m step:11 - rollouter/active_time:261.58773279190063 - rollouter/version_time:263.1973752975464 - rollouter/idle_ratio:0.006115724003045386
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:31:56,572 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 153
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 153
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=3100, queue_size=156
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 46 local_trigger_step: 2 trigger_parameter_sync_step: 4 01:32:39.676
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:32:39,680 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 106
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.37 seconds.mq_len: 106
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 11,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 3114,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 9,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 106,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 47 local_trigger_step: 3 trigger_parameter_sync_step: 4 01:33:24.888
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:33:24,892 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 43
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.40 seconds.mq_len: 43
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  41%|██████████████████████████████████████████████████████████▎                                                                                  | 12/29 [1:14:04<1:43:17, 364.54s/it]
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 11,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 3118,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 5,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 46,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 48 local_trigger_step: 4 trigger_parameter_sync_step: 4 01:34:13.960
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006241798400878906
[36m(FullyAsyncTrainer pid=555857)[0m step:12 - fully_async/count/stale_samples_processed:553.0 - fully_async/count/stale_trajectory_processed:4424.0 - fully_async/count/current_param_version:11.0 - fully_async/processing_time/avg:39.64928854388381 - fully_async/processing_time/max:381.71399442479014 - fully_async/processing_time/min:0.3875346966087818 - fully_async/processing_time/tp50:35.15289598982781 - fully_async/processing_time/tp99:110.20620119587518 - fully_async/processing_time/tp95:107.5334522146266 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:80.0 - fully_async/count/total_generated_samples:3008.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:4.0 - fully_async/partial/partial_ratio:0.001953125 - fully_async/partial/max_partial_span:1.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:38.000279903411865 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:1784.7542550874134 - rollout_corr/training_log_ppl:1.0478219691689554 - rollout_corr/kl:0.10658591170085473 - rollout_corr/k3_kl:0.4601634784660669 - rollout_corr/rollout_ppl:18.62961600520609 - rollout_corr/rollout_log_ppl:0.8708101283568493 - rollout_corr/log_ppl_diff:0.17701184836256542 - rollout_corr/log_ppl_abs_diff:0.17850105892544954 - rollout_corr/log_ppl_diff_max:10.320107460021973 - rollout_corr/log_ppl_diff_min:-0.09527051448822021 - rollout_corr/ppl_ratio:24.775260529639294 - rollout_corr/chi2_token:130893.58336536588 - rollout_corr/chi2_seq:0.2314888920558263 - actor/kl_loss:0.021408381800724567 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.03681348005392805 - actor/ppo_kl:0.10645795999316378 - actor/pg_clipfrac_lower:0.0012659719604319738 - actor/pg_loss:0.2841959327266264 - actor/grad_norm:0.8351989163531687 - perf/mfu/actor:0.04244110492054574 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.501953125 - perf/cpu_memory_used_gb:95.25337982177734 - actor/lr:5e-07 - training/global_step:48.0 - training/epoch:0.0 - critic/score/mean:0.12987232208251953 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.12987232208251953 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.28551717451773584 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.28551717451773584 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:317.080078125 - response_length/max:3072.0 - response_length/min:2.0 - response_length/clip_ratio:0.01806640625 - response_length_non_aborted/mean:317.080078125 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:2.0 - response_length_non_aborted/clip_ratio:0.01806640625 - response/aborted_ratio:0.0 - prompt_length/mean:101.375 - prompt_length/max:181.0 - prompt_length/min:64.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:39.80754666402936 - timing_s/reward:0.0008797794580459595 - timing_s/old_log_prob:0.0010037049651145935 - timing_s/ref:64.35753552615643 - timing_s/adv:0.24469688162207603 - timing_s/update_actor:128.95359774678946 - timing_s/step:233.37117952108383 - timing_per_token_ms/update_actor:0.13685938024891847 - timing_per_token_ms/adv:0.00020922836577402164 - timing_per_token_ms/ref:0.06049459157860408 - timing_per_token_ms/gen:0.004978886541446779 - perf/total_num_tokens:856996.0 - perf/time_per_step:233.37117952108383 - perf/throughput:918.0610923751352 - trainer/idle_ratio:0.17057610432325454
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 17.04 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 11 to 12
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 11 to 12 ,reset staleness_samples to: 51,idle_ratio: 0.006349068166611516
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.5849175453186035 seconds, while cache cost 2.2649765014648438e-05 seconds,  register cost 0.0007114410400390625 seconds, update cost 0.12499165534973145 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:12 - timing_s/wait_last_valid:0.002844572067260742 - timing_s/param_sync:18.637101512402296
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:34:32,618 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 18.63 seconds, pause:17.04s, sync:1.59s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.130918025970459 seconds, while cache cost 0.7853872776031494 seconds,  register cost 0.21784615516662598 seconds, update cost 0.12507057189941406 seconds
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  45%|███████████████████████████████████████████████████████████████▏                                                                             | 13/29 [1:18:16<1:28:05, 330.37s/it]
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.45661330223083496 seconds, offload model to cpu cost 1.6363914012908936 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 12,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 3135,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 244,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.5867445468902588 seconds, while cache cost 5.245208740234375e-06 seconds,  register cost 0.00047087669372558594 seconds, update cost 0.12500953674316406 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.1411664485931396 seconds, while cache cost 0.7190184593200684 seconds,  register cost 0.035198211669921875 seconds, update cost 0.1250147819519043 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4466252326965332 seconds, offload model to cpu cost 1.6110937595367432 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 39.70 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=3200, queue_size=64
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=3300, queue_size=164
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 49 local_trigger_step: 1 trigger_parameter_sync_step: 4 01:36:07.344
[36m(FullyAsyncTrainer pid=555857)[0m step:12 - rollouter/active_time:250.50864100456238 - rollouter/version_time:252.10930013656616 - rollouter/idle_ratio:0.006349068166611516
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:36:07,349 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 144
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.34 seconds.mq_len: 144
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.31s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 12,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 3355,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 24,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 155,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 50 local_trigger_step: 2 trigger_parameter_sync_step: 4 01:36:48.825
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:36:48,828 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 103
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.30 seconds.mq_len: 103
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 12,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 3369,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 10,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 105,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 51 local_trigger_step: 3 trigger_parameter_sync_step: 4 01:37:35.410
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:37:35,413 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 41
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 41
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.28s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 52 local_trigger_step: 4 trigger_parameter_sync_step: 4 01:38:25.715
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006301403045654297
[36m(FullyAsyncTrainer pid=555857)[0m step:13 - fully_async/count/stale_samples_processed:604.0 - fully_async/count/stale_trajectory_processed:4832.0 - fully_async/count/current_param_version:12.0 - fully_async/processing_time/avg:43.93626405890427 - fully_async/processing_time/max:249.172347150743 - fully_async/processing_time/min:0.45674560964107513 - fully_async/processing_time/tp50:43.019413775298744 - fully_async/processing_time/tp99:102.67979756622569 - fully_async/processing_time/tp95:70.39911006409675 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:3264.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:40.67611861228943 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:2.784807504627567 - rollout_corr/training_log_ppl:0.6958272054067884 - rollout_corr/kl:0.0007752101020543242 - rollout_corr/k3_kl:0.0008601537114932747 - rollout_corr/rollout_ppl:2.777572790243878 - rollout_corr/rollout_log_ppl:0.6940984494017007 - rollout_corr/log_ppl_diff:0.0017287557081300082 - rollout_corr/log_ppl_abs_diff:0.003178427849063435 - rollout_corr/log_ppl_diff_max:0.275793194770813 - rollout_corr/log_ppl_diff_min:-0.03822910785675049 - rollout_corr/ppl_ratio:1.0017954410397663 - rollout_corr/chi2_token:0.001887627626554324 - rollout_corr/chi2_seq:0.8051326005948851 - actor/kl_loss:0.01949568079457654 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.0014016308709422166 - actor/ppo_kl:0.0007752101020543242 - actor/pg_clipfrac_lower:0.0 - actor/pg_loss:0.06367724951881078 - actor/grad_norm:0.5513851585421699 - perf/mfu/actor:0.04344991217309441 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.501953125 - perf/cpu_memory_used_gb:95.13984632492065 - actor/lr:5e-07 - training/global_step:52.0 - training/epoch:0.0 - critic/score/mean:0.19806194305419922 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.19806194305419922 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.06513123365584761 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.06513123365584761 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:320.06884765625 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.00244140625 - response_length_non_aborted/mean:320.06884765625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.00244140625 - response/aborted_ratio:0.0 - prompt_length/mean:102.6328125 - prompt_length/max:201.0 - prompt_length/min:70.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:42.4714420363307 - timing_s/reward:0.0008681491017341614 - timing_s/old_log_prob:0.0009810365736484528 - timing_s/ref:64.10250673815608 - timing_s/adv:0.23899801075458527 - timing_s/update_actor:126.19065546244383 - timing_s/step:233.0113783814013 - timing_per_token_ms/update_actor:0.13239032127601688 - timing_per_token_ms/adv:0.00022677649970900598 - timing_per_token_ms/ref:0.06700366840350994 - timing_per_token_ms/gen:0.003964110418206281 - perf/total_num_tokens:865693.0 - perf/time_per_step:233.0113783814013 - perf/throughput:928.8097924803944 - trainer/idle_ratio:0.1822719659930595
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 72.31 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 12 to 13
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 12 to 13 ,reset staleness_samples to: 51,idle_ratio: 0.005279775322756808
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.6058759689331055 seconds, while cache cost 7.867813110351562e-06 seconds,  register cost 0.0004794597625732422 seconds, update cost 0.12250208854675293 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:13 - timing_s/wait_last_valid:0.003232192248106003 - timing_s/param_sync:73.93098118156195
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:39:39,667 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 73.93 seconds, pause:72.32s, sync:1.61s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1104600429534912 seconds, while cache cost 0.7699711322784424 seconds,  register cost 0.21506690979003906 seconds, update cost 0.12278294563293457 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4959099292755127 seconds, offload model to cpu cost 1.603963851928711 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 13,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 3379,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558094)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  48%|████████████████████████████████████████████████████████████████████                                                                         | 14/29 [1:23:24<1:20:54, 323.62s/it]
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.6057872772216797 seconds, while cache cost 5.0067901611328125e-06 seconds,  register cost 0.0004603862762451172 seconds, update cost 0.12275934219360352 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.1513981819152832 seconds, while cache cost 0.7228691577911377 seconds,  register cost 0.04282045364379883 seconds, update cost 0.12266087532043457 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4552028179168701 seconds, offload model to cpu cost 1.5882258415222168 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 36.83 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=3400, queue_size=8
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=3500, queue_size=108
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 13,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 3581,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 54,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 189,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=3600, queue_size=208
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 53 local_trigger_step: 1 trigger_parameter_sync_step: 4 01:41:19.443
[36m(FullyAsyncTrainer pid=555857)[0m step:13 - rollouter/active_time:305.4261968135834 - rollouter/version_time:307.04733777046204 - rollouter/idle_ratio:0.005279775322756808
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:41:19,448 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 160
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 160
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 54 local_trigger_step: 2 trigger_parameter_sync_step: 4 01:42:01.892
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:42:01,896 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 13,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 3626,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 9,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 159,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 106
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 106
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 55 local_trigger_step: 3 trigger_parameter_sync_step: 4 01:42:45.807
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:42:45,811 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 44
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.34 seconds.mq_len: 44
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.28s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 13,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 3630,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 5,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 46,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 56 local_trigger_step: 4 trigger_parameter_sync_step: 4 01:43:33.730
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006358623504638672
[36m(FullyAsyncTrainer pid=555857)[0m step:14 - fully_async/count/stale_samples_processed:655.0 - fully_async/count/stale_trajectory_processed:5240.0 - fully_async/count/current_param_version:13.0 - fully_async/processing_time/avg:39.587229512071644 - fully_async/processing_time/max:304.02379820495844 - fully_async/processing_time/min:0.5599331520497799 - fully_async/processing_time/tp50:39.19523489987478 - fully_async/processing_time/tp99:120.12743278348817 - fully_async/processing_time/tp95:68.23579911300912 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:3520.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:37.866052865982056 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:7.209096223768519 - rollout_corr/training_log_ppl:0.9866144630181755 - rollout_corr/kl:0.08575377283021325 - rollout_corr/k3_kl:0.06681389604804422 - rollout_corr/rollout_ppl:3.658044260672548 - rollout_corr/rollout_log_ppl:0.8506700442579789 - rollout_corr/log_ppl_diff:0.13594442136361357 - rollout_corr/log_ppl_abs_diff:0.136425779104171 - rollout_corr/log_ppl_diff_max:5.458091735839844 - rollout_corr/log_ppl_diff_min:-0.21497273445129395 - rollout_corr/ppl_ratio:1.327498925968596 - rollout_corr/chi2_token:0.04942887435206259 - rollout_corr/chi2_seq:-0.5883202768340814 - actor/kl_loss:0.021687542255040562 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.02480080874275381 - actor/ppo_kl:0.08519008236065533 - actor/pg_clipfrac_lower:0.0002723430454657115 - actor/pg_loss:0.07248875359218275 - actor/grad_norm:0.5513186966113266 - perf/mfu/actor:0.0397927600621173 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.501953125 - perf/cpu_memory_used_gb:95.19643115997314 - actor/lr:5e-07 - training/global_step:56.0 - training/epoch:0.0 - critic/score/mean:0.11957073211669922 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.11957073211669922 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.07136868860106915 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.07136868860106915 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:298.51611328125 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.00341796875 - response_length_non_aborted/mean:298.51611328125 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.00341796875 - response/aborted_ratio:0.0 - prompt_length/mean:103.9453125 - prompt_length/max:194.0 - prompt_length/min:68.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:39.61818039044738 - timing_s/reward:0.000846467912197113 - timing_s/old_log_prob:0.001008152961730957 - timing_s/ref:63.874360624700785 - timing_s/adv:0.23931868001818657 - timing_s/update_actor:130.24034614488482 - timing_s/step:233.98042970523238 - timing_per_token_ms/update_actor:0.1422060915849743 - timing_per_token_ms/adv:0.00021639922913824328 - timing_per_token_ms/ref:0.06502712377493222 - timing_per_token_ms/gen:0.004679726600834068 - perf/total_num_tokens:824241.0 - perf/time_per_step:233.98042970523238 - perf/throughput:880.6730129506724 - trainer/idle_ratio:0.16932262429109224
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 10.45 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 13 to 14
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 13 to 14 ,reset staleness_samples to: 51,idle_ratio: 0.006533360769404695
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.593564510345459 seconds, while cache cost 8.344650268554688e-06 seconds,  register cost 0.0005228519439697266 seconds, update cost 0.12387871742248535 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:14 - timing_s/wait_last_valid:0.0035215169191360474 - timing_s/param_sync:12.057275541126728
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:43:45,808 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 12.05 seconds, pause:10.46s, sync:1.60s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1191318035125732 seconds, while cache cost 0.7758057117462158 seconds,  register cost 0.21681737899780273 seconds, update cost 0.12398886680603027 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4751756191253662 seconds, offload model to cpu cost 1.6140656471252441 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 14,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 3638,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 253,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  52%|████████████████████████████████████████████████████████████████████████▉                                                                    | 15/29 [1:27:24<1:09:40, 298.58s/it]
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.593590259552002 seconds, while cache cost 5.245208740234375e-06 seconds,  register cost 0.00046825408935546875 seconds, update cost 0.12395691871643066 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.141361951828003 seconds, while cache cost 0.7102785110473633 seconds,  register cost 0.04356741905212402 seconds, update cost 0.12385272979736328 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.45331573486328125 seconds, offload model to cpu cost 1.6828093528747559 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 38.34 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=3700, queue_size=52
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=3800, queue_size=152
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 14,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 3872,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 19,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 224,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 57 local_trigger_step: 1 trigger_parameter_sync_step: 4 01:45:19.468
[36m(FullyAsyncTrainer pid=555857)[0m step:14 - rollouter/active_time:244.52426147460938 - rollouter/version_time:246.13233280181885 - rollouter/idle_ratio:0.006533360769404695
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:45:19,472 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 160
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 160
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.31s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 58 local_trigger_step: 2 trigger_parameter_sync_step: 4 01:46:01.627
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:46:01,630 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 111
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 111
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 14,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 3889,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 2,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 113,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 59 local_trigger_step: 3 trigger_parameter_sync_step: 4 01:46:46.747
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:46:46,750 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 49
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.40 seconds.mq_len: 49
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 60 local_trigger_step: 4 trigger_parameter_sync_step: 4 01:47:34.284
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006194114685058594
[36m(FullyAsyncTrainer pid=555857)[0m step:15 - fully_async/count/stale_samples_processed:706.0 - fully_async/count/stale_trajectory_processed:5648.0 - fully_async/count/current_param_version:14.0 - fully_async/processing_time/avg:40.47754036373408 - fully_async/processing_time/max:243.49215423315763 - fully_async/processing_time/min:0.5476888604462147 - fully_async/processing_time/tp50:39.76727425120771 - fully_async/processing_time/tp99:102.70057495984236 - fully_async/processing_time/tp95:64.78638224345632 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:3776.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:39.43378472328186 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:3.0365804139562327 - rollout_corr/training_log_ppl:0.6880386948485167 - rollout_corr/kl:0.029842739353233984 - rollout_corr/k3_kl:0.02462360067411864 - rollout_corr/rollout_ppl:2.621106206447589 - rollout_corr/rollout_log_ppl:0.6622351015770576 - rollout_corr/log_ppl_diff:0.025803592971970192 - rollout_corr/log_ppl_abs_diff:0.027025034774508547 - rollout_corr/log_ppl_diff_max:1.4085228443145752 - rollout_corr/log_ppl_diff_min:-0.029785096645355225 - rollout_corr/ppl_ratio:1.030711227861117 - rollout_corr/chi2_token:0.907970790803332 - rollout_corr/chi2_seq:0.14195462762306033 - actor/kl_loss:0.024069906361651947 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.009153453982115464 - actor/ppo_kl:0.02978439999640978 - actor/pg_clipfrac_lower:0.0002114679163814462 - actor/pg_loss:0.06894284230351184 - actor/grad_norm:0.6542303295598988 - perf/mfu/actor:0.041666625506519506 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.501953125 - perf/cpu_memory_used_gb:95.25165557861328 - actor/lr:5e-07 - training/global_step:60.0 - training/epoch:0.0 - critic/score/mean:0.2333984375 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.2333984375 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.07066783215850592 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.07066783215850592 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:295.3759765625 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.0029296875 - response_length_non_aborted/mean:295.3759765625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.0029296875 - response/aborted_ratio:0.0 - prompt_length/mean:102.43359375 - prompt_length/max:191.0 - prompt_length/min:70.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:41.19992647692561 - timing_s/reward:0.000794626772403717 - timing_s/old_log_prob:0.0009960681200027466 - timing_s/ref:63.156080801039934 - timing_s/adv:0.2526811920106411 - timing_s/update_actor:123.77444515377283 - timing_s/step:228.39079423621297 - timing_per_token_ms/update_actor:0.13967933753902934 - timing_per_token_ms/adv:0.00025952188641427767 - timing_per_token_ms/ref:0.06562916375004434 - timing_per_token_ms/gen:0.005095373358875393 - perf/total_num_tokens:814714.0 - perf/time_per_step:228.39079423621297 - perf/throughput:891.7982035184207 - trainer/idle_ratio:0.18039223785138478
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 14,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 3890,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 1,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 50,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 45.80 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 14 to 15
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 14 to 15 ,reset staleness_samples to: 51,idle_ratio: 0.005937291219004215
[36m(FullyAsyncRollouter pid=551476)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:48:21,737 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'green'}
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.6245241165161133 seconds, while cache cost 6.4373016357421875e-06 seconds,  register cost 0.0004899501800537109 seconds, update cost 0.12528038024902344 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:15 - timing_s/wait_last_valid:0.002956252545118332 - timing_s/param_sync:47.43260591849685
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:48:21,737 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 47.43 seconds, pause:45.80s, sync:1.63s
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1312830448150635 seconds, while cache cost 0.7893671989440918 seconds,  register cost 0.2138829231262207 seconds, update cost 0.12540745735168457 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.49363040924072266 seconds, offload model to cpu cost 1.6105906963348389 seconds
[36m(FullyAsyncRollouter pid=551476)[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': True, 'validate': True, 'global_steps': 4020}
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(FullyAsyncRollouter pid=551476)[0m validation generation end
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.6243653297424316 seconds, while cache cost 6.67572021484375e-06 seconds,  register cost 0.0004887580871582031 seconds, update cost 0.12532305717468262 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.1623544692993164 seconds, while cache cost 0.7197167873382568 seconds,  register cost 0.042182207107543945 seconds, update cost 0.1252608299255371 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.46325159072875977 seconds, offload model to cpu cost 1.591792106628418 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 15,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 51,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 3891,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=3900, queue_size=1
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 410.87 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=4000, queue_size=96
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 15,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 4094,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 53,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 190,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=4100, queue_size=196
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 61 local_trigger_step: 1 trigger_parameter_sync_step: 4 01:56:07.338
[36m(FullyAsyncTrainer pid=555857)[0m step:15 - val-aux/openai/gsm8k/reward/mean@1:0.2100075815011372 - val-core/openai/gsm8k/acc/mean@1:0.23426838514025777 - val-aux/num_turns/min:2 - val-aux/num_turns/max:2 - val-aux/num_turns/mean:2.0
[36m(FullyAsyncTrainer pid=555857)[0m ('[FullyAsyncTrainer] parameter version: 15 Validation metrics: '
[36m(FullyAsyncTrainer pid=555857)[0m  "{'val-aux/openai/gsm8k/reward/mean@1': 0.2100075815011372, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-core/openai/gsm8k/acc/mean@1': 0.23426838514025777, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-aux/num_turns/min': 2, 'val-aux/num_turns/max': 2, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-aux/num_turns/mean': 2.0}")
[36m(FullyAsyncTrainer pid=555857)[0m step:15 - rollouter/active_time:274.2849454879761 - rollouter/version_time:275.92318177223206 - rollouter/idle_ratio:0.005937291219004215 - rollouter/validate_time:373.65292813256383
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:56:07,342 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 163
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 163
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 62 local_trigger_step: 2 trigger_parameter_sync_step: 4 01:56:49.924
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:56:49,927 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 15,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 4141,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 6,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 142,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 109
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.33 seconds.mq_len: 109
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 63 local_trigger_step: 3 trigger_parameter_sync_step: 4 01:57:34.177
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:57:34,181 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  55%|█████████████████████████████████████████████████████████████████████████████▊                                                               | 16/29 [1:38:12<1:27:25, 403.53s/it]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 45
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.36 seconds.mq_len: 45
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 64 local_trigger_step: 4 trigger_parameter_sync_step: 4 01:58:21.532
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006542205810546875
[36m(FullyAsyncTrainer pid=555857)[0m step:16 - fully_async/count/stale_samples_processed:757.0 - fully_async/count/stale_trajectory_processed:6056.0 - fully_async/count/current_param_version:15.0 - fully_async/processing_time/avg:37.838929867808474 - fully_async/processing_time/max:272.24534088745713 - fully_async/processing_time/min:0.4084801599383354 - fully_async/processing_time/tp50:38.14785975497216 - fully_async/processing_time/tp99:73.6759054472297 - fully_async/processing_time/tp95:61.0462472023908 - fully_async/monitor/active_tasks_size:147.25 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:4032.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:411.9103362560272 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:3.336075295228807 - rollout_corr/training_log_ppl:0.8038596754840442 - rollout_corr/kl:0.05858592702783079 - rollout_corr/k3_kl:0.04598261563484335 - rollout_corr/rollout_ppl:2.5983042518628965 - rollout_corr/rollout_log_ppl:0.7240846725588753 - rollout_corr/log_ppl_diff:0.07977500626977185 - rollout_corr/log_ppl_abs_diff:0.0804254335700442 - rollout_corr/log_ppl_diff_max:2.2709412574768066 - rollout_corr/log_ppl_diff_min:-0.11356878280639648 - rollout_corr/ppl_ratio:1.1003538190750848 - rollout_corr/chi2_token:0.0312930430282676 - rollout_corr/chi2_seq:-0.3105787415518647 - actor/kl_loss:0.025378394690933562 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.02592780969101503 - actor/ppo_kl:0.05820013617388487 - actor/pg_clipfrac_lower:0.0002527590252453044 - actor/pg_loss:0.05043566885656522 - actor/grad_norm:0.628174345696008 - perf/mfu/actor:0.04016259667975823 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.501953125 - perf/cpu_memory_used_gb:95.24786710739136 - actor/lr:5e-07 - training/global_step:64.0 - training/epoch:0.0 - critic/score/mean:0.18666744232177734 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.18666744232177734 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.048303081188350916 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.048303081188350916 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:278.62548828125 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.00048828125 - response_length_non_aborted/mean:278.62548828125 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.00048828125 - response/aborted_ratio:0.0 - prompt_length/mean:103.98828125 - prompt_length/max:195.0 - prompt_length/min:65.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:413.7154135219753 - timing_s/reward:0.000864904373884201 - timing_s/old_log_prob:0.0010619200766086578 - timing_s/ref:62.86688673496246 - timing_s/adv:0.2440330758690834 - timing_s/update_actor:122.87471982464194 - timing_s/step:599.7090450339019 - timing_per_token_ms/update_actor:0.14571580068801843 - timing_per_token_ms/adv:0.0002436747972360576 - timing_per_token_ms/ref:0.0696380667530922 - timing_per_token_ms/gen:0.005160300000144739 - perf/total_num_tokens:783593.0 - perf/time_per_step:599.7090450339019 - perf/throughput:326.6554867267772 - trainer/idle_ratio:0.6898602196313175
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 26.27 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 15 to 16
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 15 to 16 ,reset staleness_samples to: 51,idle_ratio: 0.006126108236688688
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.5408053398132324 seconds, while cache cost 7.152557373046875e-06 seconds,  register cost 0.0005095005035400391 seconds, update cost 0.12326836585998535 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:16 - timing_s/wait_last_valid:0.0035564154386520386 - timing_s/param_sync:27.821949008852243
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 01:58:49,375 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 27.82 seconds, pause:26.27s, sync:1.55s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.0831408500671387 seconds, while cache cost 0.7438795566558838 seconds,  register cost 0.2132551670074463 seconds, update cost 0.12333321571350098 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.45870018005371094 seconds, offload model to cpu cost 1.5912530422210693 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 16,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 4147,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 256,
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  59%|██████████████████████████████████████████████████████████████████████████████████▋                                                          | 17/29 [1:42:27<1:11:47, 358.95s/it]
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558094)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.540691614151001 seconds, while cache cost 5.7220458984375e-06 seconds,  register cost 0.0004603862762451172 seconds, update cost 0.1231377124786377 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.0916543006896973 seconds, while cache cost 0.706815242767334 seconds,  register cost 0.04064750671386719 seconds, update cost 0.12326431274414062 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4500100612640381 seconds, offload model to cpu cost 1.6152067184448242 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 34.45 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=4200, queue_size=40
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=4300, queue_size=140
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 16,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 4355,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 48,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 195,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 65 local_trigger_step: 1 trigger_parameter_sync_step: 4 02:00:22.126
[36m(FullyAsyncTrainer pid=555857)[0m step:16 - rollouter/active_time:252.42234206199646 - rollouter/version_time:253.97824025154114 - rollouter/idle_ratio:0.006126108236688688
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:00:22,130 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 156
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 156
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 66 local_trigger_step: 2 trigger_parameter_sync_step: 4 02:01:04.966
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:01:04,969 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 104
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.38 seconds.mq_len: 104
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 16,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 4392,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 11,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 104,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 67 local_trigger_step: 3 trigger_parameter_sync_step: 4 02:01:50.754
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:01:50,758 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 43
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.36 seconds.mq_len: 43
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 68 local_trigger_step: 4 trigger_parameter_sync_step: 4 02:02:36.826
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006253719329833984
[36m(FullyAsyncTrainer pid=555857)[0m step:17 - fully_async/count/stale_samples_processed:808.0 - fully_async/count/stale_trajectory_processed:6464.0 - fully_async/count/current_param_version:16.0 - fully_async/processing_time/avg:37.059426610905575 - fully_async/processing_time/max:251.586531188339 - fully_async/processing_time/min:0.5236832275986671 - fully_async/processing_time/tp50:36.72730239620432 - fully_async/processing_time/tp99:102.401864069765 - fully_async/processing_time/tp95:62.885727427201346 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:4288.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:35.50367617607117 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:3.6959172917360603 - rollout_corr/training_log_ppl:0.9554812507515754 - rollout_corr/kl:0.10427337835896808 - rollout_corr/k3_kl:0.08144270887229747 - rollout_corr/rollout_ppl:2.926865167289564 - rollout_corr/rollout_log_ppl:0.809836385881832 - rollout_corr/log_ppl_diff:0.14564486834691626 - rollout_corr/log_ppl_abs_diff:0.14581486351722864 - rollout_corr/log_ppl_diff_max:2.2039101123809814 - rollout_corr/log_ppl_diff_min:-0.05695021152496338 - rollout_corr/ppl_ratio:1.1919815715504503 - rollout_corr/chi2_token:0.19692725366623845 - rollout_corr/chi2_seq:-0.9443665350536032 - actor/kl_loss:0.026967562343837886 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.032321740396724495 - actor/ppo_kl:0.10374668582641078 - actor/pg_clipfrac_lower:0.00039484025112490574 - actor/pg_loss:0.06626114265450722 - actor/grad_norm:0.5910858314148686 - perf/mfu/actor:0.039193239926184634 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.65625 - perf/cpu_memory_used_gb:95.20980024337769 - actor/lr:5e-07 - training/global_step:68.0 - training/epoch:0.0 - critic/score/mean:0.16064453125 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.16064453125 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.0645552239875542 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.0645552239875542 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:280.1123046875 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.0029296875 - response_length_non_aborted/mean:280.1123046875 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.0029296875 - response/aborted_ratio:0.0 - prompt_length/mean:103.46875 - prompt_length/max:216.0 - prompt_length/min:66.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:37.2431301549077 - timing_s/reward:0.0008227303624153137 - timing_s/old_log_prob:0.0010453574359416962 - timing_s/ref:62.85596492886543 - timing_s/adv:0.23487595468759537 - timing_s/update_actor:127.01822240278125 - timing_s/step:227.35995493084192 - timing_per_token_ms/update_actor:0.13646602188919688 - timing_per_token_ms/adv:0.00022588292006709264 - timing_per_token_ms/ref:0.0706173569579504 - timing_per_token_ms/gen:0.00485088384030538 - perf/total_num_tokens:785574.0 - perf/time_per_step:227.35995493084192 - perf/throughput:863.7998721443217 - trainer/idle_ratio:0.16380690331433376
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=4400, queue_size=48
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 80.03 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 16 to 17
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 16 to 17 ,reset staleness_samples to: 51,idle_ratio: 0.005142593967977227
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.5755038261413574 seconds, while cache cost 7.152557373046875e-06 seconds,  register cost 0.0004987716674804688 seconds, update cost 0.12281131744384766 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:17 - timing_s/wait_last_valid:0.0037143751978874207 - timing_s/param_sync:81.6152416318655
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:03:58,463 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 81.61 seconds, pause:80.03s, sync:1.58s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.094616413116455 seconds, while cache cost 0.753408670425415 seconds,  register cost 0.21522092819213867 seconds, update cost 0.12290501594543457 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4815351963043213 seconds, offload model to cpu cost 1.6198647022247314 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 17,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 4403,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558094)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  62%|███████████████████████████████████████████████████████████████████████████████████████▌                                                     | 18/29 [1:47:38<1:03:10, 344.60s/it]
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.575502872467041 seconds, while cache cost 5.4836273193359375e-06 seconds,  register cost 0.0004699230194091797 seconds, update cost 0.1228933334350586 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.098285436630249 seconds, while cache cost 0.6983373165130615 seconds,  register cost 0.04520249366760254 seconds, update cost 0.12285566329956055 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.47783398628234863 seconds, offload model to cpu cost 1.6123173236846924 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 34.72 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=4500, queue_size=84
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=4600, queue_size=184
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 17,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 4629,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 30,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 213,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 69 local_trigger_step: 1 trigger_parameter_sync_step: 4 02:05:34.232
[36m(FullyAsyncTrainer pid=555857)[0m step:17 - rollouter/active_time:307.4917850494385 - rollouter/version_time:309.0812644958496 - rollouter/idle_ratio:0.005142593967977227
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:05:34,236 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 171
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 171
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 70 local_trigger_step: 2 trigger_parameter_sync_step: 4 02:06:16.710
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:06:16,714 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 110
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.34 seconds.mq_len: 110
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 17,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 4655,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 4,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 111,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 71 local_trigger_step: 3 trigger_parameter_sync_step: 4 02:07:00.450
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:07:00,454 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 48
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 48
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 72 local_trigger_step: 4 trigger_parameter_sync_step: 4 02:07:48.017
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006861686706542969
[36m(FullyAsyncTrainer pid=555857)[0m step:18 - fully_async/count/stale_samples_processed:859.0 - fully_async/count/stale_trajectory_processed:6872.0 - fully_async/count/current_param_version:17.0 - fully_async/processing_time/avg:38.15583403959681 - fully_async/processing_time/max:306.07564621046185 - fully_async/processing_time/min:0.6292934864759445 - fully_async/processing_time/tp50:36.830853779334575 - fully_async/processing_time/tp99:116.53989464027806 - fully_async/processing_time/tp95:61.213090436626224 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:4544.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:35.73543190956116 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:2.681690023245161 - rollout_corr/training_log_ppl:0.6679238362502298 - rollout_corr/kl:0.027045220886652996 - rollout_corr/k3_kl:0.021028085113421795 - rollout_corr/rollout_ppl:2.5111995069994366 - rollout_corr/rollout_log_ppl:0.6403579192504566 - rollout_corr/log_ppl_diff:0.027565917186418307 - rollout_corr/log_ppl_abs_diff:0.02913128396252698 - rollout_corr/log_ppl_diff_max:1.0945801734924316 - rollout_corr/log_ppl_diff_min:-0.09499621391296387 - rollout_corr/ppl_ratio:1.032395714136598 - rollout_corr/chi2_token:0.10258910406049379 - rollout_corr/chi2_seq:0.3838981178634718 - actor/kl_loss:0.030373213779585295 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.008263774569752755 - actor/ppo_kl:0.026999905380859536 - actor/pg_clipfrac_lower:0.0001542053194918061 - actor/pg_loss:0.07503313081708127 - actor/grad_norm:0.7016434582458869 - perf/mfu/actor:0.03811022479665213 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.65625 - perf/cpu_memory_used_gb:95.25087976455688 - actor/lr:5e-07 - training/global_step:72.0 - training/epoch:0.0 - critic/score/mean:0.2744140625 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.2744140625 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.0776330778026022 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.0776330778026022 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:277.3818359375 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.00341796875 - response_length_non_aborted/mean:277.3818359375 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.00341796875 - response/aborted_ratio:0.0 - prompt_length/mean:102.44140625 - prompt_length/max:173.0 - prompt_length/min:56.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:37.445898592472076 - timing_s/reward:0.0009458325803279877 - timing_s/old_log_prob:0.0009866878390312195 - timing_s/ref:62.69472171738744 - timing_s/adv:0.2326265089213848 - timing_s/update_actor:129.08914826065302 - timing_s/step:229.47022773697972 - timing_per_token_ms/update_actor:0.1474351148288718 - timing_per_token_ms/adv:0.00022514245749873343 - timing_per_token_ms/ref:0.0682024422482406 - timing_per_token_ms/gen:0.004822937452801545 - perf/total_num_tokens:777878.0 - perf/time_per_step:229.47022773697972 - perf/throughput:847.4715954128142 - trainer/idle_ratio:0.16318412615772016
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 17,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 4658,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 1,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 50,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 72.56 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 17 to 18
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 17 to 18 ,reset staleness_samples to: 51,idle_ratio: 0.00504601329237242
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.519587755203247 seconds, while cache cost 7.867813110351562e-06 seconds,  register cost 0.0005002021789550781 seconds, update cost 0.12334251403808594 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:18 - timing_s/wait_last_valid:0.002797286957502365 - timing_s/param_sync:74.09314629435539
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:09:02,131 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 74.09 seconds, pause:72.57s, sync:1.52s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.0204920768737793 seconds, while cache cost 0.7906718254089355 seconds,  register cost 0.10341644287109375 seconds, update cost 0.12338995933532715 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.49931883811950684 seconds, offload model to cpu cost 1.6069648265838623 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 18,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 4659,
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  66%|█████████████████████████████████████████████████████████████████████████████████████████████▋                                                 | 19/29 [1:52:36<55:06, 330.64s/it]
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.5192115306854248 seconds, while cache cost 7.867813110351562e-06 seconds,  register cost 0.0004947185516357422 seconds, update cost 0.12343525886535645 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.0265045166015625 seconds, while cache cost 0.7086703777313232 seconds,  register cost 0.04006814956665039 seconds, update cost 0.12337660789489746 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.49333691596984863 seconds, offload model to cpu cost 1.5880427360534668 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 35.89 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.31s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=4700, queue_size=28
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=4800, queue_size=128
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 18,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 4899,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 16,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 227,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=4900, queue_size=228
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 73 local_trigger_step: 1 trigger_parameter_sync_step: 4 02:10:32.640
[36m(FullyAsyncTrainer pid=555857)[0m step:18 - rollouter/active_time:302.1333575248718 - rollouter/version_time:303.6656584739685 - rollouter/idle_ratio:0.00504601329237242
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:10:32,644 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 171
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.34 seconds.mq_len: 171
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 74 local_trigger_step: 2 trigger_parameter_sync_step: 4 02:11:14.890
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:11:14,893 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 112
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.34 seconds.mq_len: 112
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 18,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 4913,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 2,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 113,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 75 local_trigger_step: 3 trigger_parameter_sync_step: 4 02:11:59.279
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:11:59,282 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 49
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 49
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 76 local_trigger_step: 4 trigger_parameter_sync_step: 4 02:12:46.141
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006120204925537109
[36m(FullyAsyncTrainer pid=555857)[0m step:19 - fully_async/count/stale_samples_processed:910.0 - fully_async/count/stale_trajectory_processed:7280.0 - fully_async/count/current_param_version:18.0 - fully_async/processing_time/avg:38.48288338841667 - fully_async/processing_time/max:300.437396004796 - fully_async/processing_time/min:0.45208553224802017 - fully_async/processing_time/tp50:37.89645528420806 - fully_async/processing_time/tp99:69.85553668283853 - fully_async/processing_time/tp95:58.21429066490382 - fully_async/monitor/active_tasks_size:147.25 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:95.75 - fully_async/count/total_generated_samples:4800.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:36.88712453842163 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:2.109626277421116 - rollout_corr/training_log_ppl:0.5853560621283066 - rollout_corr/kl:0.0008033849264053545 - rollout_corr/k3_kl:0.0008417305486912117 - rollout_corr/rollout_ppl:2.1051280266870065 - rollout_corr/rollout_log_ppl:0.5841649497864555 - rollout_corr/log_ppl_diff:0.0011911112083137884 - rollout_corr/log_ppl_abs_diff:0.002949083307554709 - rollout_corr/log_ppl_diff_max:0.12929320335388184 - rollout_corr/log_ppl_diff_min:-0.19550561904907227 - rollout_corr/ppl_ratio:1.0012282262587164 - rollout_corr/chi2_token:0.0017664254700810707 - rollout_corr/chi2_seq:0.7169826853547304 - actor/kl_loss:0.03014722610784753 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.0018351897330147217 - actor/ppo_kl:0.0008033849264053545 - actor/pg_clipfrac_lower:0.0 - actor/pg_loss:0.048441406641178096 - actor/grad_norm:0.6499261922229436 - perf/mfu/actor:0.04009976365029428 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.65625 - perf/cpu_memory_used_gb:95.38946628570557 - actor/lr:5e-07 - training/global_step:76.0 - training/epoch:0.0 - critic/score/mean:0.2652597427368164 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.2652597427368164 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.04920579004101455 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.04920579004101455 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:273.9482421875 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.00048828125 - response_length_non_aborted/mean:273.9482421875 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.00048828125 - response/aborted_ratio:0.0 - prompt_length/mean:106.2265625 - prompt_length/max:238.0 - prompt_length/min:66.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:38.69365620613098 - timing_s/reward:0.0007902458310127258 - timing_s/old_log_prob:0.0010071620345115662 - timing_s/ref:63.003433145582676 - timing_s/adv:0.23647668212652206 - timing_s/update_actor:121.98417066410184 - timing_s/step:223.92519922181964 - timing_per_token_ms/update_actor:0.13793664302902142 - timing_per_token_ms/adv:0.0002593455028987053 - timing_per_token_ms/ref:0.07165261200781639 - timing_per_token_ms/gen:0.004864115322894824 - perf/total_num_tokens:778598.0 - perf/time_per_step:223.92519922181964 - perf/throughput:869.2612563322128 - trainer/idle_ratio:0.17279723917003714
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 45.73 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 18 to 19
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 18 to 19 ,reset staleness_samples to: 51,idle_ratio: 0.006030397707681212
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.6223673820495605 seconds, while cache cost 6.198883056640625e-06 seconds,  register cost 0.0004982948303222656 seconds, update cost 0.12383580207824707 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:19 - timing_s/wait_last_valid:0.0030293911695480347 - timing_s/param_sync:47.359866324812174
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:13:33,522 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 47.36 seconds, pause:45.73s, sync:1.63s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1349372863769531 seconds, while cache cost 0.7934472560882568 seconds,  register cost 0.21492505073547363 seconds, update cost 0.1239321231842041 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4876687526702881 seconds, offload model to cpu cost 1.6058166027069092 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 19,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 4915,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  69%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                            | 20/29 [1:57:07<46:54, 312.77s/it]
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.6222124099731445 seconds, while cache cost 6.198883056640625e-06 seconds,  register cost 0.0004570484161376953 seconds, update cost 0.12381649017333984 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.1680870056152344 seconds, while cache cost 0.7362806797027588 seconds,  register cost 0.04110097885131836 seconds, update cost 0.12375473976135254 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4550819396972656 seconds, offload model to cpu cost 1.6391937732696533 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 34.83 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.34s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=5000, queue_size=72
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=5100, queue_size=172
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 19,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 5147,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 24,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 219,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 77 local_trigger_step: 1 trigger_parameter_sync_step: 4 02:15:05.103
[36m(FullyAsyncTrainer pid=555857)[0m step:19 - rollouter/active_time:269.74938440322876 - rollouter/version_time:271.3859496116638 - rollouter/idle_ratio:0.006030397707681212
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:15:05,106 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 171
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.39 seconds.mq_len: 171
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 78 local_trigger_step: 2 trigger_parameter_sync_step: 4 02:15:47.601
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:15:47,605 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 115
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.36 seconds.mq_len: 115
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 19,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 5171,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 115,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 79 local_trigger_step: 3 trigger_parameter_sync_step: 4 02:16:31.288
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:16:31,291 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 51
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 51
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 19,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 5171,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 51,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 80 local_trigger_step: 4 trigger_parameter_sync_step: 4 02:17:17.251
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006468296051025391
[36m(FullyAsyncTrainer pid=555857)[0m step:20 - fully_async/count/stale_samples_processed:961.0 - fully_async/count/stale_trajectory_processed:7688.0 - fully_async/count/current_param_version:19.0 - fully_async/processing_time/avg:38.03285824545674 - fully_async/processing_time/max:268.3890117779374 - fully_async/processing_time/min:0.7406416945159435 - fully_async/processing_time/tp50:38.10539862327278 - fully_async/processing_time/tp99:65.18005246138199 - fully_async/processing_time/tp95:56.25626362524926 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:5056.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:35.924001693725586 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:2.217669234906563 - rollout_corr/training_log_ppl:0.5831112017147965 - rollout_corr/kl:0.0009440146419947189 - rollout_corr/k3_kl:0.0008525136472740895 - rollout_corr/rollout_ppl:2.212873305051506 - rollout_corr/rollout_log_ppl:0.5816853758974849 - rollout_corr/log_ppl_diff:0.0014258252608884193 - rollout_corr/log_ppl_abs_diff:0.0027473945864783782 - rollout_corr/log_ppl_diff_max:0.298215389251709 - rollout_corr/log_ppl_diff_min:-0.011881589889526367 - rollout_corr/ppl_ratio:1.0014666052297667 - rollout_corr/chi2_token:0.0014991243372712933 - rollout_corr/chi2_seq:0.4850289765180551 - actor/kl_loss:0.03218032139968608 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.0019434494637021321 - actor/ppo_kl:0.0009440146419947189 - actor/pg_clipfrac_lower:0.0 - actor/pg_loss:0.04992049131303793 - actor/grad_norm:0.6964014540715352 - perf/mfu/actor:0.03822924472657699 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.65625 - perf/cpu_memory_used_gb:95.31608867645264 - actor/lr:5e-07 - training/global_step:80.0 - training/epoch:0.0 - critic/score/mean:0.3037109375 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.3037109375 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.05081962514668703 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.05081962514668703 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:262.77978515625 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.0009765625 - response_length_non_aborted/mean:262.77978515625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.0009765625 - response/aborted_ratio:0.0 - prompt_length/mean:103.6328125 - prompt_length/max:232.0 - prompt_length/min:69.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:37.741653461009264 - timing_s/reward:0.0008272677659988403 - timing_s/old_log_prob:0.0010071173310279846 - timing_s/ref:62.26667218282819 - timing_s/adv:0.23999301344156265 - timing_s/update_actor:123.38982562720776 - timing_s/step:223.64596297591925 - timing_per_token_ms/update_actor:0.14274715222664294 - timing_per_token_ms/adv:0.0002495603096026158 - timing_per_token_ms/ref:0.07341052056385788 - timing_per_token_ms/gen:0.005248804498464644 - perf/total_num_tokens:750413.0 - perf/time_per_step:223.64596297591925 - perf/throughput:838.8403148605008 - trainer/idle_ratio:0.16875624741356518
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 0.02 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 19 to 20
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 19 to 20 ,reset staleness_samples to: 51,idle_ratio: 0.4184509680074132
[36m(FullyAsyncRollouter pid=551476)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:17:18,742 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'green'}
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.4337880611419678 seconds, while cache cost 6.9141387939453125e-06 seconds,  register cost 0.0005414485931396484 seconds, update cost 0.12469029426574707 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:20 - timing_s/wait_last_valid:0.003284212201833725 - timing_s/param_sync:1.4695466384291649
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:17:18,742 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 1.47 seconds, pause:0.03s, sync:1.44s
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:0.9799835681915283 seconds, while cache cost 0.7602307796478271 seconds,  register cost 0.09231710433959961 seconds, update cost 0.12480497360229492 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4556601047515869 seconds, offload model to cpu cost 1.598205804824829 seconds
[36m(FullyAsyncRollouter pid=551476)[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': True, 'validate': True, 'global_steps': 5300}
[36m(WorkerDict pid=558094)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(FullyAsyncRollouter pid=551476)[0m validation generation end
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.4339847564697266 seconds, while cache cost 5.9604644775390625e-06 seconds,  register cost 0.0004971027374267578 seconds, update cost 0.12467741966247559 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:0.9841189384460449 seconds, while cache cost 0.7347574234008789 seconds,  register cost 0.055406808853149414 seconds, update cost 0.12484598159790039 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4512441158294678 seconds, offload model to cpu cost 1.6175076961517334 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 20,
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  72%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 21/29 [2:07:04<53:04, 398.10s/it]
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 51,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 5171,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 407.98 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=5200, queue_size=16
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=5300, queue_size=116
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 20,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 5388,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 39,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 204,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=5400, queue_size=216
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 81 local_trigger_step: 1 trigger_parameter_sync_step: 4 02:24:59.783
[36m(FullyAsyncTrainer pid=555857)[0m step:20 - val-aux/openai/gsm8k/reward/mean@1:0.23426838514025777 - val-core/openai/gsm8k/acc/mean@1:0.25549658832448824 - val-aux/num_turns/min:2 - val-aux/num_turns/max:2 - val-aux/num_turns/mean:2.0
[36m(FullyAsyncTrainer pid=555857)[0m ('[FullyAsyncTrainer] parameter version: 20 Validation metrics: '
[36m(FullyAsyncTrainer pid=555857)[0m  "{'val-aux/openai/gsm8k/reward/mean@1': 0.23426838514025777, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-core/openai/gsm8k/acc/mean@1': 0.25549658832448824, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-aux/num_turns/min': 2, 'val-aux/num_turns/max': 2, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-aux/num_turns/mean': 2.0}")
[36m(FullyAsyncTrainer pid=555857)[0m step:20 - rollouter/active_time:130.97316670417786 - rollouter/version_time:225.21431469917297 - rollouter/idle_ratio:0.4184509680074132 - rollouter/validate_time:374.4120140708983
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:24:59,788 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 157
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.33 seconds.mq_len: 157
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 82 local_trigger_step: 2 trigger_parameter_sync_step: 4 02:25:42.274
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:25:42,277 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 110
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.34 seconds.mq_len: 110
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 83 local_trigger_step: 3 trigger_parameter_sync_step: 4 02:26:27.064
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:26:27,068 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 46
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.36 seconds.mq_len: 46
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.35s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 20,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 5423,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 4,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 47,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 84 local_trigger_step: 4 trigger_parameter_sync_step: 4 02:27:14.308
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006668567657470703
[36m(FullyAsyncTrainer pid=555857)[0m step:21 - fully_async/count/stale_samples_processed:1012.0 - fully_async/count/stale_trajectory_processed:8096.0 - fully_async/count/current_param_version:20.0 - fully_async/processing_time/avg:37.080353897963505 - fully_async/processing_time/max:129.69442281872034 - fully_async/processing_time/min:0.5353519059717655 - fully_async/processing_time/tp50:37.22539588995278 - fully_async/processing_time/tp99:64.76808202537708 - fully_async/processing_time/tp95:57.77025432181545 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:5312.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:409.0039527416229 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:4.391447232839483 - rollout_corr/training_log_ppl:0.789294247841366 - rollout_corr/kl:0.07520423025688232 - rollout_corr/k3_kl:0.059204305971721695 - rollout_corr/rollout_ppl:2.470336456368552 - rollout_corr/rollout_log_ppl:0.6888795809844719 - rollout_corr/log_ppl_diff:0.10041466700317667 - rollout_corr/log_ppl_abs_diff:0.10076242566614939 - rollout_corr/log_ppl_diff_max:5.816944122314453 - rollout_corr/log_ppl_diff_min:-0.014641597867012024 - rollout_corr/ppl_ratio:1.2794586464330768 - rollout_corr/chi2_token:0.07114333228264043 - rollout_corr/chi2_seq:-0.543530257635996 - actor/kl_loss:0.03481397999089347 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.025544874713971218 - actor/ppo_kl:0.07472488902446907 - actor/pg_clipfrac_lower:0.00025501404078730726 - actor/pg_loss:0.030000650462361406 - actor/grad_norm:0.5767204569864047 - perf/mfu/actor:0.03911990599885039 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.65625 - perf/cpu_memory_used_gb:95.49797773361206 - actor/lr:5e-07 - training/global_step:84.0 - training/epoch:0.0 - critic/score/mean:0.1875 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.1875 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-0.026507069589570165 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.026507069589570165 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:264.78515625 - response_length/max:1525.0 - response_length/min:3.0 - response_length/clip_ratio:0.0 - response_length_non_aborted/mean:264.78515625 - response_length_non_aborted/max:1525.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.0 - response/aborted_ratio:0.0 - prompt_length/mean:104.8984375 - prompt_length/max:199.0 - prompt_length/min:70.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:410.9242495559156 - timing_s/reward:0.0008672699332237244 - timing_s/old_log_prob:0.0010029971599578857 - timing_s/ref:62.63255286961794 - timing_s/adv:0.23904349654912949 - timing_s/update_actor:121.65703866630793 - timing_s/step:595.4606763236225 - timing_per_token_ms/update_actor:0.14548747922045938 - timing_per_token_ms/adv:0.00025787530252136974 - timing_per_token_ms/ref:0.07396206405938072 - timing_per_token_ms/gen:0.00572590513998709 - perf/total_num_tokens:757112.0 - perf/time_per_step:595.4606763236225 - perf/throughput:317.8681775740481 - trainer/idle_ratio:0.690094687852377
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 123.75 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 20 to 21
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 20 to 21 ,reset staleness_samples to: 51,idle_ratio: 0.0043574833067643315
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.4947421550750732 seconds, while cache cost 6.67572021484375e-06 seconds,  register cost 0.00047779083251953125 seconds, update cost 0.12438321113586426 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:21 - timing_s/wait_last_valid:0.0027698203921318054 - timing_s/param_sync:125.25258938223124
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:29:19,588 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 125.25 seconds, pause:123.75s, sync:1.50s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:0.9916324615478516 seconds, while cache cost 0.7700350284576416 seconds,  register cost 0.09406542778015137 seconds, update cost 0.12444448471069336 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.5035700798034668 seconds, offload model to cpu cost 1.6176767349243164 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 21,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 5427,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                  | 22/29 [2:12:46<44:27, 381.13s/it]
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.4945847988128662 seconds, while cache cost 5.9604644775390625e-06 seconds,  register cost 0.0004642009735107422 seconds, update cost 0.12441825866699219 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.0078482627868652 seconds, while cache cost 0.7154407501220703 seconds,  register cost 0.04299759864807129 seconds, update cost 0.12447857856750488 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.48685765266418457 seconds, offload model to cpu cost 1.6201260089874268 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 32.43 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.31s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=5500, queue_size=60
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=5600, queue_size=160
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 21,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 5660,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 23,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 221,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 85 local_trigger_step: 1 trigger_parameter_sync_step: 4 02:30:45.034
[36m(FullyAsyncTrainer pid=555857)[0m step:21 - rollouter/active_time:344.9173381328583 - rollouter/version_time:346.42688751220703 - rollouter/idle_ratio:0.0043574833067643315
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:30:45,039 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 167
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.34 seconds.mq_len: 167
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 86 local_trigger_step: 2 trigger_parameter_sync_step: 4 02:31:27.660
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:31:27,663 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 109
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.33 seconds.mq_len: 109
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 21,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 5677,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 6,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 109,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 87 local_trigger_step: 3 trigger_parameter_sync_step: 4 02:32:10.815
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:32:10,818 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 47
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.31 seconds.mq_len: 47
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 88 local_trigger_step: 4 trigger_parameter_sync_step: 4 02:32:55.849
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006320476531982422
[36m(FullyAsyncTrainer pid=555857)[0m step:22 - fully_async/count/stale_samples_processed:1063.0 - fully_async/count/stale_trajectory_processed:8504.0 - fully_async/count/current_param_version:21.0 - fully_async/processing_time/avg:36.722638279085004 - fully_async/processing_time/max:343.9608901962638 - fully_async/processing_time/min:0.3675171472132206 - fully_async/processing_time/tp50:35.55804440798238 - fully_async/processing_time/tp99:67.99581382413393 - fully_async/processing_time/tp95:57.07792976233177 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:5568.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:33.409037590026855 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:4.8251667155845075 - rollout_corr/training_log_ppl:0.5946284363119333 - rollout_corr/kl:0.023637976249470498 - rollout_corr/k3_kl:0.017910991165762447 - rollout_corr/rollout_ppl:3.4741480234551245 - rollout_corr/rollout_log_ppl:0.5699706120142604 - rollout_corr/log_ppl_diff:0.024657823804279232 - rollout_corr/log_ppl_abs_diff:0.026064089752356415 - rollout_corr/log_ppl_diff_max:1.6282124519348145 - rollout_corr/log_ppl_diff_min:-0.1358799934387207 - rollout_corr/ppl_ratio:1.028845938270082 - rollout_corr/chi2_token:0.01618630785849832 - rollout_corr/chi2_seq:0.034679634955187305 - actor/kl_loss:0.036874847284217194 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.010373899447159177 - actor/ppo_kl:0.023581199973146554 - actor/pg_clipfrac_lower:0.00010983032113169126 - actor/pg_loss:0.0681544864196544 - actor/grad_norm:0.7428225834185554 - perf/mfu/actor:0.03927471382892919 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.65625 - perf/cpu_memory_used_gb:95.42398118972778 - actor/lr:5e-07 - training/global_step:88.0 - training/epoch:0.0 - critic/score/mean:0.306640625 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.306640625 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.07005493307951838 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.07005493307951838 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:260.0693359375 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.001953125 - response_length_non_aborted/mean:260.0693359375 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.001953125 - response/aborted_ratio:0.0 - prompt_length/mean:102.02734375 - prompt_length/max:177.0 - prompt_length/min:68.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:35.22577831894159 - timing_s/reward:0.0008260421454906464 - timing_s/old_log_prob:0.0010094530880451202 - timing_s/ref:62.07191985473037 - timing_s/adv:0.24046143144369125 - timing_s/update_actor:118.62399509549141 - timing_s/step:216.17013933882117 - timing_per_token_ms/update_actor:0.14575767697516945 - timing_per_token_ms/adv:0.00024931890323210266 - timing_per_token_ms/ref:0.07143773424639124 - timing_per_token_ms/gen:0.005248497029273317 - perf/total_num_tokens:741574.0 - perf/time_per_step:216.17013933882117 - perf/throughput:857.6277027301055 - trainer/idle_ratio:0.16295395111777833
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 21,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 5681,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 2,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 49,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 148.51 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 21 to 22
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 21 to 22 ,reset staleness_samples to: 51,idle_ratio: 0.004438731774713545
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.6114983558654785 seconds, while cache cost 6.198883056640625e-06 seconds,  register cost 0.0004742145538330078 seconds, update cost 0.12447404861450195 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:22 - timing_s/wait_last_valid:0.0028524249792099 - timing_s/param_sync:150.127452544868
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:35:25,998 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 150.12 seconds, pause:148.51s, sync:1.62s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1144084930419922 seconds, while cache cost 0.7686657905578613 seconds,  register cost 0.21851587295532227 seconds, update cost 0.12454652786254883 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4974048137664795 seconds, offload model to cpu cost 1.5989458560943604 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 22,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 5683,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558094)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.6106948852539062 seconds, while cache cost 7.3909759521484375e-06 seconds,  register cost 0.0005340576171875 seconds, update cost 0.12442564964294434 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.143195629119873 seconds, while cache cost 0.7607951164245605 seconds,  register cost 0.04479837417602539 seconds, update cost 0.12442135810852051 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.46875882148742676 seconds, offload model to cpu cost 1.6085834503173828 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 30.73 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.83s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=5700, queue_size=4
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=5800, queue_size=104
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=5900, queue_size=204
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 22,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 5918,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 21,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 222,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 89 local_trigger_step: 1 trigger_parameter_sync_step: 4 02:36:52.863
[36m(FullyAsyncTrainer pid=555857)[0m step:22 - rollouter/active_time:364.77809476852417 - rollouter/version_time:366.4044659137726 - rollouter/idle_ratio:0.004438731774713545
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:36:52,867 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 167
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.33 seconds.mq_len: 167
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 90 local_trigger_step: 2 trigger_parameter_sync_step: 4 02:37:35.133
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:37:35,137 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 114
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.34 seconds.mq_len: 114
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 22,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 5938,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 1,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 114,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 91 local_trigger_step: 3 trigger_parameter_sync_step: 4 02:38:18.858
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:38:18,862 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 50
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 50
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.33s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 22,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 5939,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 51,
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                             | 23/29 [2:18:56<37:46, 377.70s/it]
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 92 local_trigger_step: 4 trigger_parameter_sync_step: 4 02:39:05.542
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006313323974609375
[36m(FullyAsyncTrainer pid=555857)[0m step:23 - fully_async/count/stale_samples_processed:1114.0 - fully_async/count/stale_trajectory_processed:8912.0 - fully_async/count/current_param_version:22.0 - fully_async/processing_time/avg:36.01426761086077 - fully_async/processing_time/max:363.47673792392015 - fully_async/processing_time/min:0.8180848471820354 - fully_async/processing_time/tp50:35.64035504125059 - fully_async/processing_time/tp99:74.29713309822594 - fully_async/processing_time/tp95:52.01093776165508 - fully_async/monitor/active_tasks_size:147.25 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:95.75 - fully_async/count/total_generated_samples:5824.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:31.726919412612915 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:1.9229966793878104 - rollout_corr/training_log_ppl:0.5135599657913102 - rollout_corr/kl:0.0008295651407113989 - rollout_corr/k3_kl:0.0007971177621619242 - rollout_corr/rollout_ppl:1.9203591652362517 - rollout_corr/rollout_log_ppl:0.5126285588001651 - rollout_corr/log_ppl_diff:0.0009314088054091839 - rollout_corr/log_ppl_abs_diff:0.0024444683233228073 - rollout_corr/log_ppl_diff_max:0.2060788869857788 - rollout_corr/log_ppl_diff_min:-0.03402864933013916 - rollout_corr/ppl_ratio:1.0009494958535077 - rollout_corr/chi2_token:0.0015476686306542527 - rollout_corr/chi2_seq:0.4851694592683824 - actor/kl_loss:0.037968727333522405 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.0019342874883952182 - actor/ppo_kl:0.0008295651407113989 - actor/pg_clipfrac_lower:1.5364570241548459e-06 - actor/pg_loss:0.051130742249873684 - actor/grad_norm:0.7071084968401289 - perf/mfu/actor:0.03690780250450666 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.65625 - perf/cpu_memory_used_gb:95.42263650894165 - actor/lr:5e-07 - training/global_step:92.0 - training/epoch:0.0 - critic/score/mean:0.35042667388916016 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.35042667388916016 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.053065411222632974 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.053065411222632974 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:249.36572265625 - response_length/max:3072.0 - response_length/min:5.0 - response_length/clip_ratio:0.0009765625 - response_length_non_aborted/mean:249.36572265625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:5.0 - response_length_non_aborted/clip_ratio:0.0009765625 - response/aborted_ratio:0.0 - prompt_length/mean:103.6484375 - prompt_length/max:184.0 - prompt_length/min:68.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:34.14272625744343 - timing_s/reward:0.0007947832345962524 - timing_s/old_log_prob:0.0009623095393180847 - timing_s/ref:61.367195796221495 - timing_s/adv:0.23736251518130302 - timing_s/update_actor:123.70512420684099 - timing_s/step:219.45989736169577 - timing_per_token_ms/update_actor:0.15140454042343432 - timing_per_token_ms/adv:0.0002870437124174241 - timing_per_token_ms/ref:0.07224463877429473 - timing_per_token_ms/gen:0.006001137596146575 - perf/total_num_tokens:722973.0 - perf/time_per_step:219.45989736169577 - perf/throughput:823.5821312816611 - trainer/idle_ratio:0.15557615157894744
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 0.02 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 22 to 23
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 22 to 23 ,reset staleness_samples to: 51,idle_ratio: 0.14470666876266725
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.4626858234405518 seconds, while cache cost 6.9141387939453125e-06 seconds,  register cost 0.0004947185516357422 seconds, update cost 0.12474608421325684 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:23 - timing_s/wait_last_valid:0.0033383257687091827 - timing_s/param_sync:1.4978117495775223
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:39:07,061 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 1.49 seconds, pause:0.03s, sync:1.47s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.003568172454834 seconds, while cache cost 0.785968542098999 seconds,  register cost 0.09015893936157227 seconds, update cost 0.12483787536621094 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.46051955223083496 seconds, offload model to cpu cost 1.587522029876709 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 32.41 seconds.mq_len: 0
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                        | 24/29 [2:22:42<27:42, 332.45s/it]
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.4624888896942139 seconds, while cache cost 6.4373016357421875e-06 seconds,  register cost 0.0004820823669433594 seconds, update cost 0.12475895881652832 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.0095059871673584 seconds, while cache cost 0.7154662609100342 seconds,  register cost 0.03727102279663086 seconds, update cost 0.12487173080444336 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.45438051223754883 seconds, offload model to cpu cost 1.5977566242218018 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.31s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=6000, queue_size=48
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 23,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 6017,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 178,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 65,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=6100, queue_size=148
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 93 local_trigger_step: 1 trigger_parameter_sync_step: 4 02:40:40.646
[36m(FullyAsyncTrainer pid=555857)[0m step:23 - rollouter/active_time:189.0688714981079 - rollouter/version_time:221.0573432445526 - rollouter/idle_ratio:0.14470666876266725
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:40:40,650 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 174
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.37 seconds.mq_len: 174
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 23,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 6192,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 3,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 176,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 94 local_trigger_step: 2 trigger_parameter_sync_step: 4 02:41:23.858
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:41:23,861 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 113
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 113
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.31s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 95 local_trigger_step: 3 trigger_parameter_sync_step: 4 02:42:06.743
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:42:06,746 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 50
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 50
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 23,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 6194,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 1,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 50,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 96 local_trigger_step: 4 trigger_parameter_sync_step: 4 02:42:52.356
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006401538848876953
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m step:24 - fully_async/count/stale_samples_processed:1165.0 - fully_async/count/stale_trajectory_processed:9320.0 - fully_async/count/current_param_version:23.0 - fully_async/processing_time/avg:35.34179657403365 - fully_async/processing_time/max:187.97297770902514 - fully_async/processing_time/min:1.2253433614969254 - fully_async/processing_time/tp50:35.49909084755927 - fully_async/processing_time/tp99:60.73316971420311 - fully_async/processing_time/tp95:52.331464062025766 - fully_async/monitor/active_tasks_size:147.5 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:95.75 - fully_async/count/total_generated_samples:6080.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:33.47913479804993 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:1.864465677428555 - rollout_corr/training_log_ppl:0.4945601274362197 - rollout_corr/kl:0.0008341181149452135 - rollout_corr/k3_kl:0.0007775739215999651 - rollout_corr/rollout_ppl:1.8619184900970234 - rollout_corr/rollout_log_ppl:0.4935832450287296 - rollout_corr/log_ppl_diff:0.000976883343792469 - rollout_corr/log_ppl_abs_diff:0.0024147545024918926 - rollout_corr/log_ppl_diff_max:0.11169874668121338 - rollout_corr/log_ppl_diff_min:-0.011829227209091187 - rollout_corr/ppl_ratio:1.000987026986799 - rollout_corr/chi2_token:0.0014199367942070804 - rollout_corr/chi2_seq:0.4083613706752658 - actor/kl_loss:0.040676853108346796 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.0019701077246801497 - actor/ppo_kl:0.0008341181149452135 - actor/pg_clipfrac_lower:0.0 - actor/pg_loss:0.022914108828915716 - actor/grad_norm:0.6784133665449389 - perf/mfu/actor:0.03547302755337238 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.65625 - perf/cpu_memory_used_gb:95.32715845108032 - actor/lr:5e-07 - training/global_step:96.0 - training/epoch:0.0 - critic/score/mean:0.3701171875 - critic/score/max:1.0 - critic/score/min:0.0 - critic/rewards/mean:0.3701171875 - critic/rewards/max:1.0 - critic/rewards/min:0.0 - critic/advantages/mean:-0.022924419841729105 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.022924419841729105 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:244.7685546875 - response_length/max:2510.0 - response_length/min:4.0 - response_length/clip_ratio:0.0 - response_length_non_aborted/mean:244.7685546875 - response_length_non_aborted/max:2510.0 - response_length_non_aborted/min:4.0 - response_length_non_aborted/clip_ratio:0.0 - response/aborted_ratio:0.0 - prompt_length/mean:102.9296875 - prompt_length/max:194.0 - prompt_length/min:68.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:35.295725256204605 - timing_s/reward:0.0008209720253944397 - timing_s/old_log_prob:0.001010015606880188 - timing_s/ref:61.90337019786239 - timing_s/adv:0.24026444554328918 - timing_s/update_actor:127.7652410119772 - timing_s/step:225.2127811163664 - timing_per_token_ms/update_actor:0.14868505305210014 - timing_per_token_ms/adv:0.0002651560853398631 - timing_per_token_ms/ref:0.07804365330665666 - timing_per_token_ms/gen:0.005562899265712892 - perf/total_num_tokens:712086.0 - perf/time_per_step:225.2127811163664 - perf/throughput:790.4591343242511 - trainer/idle_ratio:0.15672167929922
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 117.88 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 23 to 24
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 23 to 24 ,reset staleness_samples to: 51,idle_ratio: 0.004759264573771627
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.6279072761535645 seconds, while cache cost 6.198883056640625e-06 seconds,  register cost 0.0004820823669433594 seconds, update cost 0.12389016151428223 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:24 - timing_s/wait_last_valid:0.003401797264814377 - timing_s/param_sync:119.51761778816581
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:44:51,986 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 119.51 seconds, pause:117.88s, sync:1.63s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.1644139289855957 seconds, while cache cost 0.7729473114013672 seconds,  register cost 0.0442500114440918 seconds, update cost 0.12387228012084961 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4641592502593994 seconds, offload model to cpu cost 1.5984992980957031 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 24,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 6195,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 25/29 [2:28:21<22:17, 334.38s/it]
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.6272854804992676 seconds, while cache cost 8.106231689453125e-06 seconds,  register cost 0.0005102157592773438 seconds, update cost 0.123779296875 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1389954090118408 seconds, while cache cost 0.7957351207733154 seconds,  register cost 0.21651506423950195 seconds, update cost 0.12392544746398926 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.48978185653686523 seconds, offload model to cpu cost 1.6376113891601562 seconds
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=6200, queue_size=1
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 34.93 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.33s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=6300, queue_size=92
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=6400, queue_size=192
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 24,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 6431,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 20,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 223,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 97 local_trigger_step: 1 trigger_parameter_sync_step: 4 02:46:19.877
[36m(FullyAsyncTrainer pid=555857)[0m step:24 - rollouter/active_time:343.2676205635071 - rollouter/version_time:344.90913438796997 - rollouter/idle_ratio:0.004759264573771627
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:46:19,880 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 167
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.34 seconds.mq_len: 167
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 98 local_trigger_step: 2 trigger_parameter_sync_step: 4 02:47:02.510
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:47:02,514 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 110
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.34 seconds.mq_len: 110
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 99 local_trigger_step: 3 trigger_parameter_sync_step: 4 02:47:46.040
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:47:46,043 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 46
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.36 seconds.mq_len: 46
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 24,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 6447,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 4,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 47,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 100 local_trigger_step: 4 trigger_parameter_sync_step: 4 02:48:31.316
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006959438323974609
[36m(FullyAsyncTrainer pid=555857)[0m step:25 - fully_async/count/stale_samples_processed:1216.0 - fully_async/count/stale_trajectory_processed:9728.0 - fully_async/count/current_param_version:24.0 - fully_async/processing_time/avg:36.15702400004375 - fully_async/processing_time/max:342.4568842686713 - fully_async/processing_time/min:1.0015887841582298 - fully_async/processing_time/tp50:36.16153156757355 - fully_async/processing_time/tp99:59.54392860038206 - fully_async/processing_time/tp95:52.30021479288116 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:6336.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:35.974499225616455 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:1.7223208405720634 - rollout_corr/training_log_ppl:0.47761600310149377 - rollout_corr/kl:0.007923770038709244 - rollout_corr/k3_kl:0.005688884614592529 - rollout_corr/rollout_ppl:1.7070126845618756 - rollout_corr/rollout_log_ppl:0.4694335645804647 - rollout_corr/log_ppl_diff:0.008182438392412526 - rollout_corr/log_ppl_abs_diff:0.009037663808605271 - rollout_corr/log_ppl_diff_max:0.1928531527519226 - rollout_corr/log_ppl_diff_min:-0.01858927309513092 - rollout_corr/ppl_ratio:1.008431669631425 - rollout_corr/chi2_token:0.0009817031772082958 - rollout_corr/chi2_seq:0.19142951413767087 - actor/kl_loss:0.04089182352287356 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.0055992460700036205 - actor/ppo_kl:0.00788196277351029 - actor/pg_clipfrac_lower:2.519407591244701e-05 - actor/pg_loss:0.04808164295585223 - actor/grad_norm:0.668267257776565 - perf/mfu/actor:0.03806741648451213 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.65625 - perf/cpu_memory_used_gb:95.03171825408936 - actor/lr:5e-07 - training/global_step:100.0 - training/epoch:0.0 - critic/score/mean:0.3515625 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.3515625 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.0493984988424927 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.0493984988424927 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:249.6083984375 - response_length/max:3072.0 - response_length/min:7.0 - response_length/clip_ratio:0.00048828125 - response_length_non_aborted/mean:249.6083984375 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:7.0 - response_length_non_aborted/clip_ratio:0.00048828125 - response/aborted_ratio:0.0 - prompt_length/mean:103.91796875 - prompt_length/max:212.0 - prompt_length/min:68.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:37.770504746586084 - timing_s/reward:0.0008740425109863281 - timing_s/old_log_prob:0.0009941942989826202 - timing_s/ref:61.528636045753956 - timing_s/adv:0.23700909316539764 - timing_s/update_actor:119.70525920763612 - timing_s/step:219.24897798895836 - timing_per_token_ms/update_actor:0.14671807781397925 - timing_per_token_ms/adv:0.0002629590211892867 - timing_per_token_ms/ref:0.07589305839569868 - timing_per_token_ms/gen:0.005483975198145523 - perf/total_num_tokens:724022.0 - perf/time_per_step:219.24897798895836 - perf/throughput:825.5705529861839 - trainer/idle_ratio:0.17227220438166993
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncAgentLoopWorker pid=555832)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 20.08 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 24 to 25
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 24 to 25 ,reset staleness_samples to: 51,idle_ratio: 0.006694175466911312
[36m(FullyAsyncRollouter pid=551476)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:48:53,030 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'green'}
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.5992975234985352 seconds, while cache cost 6.198883056640625e-06 seconds,  register cost 0.0005218982696533203 seconds, update cost 0.12606239318847656 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:25 - timing_s/wait_last_valid:0.002956114709377289 - timing_s/param_sync:21.689979389309883
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:48:53,027 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 21.69 seconds, pause:20.08s, sync:1.60s
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.126157283782959 seconds, while cache cost 0.7822754383087158 seconds,  register cost 0.2152571678161621 seconds, update cost 0.12613153457641602 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.473721981048584 seconds, offload model to cpu cost 1.5978491306304932 seconds
[36m(FullyAsyncRollouter pid=551476)[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': True, 'validate': True, 'global_steps': 6580}
[36m(FullyAsyncAgentLoopWorker pid=555848)[0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[36m(WorkerDict pid=558094)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(FullyAsyncRollouter pid=551476)[0m validation generation end
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.5991904735565186 seconds, while cache cost 5.4836273193359375e-06 seconds,  register cost 0.00047969818115234375 seconds, update cost 0.12601542472839355 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.1267528533935547 seconds, while cache cost 0.7563526630401611 seconds,  register cost 0.044351816177368164 seconds, update cost 0.12604093551635742 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.47328615188598633 seconds, offload model to cpu cost 1.5795669555664062 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 25,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 51,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 6448,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 3,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 405.11 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=6500, queue_size=36
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=6600, queue_size=136
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 25,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 6670,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 37,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 206,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 101 local_trigger_step: 1 trigger_parameter_sync_step: 4 02:56:29.431
[36m(FullyAsyncTrainer pid=555857)[0m step:25 - val-aux/openai/gsm8k/reward/mean@1:0.4086429112964367 - val-core/openai/gsm8k/acc/mean@1:0.4177407126611069 - val-aux/num_turns/min:2 - val-aux/num_turns/max:2 - val-aux/num_turns/mean:2.0
[36m(FullyAsyncTrainer pid=555857)[0m ('[FullyAsyncTrainer] parameter version: 25 Validation metrics: '
[36m(FullyAsyncTrainer pid=555857)[0m  "{'val-aux/openai/gsm8k/reward/mean@1': 0.4086429112964367, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-core/openai/gsm8k/acc/mean@1': 0.4177407126611069, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-aux/num_turns/min': 2, 'val-aux/num_turns/max': 2, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-aux/num_turns/mean': 2.0}")
[36m(FullyAsyncTrainer pid=555857)[0m step:25 - rollouter/active_time:239.42476725578308 - rollouter/version_time:241.03832006454468 - rollouter/idle_ratio:0.006694175466911312 - rollouter/validate_time:373.78384229540825
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:56:29,435 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 167
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.31 seconds.mq_len: 167
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=6700, queue_size=172
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 102 local_trigger_step: 2 trigger_parameter_sync_step: 4 02:57:13.469
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:57:13,473 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 109
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 109
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 25,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 6701,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 6,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 109,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 103 local_trigger_step: 3 trigger_parameter_sync_step: 4 02:57:55.445
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 02:57:55,448 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 49
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 26/29 [2:38:30<20:50, 416.80s/it]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 49
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.29s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 104 local_trigger_step: 4 trigger_parameter_sync_step: 4 02:58:40.407
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006499290466308594
[36m(FullyAsyncTrainer pid=555857)[0m step:26 - fully_async/count/stale_samples_processed:1264.0 - fully_async/count/stale_trajectory_processed:10112.0 - fully_async/count/current_param_version:25.0 - fully_async/processing_time/avg:33.991552291974585 - fully_async/processing_time/max:237.22181318327785 - fully_async/processing_time/min:1.5640486478805542 - fully_async/processing_time/tp50:33.7576809679158 - fully_async/processing_time/tp99:57.993002898897956 - fully_async/processing_time/tp95:50.424621005123484 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:6592.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:406.0848217010498 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:1.8433379183351168 - rollout_corr/training_log_ppl:0.4703181669726847 - rollout_corr/kl:0.004890840583941185 - rollout_corr/k3_kl:0.003990167673815637 - rollout_corr/rollout_ppl:1.829414329638427 - rollout_corr/rollout_log_ppl:0.4654556741821378 - rollout_corr/log_ppl_diff:0.004862491014483524 - rollout_corr/log_ppl_abs_diff:0.006354968900218635 - rollout_corr/log_ppl_diff_max:0.39518260955810547 - rollout_corr/log_ppl_diff_min:-0.017057836055755615 - rollout_corr/ppl_ratio:1.0051112489633696 - rollout_corr/chi2_token:0.00216876435387504 - rollout_corr/chi2_seq:0.3747800959266811 - actor/kl_loss:0.04409655650050449 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.0034478641458561524 - actor/ppo_kl:0.004846263056194271 - actor/pg_clipfrac_lower:1.1093397356139925e-05 - actor/pg_loss:0.03959744216551217 - actor/grad_norm:0.7210267778448789 - perf/mfu/actor:0.036661254219699554 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.65625 - perf/cpu_memory_used_gb:95.03130292892456 - actor/lr:5e-07 - training/global_step:104.0 - training/epoch:0.0 - critic/score/mean:0.4492464065551758 - critic/score/max:1.0 - critic/score/min:-0.943359375 - critic/rewards/mean:0.4492464065551758 - critic/rewards/max:1.0 - critic/rewards/min:-0.943359375 - critic/advantages/mean:-0.03989333030767739 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.03989333030767739 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:235.08056640625 - response_length/max:3043.0 - response_length/min:4.0 - response_length/clip_ratio:0.0 - response_length_non_aborted/mean:235.08056640625 - response_length_non_aborted/max:3043.0 - response_length_non_aborted/min:4.0 - response_length_non_aborted/clip_ratio:0.0 - response/aborted_ratio:0.0 - prompt_length/mean:100.53515625 - prompt_length/max:186.0 - prompt_length/min:62.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:407.8365486636758 - timing_s/reward:0.0009179115295410156 - timing_s/old_log_prob:0.0010225623846054077 - timing_s/ref:61.062516283243895 - timing_s/adv:0.24254726991057396 - timing_s/update_actor:118.14628620073199 - timing_s/step:587.2959612645209 - timing_per_token_ms/update_actor:0.15418574240246377 - timing_per_token_ms/adv:0.0002760310763256926 - timing_per_token_ms/ref:0.07782541112930993 - timing_per_token_ms/gen:0.0056843561146373974 - perf/total_num_tokens:687341.0 - perf/time_per_step:587.2959612645209 - perf/throughput:292.5871474239623 - trainer/idle_ratio:0.6944310459509261
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 25,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 6706,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 1,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 50,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 135.18 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 25 to 26
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 25 to 26 ,reset staleness_samples to: 51,idle_ratio: 0.004590353175307205
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.5943753719329834 seconds, while cache cost 6.4373016357421875e-06 seconds,  register cost 0.0005137920379638672 seconds, update cost 0.12355208396911621 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:26 - timing_s/wait_last_valid:0.00357716903090477 - timing_s/param_sync:136.78566786646843
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 03:00:57,214 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 136.78 seconds, pause:135.18s, sync:1.60s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1217210292816162 seconds, while cache cost 0.7709062099456787 seconds,  register cost 0.22445988655090332 seconds, update cost 0.1236872673034668 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4731414318084717 seconds, offload model to cpu cost 1.6000409126281738 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 26,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 6707,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.593949794769287 seconds, while cache cost 7.867813110351562e-06 seconds,  register cost 0.0005204677581787109 seconds, update cost 0.12358880043029785 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.0967974662780762 seconds, while cache cost 0.7118813991546631 seconds,  register cost 0.04117703437805176 seconds, update cost 0.12355875968933105 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.49775195121765137 seconds, offload model to cpu cost 1.600060224533081 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 33.97 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=6800, queue_size=80
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=6900, queue_size=180
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 26,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 6943,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 20,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 223,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 105 local_trigger_step: 1 trigger_parameter_sync_step: 4 03:02:25.665
[36m(FullyAsyncTrainer pid=555857)[0m step:26 - rollouter/active_time:348.78119111061096 - rollouter/version_time:350.38960313796997 - rollouter/idle_ratio:0.004590353175307205
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 03:02:25,669 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 167
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 167
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 106 local_trigger_step: 2 trigger_parameter_sync_step: 4 03:03:08.245
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 03:03:08,249 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 109
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.41 seconds.mq_len: 109
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 26,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 6958,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 5,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 110,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 107 local_trigger_step: 3 trigger_parameter_sync_step: 4 03:03:51.565
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 03:03:51,569 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 46
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.45 seconds.mq_len: 46
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.36s
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  93%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 27/29 [2:44:27<13:17, 398.80s/it]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 108 local_trigger_step: 4 trigger_parameter_sync_step: 4 03:04:37.210
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006227493286132812
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m step:27 - fully_async/count/stale_samples_processed:1315.0 - fully_async/count/stale_trajectory_processed:10520.0 - fully_async/count/current_param_version:26.0 - fully_async/processing_time/avg:37.05632726525073 - fully_async/processing_time/max:396.45380349829793 - fully_async/processing_time/min:1.8458457104861736 - fully_async/processing_time/tp50:36.10074825352058 - fully_async/processing_time/tp99:76.62888515801161 - fully_async/processing_time/tp95:53.102024661982426 - fully_async/monitor/active_tasks_size:147.0 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:6848.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:3.0 - fully_async/partial/partial_ratio:0.00146484375 - fully_async/partial/max_partial_span:1.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:35.18523359298706 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:2.3197378753344533 - rollout_corr/training_log_ppl:0.46634701263883616 - rollout_corr/kl:0.0009482178939673538 - rollout_corr/k3_kl:0.000809742429517346 - rollout_corr/rollout_ppl:2.311022410342238 - rollout_corr/rollout_log_ppl:0.4654279828268951 - rollout_corr/log_ppl_diff:0.0009190316457371383 - rollout_corr/log_ppl_abs_diff:0.0023230040971161815 - rollout_corr/log_ppl_diff_max:0.04572129249572754 - rollout_corr/log_ppl_diff_min:-0.013009428977966309 - rollout_corr/ppl_ratio:1.0009243610912881 - rollout_corr/chi2_token:0.0012915438025438485 - rollout_corr/chi2_seq:0.3420204350295394 - actor/kl_loss:0.04141184760932275 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.00214052823497324 - actor/ppo_kl:0.0009482178939673538 - actor/pg_clipfrac_lower:0.0 - actor/pg_loss:0.06456612134592643 - actor/grad_norm:0.6746423790395157 - perf/mfu/actor:0.03802634899242791 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.65625 - perf/cpu_memory_used_gb:95.36370182037354 - actor/lr:5e-07 - training/global_step:108.0 - training/epoch:0.0 - critic/score/mean:0.3690986633300781 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.3690986633300781 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.06677954876795411 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.06677954876795411 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:253.466796875 - response_length/max:3072.0 - response_length/min:7.0 - response_length/clip_ratio:0.001953125 - response_length_non_aborted/mean:253.466796875 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:7.0 - response_length_non_aborted/clip_ratio:0.001953125 - response/aborted_ratio:0.0 - prompt_length/mean:102.796875 - prompt_length/max:180.0 - prompt_length/min:68.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:37.18246411904693 - timing_s/reward:0.0008640401065349579 - timing_s/old_log_prob:0.0009946301579475403 - timing_s/ref:61.568684719502926 - timing_s/adv:0.24777304753661156 - timing_s/update_actor:120.89933837205172 - timing_s/step:219.9060067012906 - timing_per_token_ms/update_actor:0.14706417115129355 - timing_per_token_ms/adv:0.00027537844349551603 - timing_per_token_ms/ref:0.07434574143371085 - timing_per_token_ms/gen:0.007135731129558622 - perf/total_num_tokens:729628.0 - perf/time_per_step:219.9060067012906 - perf/throughput:829.4771149556301 - trainer/idle_ratio:0.16908344013337362
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 71.92 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 26 to 27
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 26 to 27 ,reset staleness_samples to: 51,idle_ratio: 0.0055961786246494505
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.619654655456543 seconds, while cache cost 6.4373016357421875e-06 seconds,  register cost 0.0004916191101074219 seconds, update cost 0.12263298034667969 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:27 - timing_s/wait_last_valid:0.0029838383197784424 - timing_s/param_sync:73.56018053740263
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 03:05:50,791 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 73.56 seconds, pause:71.92s, sync:1.63s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][ShouldPause] due to staleness_samples 307 >= max_required_samples 307 
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received pause signal, waiting for remaining tasks to return...
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1440036296844482 seconds, while cache cost 0.803311824798584 seconds,  register cost 0.21507644653320312 seconds, update cost 0.12270355224609375 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4761836528778076 seconds, offload model to cpu cost 1.5994737148284912 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 27,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 6963,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress:  97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 28/29 [2:49:13<06:04, 364.78s/it]
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.6194233894348145 seconds, while cache cost 5.245208740234375e-06 seconds,  register cost 0.0004942417144775391 seconds, update cost 0.12259531021118164 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.1531002521514893 seconds, while cache cost 0.6983904838562012 seconds,  register cost 0.0434722900390625 seconds, update cost 0.12262439727783203 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4672515392303467 seconds, offload model to cpu cost 1.5817482471466064 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 31.09 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=7000, queue_size=24
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=7100, queue_size=124
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=7200, queue_size=224
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 27,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 7201,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 18,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 225,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 109 local_trigger_step: 1 trigger_parameter_sync_step: 4 03:07:10.200
[36m(FullyAsyncTrainer pid=555857)[0m step:27 - rollouter/active_time:291.931964635849 - rollouter/version_time:293.5748620033264 - rollouter/idle_ratio:0.0055961786246494505
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 03:07:10,203 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 168
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.33 seconds.mq_len: 168
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.31s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 110 local_trigger_step: 2 trigger_parameter_sync_step: 4 03:07:53.196
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 03:07:53,199 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 112
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.36 seconds.mq_len: 112
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 27,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 7217,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 2,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 113,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 128,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 111 local_trigger_step: 3 trigger_parameter_sync_step: 4 03:08:35.476
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 03:08:35,479 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 49
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 49
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.31s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 112 local_trigger_step: 4 trigger_parameter_sync_step: 4 03:09:22.625
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.00063323974609375
[36m(FullyAsyncTrainer pid=555857)[0m step:28 - fully_async/count/stale_samples_processed:1366.0 - fully_async/count/stale_trajectory_processed:10928.0 - fully_async/count/current_param_version:27.0 - fully_async/processing_time/avg:35.65722646522045 - fully_async/processing_time/max:290.9088841788471 - fully_async/processing_time/min:0.5551504381000996 - fully_async/processing_time/tp50:35.13214092189446 - fully_async/processing_time/tp99:68.99662199109787 - fully_async/processing_time/tp95:51.924981463607395 - fully_async/monitor/active_tasks_size:147.75 - fully_async/monitor/queue/pending_queue_size:128.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:95.75 - fully_async/count/total_generated_samples:7104.0 - fully_async/count/staleness_samples:307.0 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:32.11691331863403 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:1.9071155223642 - rollout_corr/training_log_ppl:0.5198503423695215 - rollout_corr/kl:0.03906321805333372 - rollout_corr/k3_kl:0.032662097469466814 - rollout_corr/rollout_ppl:1.7904674353929164 - rollout_corr/rollout_log_ppl:0.47460367740828646 - rollout_corr/log_ppl_diff:0.04524666173997997 - rollout_corr/log_ppl_abs_diff:0.045996538326232225 - rollout_corr/log_ppl_diff_max:0.8187096118927002 - rollout_corr/log_ppl_diff_min:-0.021883249282836914 - rollout_corr/ppl_ratio:1.0497339005365474 - rollout_corr/chi2_token:0.19795368813372372 - rollout_corr/chi2_seq:0.4014359635101424 - actor/kl_loss:0.04730930653251496 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.020953253977097165 - actor/ppo_kl:0.03877571693254027 - actor/pg_clipfrac_lower:0.00019049303161851967 - actor/pg_loss:0.06842583585751734 - actor/grad_norm:0.7355744752015834 - perf/mfu/actor:0.039171012711224085 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.65625 - perf/cpu_memory_used_gb:95.27164602279663 - actor/lr:5e-07 - training/global_step:112.0 - training/epoch:0.0 - critic/score/mean:0.36083984375 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.36083984375 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.06728841410949826 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.06728841410949826 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:246.1181640625 - response_length/max:3072.0 - response_length/min:3.0 - response_length/clip_ratio:0.00146484375 - response_length_non_aborted/mean:246.1181640625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:3.0 - response_length_non_aborted/clip_ratio:0.00146484375 - response/aborted_ratio:0.0 - prompt_length/mean:101.62109375 - prompt_length/max:189.0 - prompt_length/min:68.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:33.95553805306554 - timing_s/reward:0.0008292980492115021 - timing_s/old_log_prob:0.0010106302797794342 - timing_s/ref:62.074107218533754 - timing_s/adv:0.2472509779036045 - timing_s/update_actor:115.45937269553542 - timing_s/step:211.74420527368784 - timing_per_token_ms/update_actor:0.13657867373967766 - timing_per_token_ms/adv:0.00028552593084395835 - timing_per_token_ms/ref:0.07144688368590814 - timing_per_token_ms/gen:0.00590493338774904 - perf/total_num_tokens:712170.0 - perf/time_per_step:211.74420527368784 - perf/throughput:840.8376501726361 - trainer/idle_ratio:0.16036112066999259
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 136.87 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 27 to 28
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2
[36m(WorkerDict pid=558094)[0m [rank1] register pin_memory for  bucket 1/1 finished, size 241.59MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 27 to 28 ,reset staleness_samples to: 51,idle_ratio: 0.004880701036424684
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.695096492767334 seconds, while cache cost 7.152557373046875e-06 seconds,  register cost 0.0005197525024414062 seconds, update cost 0.12508749961853027 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:28 - timing_s/wait_last_valid:0.003069687634706497 - timing_s/param_sync:138.58120905980468
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 03:11:41,228 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 138.58 seconds, pause:136.88s, sync:1.70s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Feed] Maximum count has been reached, stop adding new samples7473 >= 7473
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Feed] Sample addition is complete, 7473 samples have been added
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Processor] Received end signal, waiting for remaining tasks to complete...
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.1950478553771973 seconds, while cache cost 0.7769224643707275 seconds,  register cost 0.04429054260253906 seconds, update cost 0.1250166893005371 seconds
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4997882843017578 seconds, offload model to cpu cost 1.5940501689910889 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter] Sample feed completed
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 28,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 306,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 7219,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 254,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [2:55:04<00:00, 360.71s/it]
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:1.6945984363555908 seconds, while cache cost 7.152557373046875e-06 seconds,  register cost 0.0005192756652832031 seconds, update cost 0.1250162124633789 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.1558904647827148 seconds, while cache cost 0.8100998401641846 seconds,  register cost 0.21795654296875 seconds, update cost 0.12514734268188477 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.5398402214050293 seconds, offload model to cpu cost 1.7012293338775635 seconds
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 30.62 seconds.mq_len: 0
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.32s
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=7300, queue_size=68
[36m(MessageQueue pid=560789)[0m MessageQueue stats: produced=7400, queue_size=168
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 28,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 306,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 7462,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 11,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 230,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 113 local_trigger_step: 1 trigger_parameter_sync_step: 4 03:13:03.693
[36m(FullyAsyncTrainer pid=555857)[0m step:28 - rollouter/active_time:348.7196583747864 - rollouter/version_time:350.430002450943 - rollouter/idle_ratio:0.004880701036424684
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 03:13:03,697 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 167
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.35 seconds.mq_len: 167
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 114 local_trigger_step: 2 trigger_parameter_sync_step: 4 03:13:47.900
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 03:13:47,903 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 109
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.32 seconds.mq_len: 109
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 115 local_trigger_step: 3 trigger_parameter_sync_step: 4 03:14:28.750
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 03:14:28,753 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Collected 64/64 samples. mq_len: 46
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Loop collection completed: 64/64 samples, total wait time: 0.31 seconds.mq_len: 46
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Assembling batch from 64 RolloutSample objects
[36m(FullyAsyncTrainer pid=555857)[0m [BatchUtils] Batch assembly completed in 0.30s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 28,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 306,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 7471,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 2,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 47,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] global_steps: 116 local_trigger_step: 4 trigger_parameter_sync_step: 4 03:15:13.834
[36m(FullyAsyncTrainer pid=555857)[0m aggregated metrics done. cost 0.0006182193756103516
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress: 30it [2:56:17, 274.51s/it]                                                                                                                                                             
[36m(FullyAsyncTrainer pid=555857)[0m step:29 - fully_async/count/stale_samples_processed:1417.0 - fully_async/count/stale_trajectory_processed:11336.0 - fully_async/count/current_param_version:28.0 - fully_async/processing_time/avg:34.11348866152912 - fully_async/processing_time/max:347.36580416560173 - fully_async/processing_time/min:3.388306677341461 - fully_async/processing_time/tp50:33.6253774240613 - fully_async/processing_time/tp99:59.66538356550967 - fully_async/processing_time/tp95:49.968437294429165 - fully_async/monitor/active_tasks_size:145.5 - fully_async/monitor/queue/pending_queue_size:32.0 - fully_async/monitor/queue/cancel_queue_size:0.0 - fully_async/monitor/queue/mq_queue_size:96.0 - fully_async/count/total_generated_samples:7360.0 - fully_async/count/staleness_samples:306.25 - fully_async/count/dropped_stale_samples:0.0 - fully_async/static/max_required_samples:307.0 - fully_async/static/required_samples:64.0 - fully_async/static/staleness_threshold:0.2 - fully_async/static/max_queue_size:307.0 - fully_async/static/max_concurrent_samples:256.0 - fully_async/partial/total_partial_num:0.0 - fully_async/partial/partial_ratio:0.0 - fully_async/partial/max_partial_span:0.0 - timing_s/agent_loop/tool_calls/max:0.0 - timing_s/agent_loop/tool_calls/min:0.0 - timing_s/agent_loop/tool_calls/mean:0.0 - fully_async/total_wait_time:31.593909740447998 - rollout_corr/rollout_is_veto_fraction:0.0 - rollout_corr/rollout_is_catastrophic_token_fraction:0.0 - rollout_corr/training_ppl:1.6159860671264288 - rollout_corr/training_log_ppl:0.42535039300793154 - rollout_corr/kl:0.012963796468996246 - rollout_corr/k3_kl:0.010478460883966166 - rollout_corr/rollout_ppl:1.580262249579295 - rollout_corr/rollout_log_ppl:0.41130376225094095 - rollout_corr/log_ppl_diff:0.014046633662561194 - rollout_corr/log_ppl_abs_diff:0.015340397333173184 - rollout_corr/log_ppl_diff_max:1.3036234378814697 - rollout_corr/log_ppl_diff_min:-0.02767765522003174 - rollout_corr/ppl_ratio:1.0167221379529556 - rollout_corr/chi2_token:0.012516492665412252 - rollout_corr/chi2_seq:0.1943516870166985 - actor/kl_loss:0.047825997166985955 - actor/kl_coef:0.001 - actor/pg_clipfrac:0.006422276268732573 - actor/ppo_kl:0.01282134717766198 - actor/pg_clipfrac_lower:5.292654183942983e-05 - actor/pg_loss:0.0492968800083034 - actor/grad_norm:0.6905224481835965 - perf/mfu/actor:0.03752501730269468 - perf/max_memory_allocated_gb:22.45757246017456 - perf/max_memory_reserved_gb:58.65625 - perf/cpu_memory_used_gb:95.50933647155762 - actor/lr:5e-07 - training/global_step:116.0 - training/epoch:0.0 - critic/score/mean:0.42919921875 - critic/score/max:1.0 - critic/score/min:-1.0 - critic/rewards/mean:0.42919921875 - critic/rewards/max:1.0 - critic/rewards/min:-1.0 - critic/advantages/mean:-0.04951778054237366 - critic/advantages/max:2.4748666286468506 - critic/advantages/min:-2.4748666286468506 - critic/returns/mean:-0.04951778054237366 - critic/returns/max:2.4748666286468506 - critic/returns/min:-2.4748666286468506 - response_length/mean:233.70556640625 - response_length/max:3072.0 - response_length/min:11.0 - response_length/clip_ratio:0.00048828125 - response_length_non_aborted/mean:233.70556640625 - response_length_non_aborted/max:3072.0 - response_length_non_aborted/min:11.0 - response_length_non_aborted/clip_ratio:0.00048828125 - response/aborted_ratio:0.0 - prompt_length/mean:102.984375 - prompt_length/max:183.0 - prompt_length/min:66.0 - prompt_length/clip_ratio:0.0 - num_turns/min:2.0 - num_turns/max:2.0 - num_turns/mean:2.0 - timing_s/gen:33.46920472756028 - timing_s/reward:0.0008217692375183105 - timing_s/old_log_prob:0.0009700357913970947 - timing_s/ref:61.64164433255792 - timing_s/adv:0.7554159350693226 - timing_s/update_actor:116.6400173343718 - timing_s/step:212.51395715028048 - timing_per_token_ms/update_actor:0.14938393426069202 - timing_per_token_ms/adv:0.00029034487570081004 - timing_per_token_ms/ref:0.08103111412941712 - timing_per_token_ms/gen:0.00567889037290354 - perf/total_num_tokens:689541.0 - perf/time_per_step:212.51395715028048 - perf/throughput:811.171427569328 - trainer/idle_ratio:0.15749179572187977
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause] All active tasks completed
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter] Streaming process completed
[36m(WorkerDict pid=552781)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 71.50 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 28 to 29
[36m(WorkerDict pid=558093)[0m cache_actor_weights_to_cpu, local_rank:0, world_size:2
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 28 to 29 ,reset staleness_samples to: 50,idle_ratio: None
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(WorkerDict pid=552781)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:False, is_rollout:True, total cost:1.5999908447265625 seconds, while cache cost 3.814697265625e-05 seconds,  register cost 0.0008294582366943359 seconds, update cost 0.1262342929840088 seconds
[36m(FullyAsyncTrainer pid=555857)[0m step:29 - timing_s/wait_last_valid:0.0033185556530952454 - timing_s/param_sync:73.11417369544506
[36m(FullyAsyncTrainer pid=555857)[0m [Rank 0 | Local Rank 0] 2026-01-06 03:16:26,972 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'red'}
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Requesting 64 samples from queue
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 73.11 seconds, pause:71.50s, sync:1.61s
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Pause]
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] Detected termination signal (None), stopping sample collection. Collected 49/64 samples
[36m(FullyAsyncTrainer pid=555857)[0m [FullyAsyncTrainer] not enough samples collected after loop
[36m(FullyAsyncTrainer pid=555857)[0m step:29
[36m(FullyAsyncTrainer pid=555857)[0m step:30
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 0.00 seconds
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] rollout paused. cost 0.02 seconds
[36m(MessageQueue pid=560789)[0m Parameter version updated from 29 to 30
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint finish!, rank:0, is_actor:True, is_rollout:False, total cost:1.121145248413086 seconds, while cache cost 0.7776985168457031 seconds,  register cost 0.21436238288879395 seconds, update cost 0.12635183334350586 seconds
[36m(WorkerDict pid=558093)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.4821925163269043 seconds, offload model to cpu cost 1.6043343544006348 seconds
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][update_param_version] Parameter version updated from 29 to 30 ,reset staleness_samples to: 0,idle_ratio: None
[36m(FullyAsyncRollouter pid=551476)[0m [Rank 0 | Local Rank 0] 2026-01-06 03:16:30,175 WARNING [root:82] => Kwargs are not supported in mstx_profile, but received: {'color': 'green'}
[36m(FullyAsyncTrainer pid=555857)[0m step:30 - timing_s/wait_last_valid:0.0014758333563804626 - timing_s/param_sync:2.931927677243948
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] sync_weights success. cost 2.93 seconds, pause:0.02s, sync:2.90s
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Waiting last sync and validate...
[36m(WorkerDict pid=558093)[0m set checkpoint_engine device buffer size: 4096M, and finally set it to 4096M considering the largest paramter tensor size[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=558094)[0m cache_actor_weights_to_cpu, local_rank:1, world_size:2[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558093)[0m [rank0] register pin_memory for  bucket 1/1 finished, size 700.70MiB, start to copy tensors to buffer[32m [repeated 3x across cluster][0m
[36m(FullyAsyncRollouter pid=551476)[0m test_gen_batch meta info: {'eos_token_id': 151645, 'pad_token_id': 151643, 'recompute_log_prob': False, 'do_sample': True, 'validate': True, 'global_steps': 7473}
[36m(WorkerDict pid=552782)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:False, is_rollout:True, total cost:2.9001176357269287 seconds, while cache cost 2.1457672119140625e-06 seconds,  register cost 0.0003790855407714844 seconds, update cost 0.12104129791259766 seconds[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint finish!, rank:1, is_actor:True, is_rollout:False, total cost:1.1325328350067139 seconds, while cache cost 0.7103955745697021 seconds,  register cost 0.040460824966430664 seconds, update cost 0.12107253074645996 seconds[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=558094)[0m sync_rollout_weights_by_checkpoint load model to gpu cost 0.45820021629333496 seconds, offload model to cpu cost 1.605907678604126 seconds[32m [repeated 3x across cluster][0m
[36m(FullyAsyncRollouter pid=551476)[0m validation generation end
total time: 11158.66 seconds
[36m(FullyAsyncTrainer pid=555857)[0m Training Progress: 30it [3:02:27, 364.91s/it]
/home/ma-user/.conda/envs/test01/lib/python3.10/subprocess.py:1072: ResourceWarning: subprocess 538849 is still running
  _warn("subprocess %s is still running" % self.pid,
/home/ma-user/.conda/envs/test01/lib/python3.10/subprocess.py:1072: ResourceWarning: subprocess 539177 is still running
  _warn("subprocess %s is still running" % self.pid,
[36m(FullyAsyncTaskRunner pid=545998)[0m [ASYNC MAIN] One component completed successfully
[36m(FullyAsyncTaskRunner pid=545998)[0m [ASYNC MAIN] One component completed successfully
[36m(FullyAsyncTaskRunner pid=545998)[0m [ASYNC MAIN] Training completed or interrupted
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][MonitorLoop][Statistics] {'count/current_param_version': 30,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/dropped_stale_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/staleness_samples': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'count/total_generated_samples': 7473,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/active_tasks_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/cancel_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/mq_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'monitor/queue/pending_queue_size': 0,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_concurrent_samples': 256,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_queue_size': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/max_required_samples': 307,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/required_samples': 64,
[36m(FullyAsyncRollouter pid=551476)[0m  'static/staleness_threshold': 0.2}
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter] Rollouter fit completed
[36m(FullyAsyncRollouter pid=551476)[0m [FullyAsyncRollouter][Public][Resume]
[36m(FullyAsyncTrainer pid=555857)[0m step:30 - val-aux/openai/gsm8k/reward/mean@1:0.4336618650492798 - val-core/openai/gsm8k/acc/mean@1:0.444275966641395 - val-aux/num_turns/min:2 - val-aux/num_turns/max:2 - val-aux/num_turns/mean:2.0
[36m(FullyAsyncTrainer pid=555857)[0m ('[FullyAsyncTrainer] parameter version: 30 Validation metrics: '
[36m(FullyAsyncTrainer pid=555857)[0m  "{'val-aux/openai/gsm8k/reward/mean@1': 0.4336618650492798, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-core/openai/gsm8k/acc/mean@1': 0.444275966641395, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-aux/num_turns/min': 2, 'val-aux/num_turns/max': 2, "
[36m(FullyAsyncTrainer pid=555857)[0m  "'val-aux/num_turns/mean': 2.0}")
[36m(FullyAsyncTrainer pid=555857)[0m step:30 - rollouter/validate_time:366.78051168844104
[36m(ParameterSynchronizer pid=560802)[0m [ParameterSynchronizer] Wait last validate cost: 366.80 seconds
