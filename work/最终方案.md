

# 系统设计文档：基于探路者分流的动态分段生成系统 (P-DSR)

**项目名称**：Probe-Based Dynamic Segment Rollout (P-DSR)

**适用场景**：RL 训练（GRPO 算法）中的推理生成阶段

**核心目标**：解决推理任务中生成长度的“长尾分布”导致的 GPU 算力空转与显存碎片问题，最大化训练吞吐量。

------

## 1. V1 版本方案：批次同步探路与分流 (Batch-Sync Probe Dispatch)

V1 版本采用“先全量摸底，后集中分流”的策略，利用 GRPO 需对同一 Prompt 采样 $N$ 次的特性，通过第 1 次采样的真实耗时来预测任务难度。

### 1.1 核心流程 (Workflow)

1. **全量摸底 (Batch Probe)**
   - **输入**：一个 Batch 的 Prompts（例如 $B=128$），每个 Prompt 需采样 $N=8$ 次。
   - **动作**：调度器提取所有 Prompt 的**第 1 次**采样请求，组成 Probe Batch，发送给 **Fast Worker**。
   - **执行**：Worker 运行 **Dynamic Segment Rollout**（见下文微观执行），跑完所有探路样本，**不设熔断**，记录每个样本的 **真实生成耗时 (Wall-clock Duration)**。
2. **排序与分级 (Sort & Classify)**
   - **同步等待**：调度器等待 Probe Batch 中所有样本完成。
   - **排序**：根据真实耗时从长到短排序。
   - **划分**：
     - **Heavy Task (长尾)**：耗时 Top $K\%$（例如 10%）。
     - **Fast Task (普通)**：剩余 Bottom $(100-K)\%$。
3. **定向分发 (Targeted Dispatch)**
   - 将 Heavy Task 的剩余 $N-1$ 次采样 $\rightarrow$ 发往 **Heavy Worker Queue**（大显存节点）。
   - 将 Fast Task 的剩余 $N-1$ 次采样 $\rightarrow$ 发往 **Fast Worker Queue**（高并发节点）。

### 1.2 微观执行：动态分段 (Budget-Aware Segment Rollout)

在所有 Worker 内部，摒弃固定步长，采用基于**Token 吞吐预算**的动态切分：

- **公式**：$L_{next} = \text{Clamp}(\frac{\text{Total\_Token\_Capacity}}{N_{active}}, L_{min}, L_{max})$
- **逻辑**：
  - **清洗阶段**：样本多，$L$ 小（如 64）。快速筛除秒回的简单样本。
  - **冲刺阶段**：样本少，$L$ 大（如 4096）。消除 Python 调度开销，全速跑完长尾。

### 1.3 V1 版本存在的风险点 (Risks)

1. **宏观同步屏障 (Synchronization Barrier)**：
   - **问题**：摸底阶段必须等待 Batch 中“最慢”的那个样本跑完，才能进行排序和分发。如果 127 个样本 1 秒跑完，1 个样本跑了 30 秒，整个系统会阻塞 29 秒。
   - **影响**：导致 Fast Worker 在等待期间出现明显的算力闲置。
2. **采样方差导致的误判 (Sampling Variance)**：
   - **问题**：RL 采样存在随机性。Prompt A 的第 1 次采样可能很短（运气好早停了），系统判为“简单”；但后续 7 次采样可能很长。
   - **影响**：长任务被错误分发到 Fast Worker，导致 Fast Worker 被“伪装者”卡死。

### 1.4 V1 风险点的解决方案 (Mitigations)

针对 V1 的局限性，在不升级架构的前提下，可采用以下补丁：

1. **针对“同步屏障”**：
   - **设置摸底超时 (Probe Timeout)**：在摸底阶段设置硬性时间上限（如 5 秒）。如果 5 秒没跑完，强制停止，直接标记为 Heavy Task。虽然牺牲了该样本的完整性（可能需要丢弃），但保证了调度流水线的流动。
2. **针对“采样方差”**：
   - **Fast Worker 静态限流**：在 Fast Worker 上设置严格的 `max_tokens`（如 2048）。如果任务被误判且超过此长度，强制截断（Truncate）。虽然会损失一条有效轨迹，但保护了节点不被卡死。

------

## 2. V2 版本方案：流式异步分流与熔断 (Streaming P-DSR)

V2 版本将架构升级为**全异步事件驱动**，引入**滑动窗口阈值**和**熔断回流机制**，彻底解决 V1 的阻塞和误判问题。

### 2.1 核心流程 (Workflow)

1. **流式摸底 (Streaming Probe)**
   - **动作**：调度器持续将探路请求发给 Fast Worker。
   - **事件驱动**：**不需要等待整个 Batch**。只要任意一个探路样本 Finish，立即上报耗时 $T$。
2. **即时分流 (Real-time Routing)**
   - **动态阈值**：维护最近 $M$ 个任务耗时的 P80 分位点作为 $T_{threshold}$（滑动窗口）。
   - **决策**：
     - 若 $T \le T_{threshold}$ $\rightarrow$ 立即分发剩余采样至 **Fast Queue**。
     - 若 $T > T_{threshold}$ $\rightarrow$ 立即分发剩余采样至 **Heavy Queue**。
   - **效果**：短任务探路一结束，后续任务秒发，流水线无阻塞。
3. **异常修正：熔断回流 (Circuit Breaker & Repack)**
   - **场景**：解决 V1 中的“采样方差”问题。如果一个被判为 Simple 的任务在 Fast Worker 上突然变长。
   - **监控**：Fast Worker 实时监控 `Elapsed_Time` 和 `Generated_Tokens`。
   - **熔断条件**：Time > 10s 或 Token > 2048。
   - **回流动作**：
     1. **Suspend**：挂起任务。
     2. **Repack**：打包当前 Context (Token IDs)。
     3. **Transfer**：将任务扔回 **Heavy Queue**，由 Heavy Worker 接盘继续跑。
   - **标记修正**：同时通知调度器将该 Prompt 标记为 Hard，防止后续采样继续错投。
4. **负载均衡：任务窃取 (Work Stealing)**
   - 若 Fast Queue 空闲，Fast Worker 可从 Heavy Queue 窃取任务（但在严格 Time Limit 下运行）。
   - 若 Heavy Queue 空闲，Heavy Worker 可批量窃取 Fast Queue 任务（降维打击）。

### 2.2 微观执行 (Micro Execution)

- 继续沿用 **Budget-Aware Dynamic Segment Rollout**（同 V1），确保单卡内的显存和算力利用率最大化。

### 2.3 算法修正 (Algorithm Correction)

- **异步重要性采样 (IS)**：由于 V2 是全异步的，Actor 和 Learner 策略版本存在差异。在训练 Loss 计算时引入重要性权重 $\rho_t = \pi_{new}/\pi_{old}$ 或使用 V-Trace 进行修正，确保数学收敛性。

### 2.4 V2 方案优势总结

1. **零阻塞**：流式调度消除了 V1 的批次等待时间，Latency 降至最低。
2. **高鲁棒**：熔断回流机制完美处理了 RL 采样的随机性，Fast Worker 永远不会被“伪装的长任务”击穿。
3. **自适应**：滑动窗口阈值能实时适应模型训练过程中（如 Grokking 阶段）的长度分布变化。
